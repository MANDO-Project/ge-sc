{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab621c52-c296-4ad7-91ca-b2198cf2ce68",
   "metadata": {},
   "source": [
    "# Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d42cd2-d8f7-48df-affc-18952944e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import dgl\n",
    "import networkx as nx\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy, relu, softmax, log_softmax, one_hot\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl import graph\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "from slither.slither import Slither\n",
    "from slither.core.cfg.node import NodeType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d797c617-43fc-4507-bb01-22f2a3224ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minhnn/.virtualenvs/ICSE/bin/solc\n",
      "solc, the solidity compiler commandline interface\n",
      "Version: 0.5.0+commit.1d4f565a.Linux.g++\n"
     ]
    }
   ],
   "source": [
    "!which solc && solc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70837768-64fd-4dbc-98d8-18c6e23ae140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from solc import install_solc\n",
    "# install_solc('v0.4.24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97f4e8-7b6f-4671-ad38-44891b0bd4ef",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77567eb3-d2f0-44ff-a95b-fa8871c2ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type_feature(nx_graph):\n",
    "    nx_g = nx_graph\n",
    "    list_node_type = []\n",
    "    node_type_feat_attrs = dict()\n",
    "    for node, data in nx_graph.nodes(data=True):\n",
    "        if data.get('node_type') is not None:\n",
    "            if data['node_type'] not in list_node_type:\n",
    "                list_node_type.append(data['node_type'])\n",
    "            node_type_feat = torch.tensor(list_node_type.index(data['node_type']), dtype=torch.int64)\n",
    "            node_type_feat_attrs[node] = node_type_feat\n",
    "            # print(node_type_feat)\n",
    "\n",
    "    nx.set_node_attributes(nx_g, node_type_feat_attrs, '_TYPE')\n",
    "\n",
    "    return nx_g, list_node_type\n",
    "\n",
    "def add_edge_type_feature(nx_graph):\n",
    "    nx_g = nx_graph\n",
    "    list_edge_type = []\n",
    "\n",
    "    for source, target, data in nx_graph.edges(data=True):\n",
    "        if data.get('edge_type') is not None:\n",
    "            if data['edge_type'] not in list_edge_type:\n",
    "                list_edge_type.append(data['edge_type'])\n",
    "            edge_type_feat = torch.tensor(list_edge_type.index(data['edge_type']), dtype=torch.int64)\n",
    "            nx_g[source][target][0]['_TYPE'] = edge_type_feat\n",
    "\n",
    "    return nx_g, list_edge_type\n",
    "\n",
    "def convert_edge_data_to_tensor(dict_egdes):\n",
    "    dict_three_cannonical_egdes = dict_egdes\n",
    "\n",
    "    for key, val in dict_three_cannonical_egdes.items():\n",
    "        list_source = []\n",
    "        list_target = []\n",
    "        for source, target in val:\n",
    "            list_source.append(source)\n",
    "            list_target.append(target)\n",
    "        # print(list_source, list_target)\n",
    "        dict_three_cannonical_egdes[key] = (torch.tensor(list_source, dtype=torch.int64), torch.tensor(list_target, dtype=torch.int64))\n",
    "\n",
    "    return dict_three_cannonical_egdes\n",
    "\n",
    "def generate_hetero_graph_data(nx_graph):\n",
    "    nx_g = nx_graph\n",
    "    dict_three_cannonical_egdes = dict()\n",
    "    for source, target, data in nx_g.edges(data=True):\n",
    "        edge_type = data['edge_type']\n",
    "        source_node_type = nx_g.nodes[source]['node_type']\n",
    "        target_node_type = nx_g.nodes[target]['node_type']\n",
    "        three_cannonical_egde = (source_node_type, edge_type, target_node_type)\n",
    "        # print(dict_three_cannonical_egdes)\n",
    "        # print(three_cannonical_egde, source, target)\n",
    "        if three_cannonical_egde not in dict_three_cannonical_egdes.keys():\n",
    "            dict_three_cannonical_egdes[three_cannonical_egde] = [(source, target)]\n",
    "        else:\n",
    "            current_val = dict_three_cannonical_egdes[three_cannonical_egde]\n",
    "            temp_edge = (source, target)\n",
    "            current_val.append(temp_edge)\n",
    "            dict_three_cannonical_egdes[three_cannonical_egde] = current_val\n",
    "    \n",
    "    dict_three_cannonical_egdes = convert_edge_data_to_tensor(dict_three_cannonical_egdes)\n",
    "\n",
    "    return dict_three_cannonical_egdes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111a3d99-6543-4796-905c-3aff7f1fe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_full_metapath(hete_graph_data, metapaths):\n",
    "    for metapath in metapaths:\n",
    "        if metapath not in hete_graph_data.keys():\n",
    "            hete_graph_data[metapath] = (torch.tensor([], dtype=torch.int64), torch.tensor([], dtype=torch.int64))\n",
    "    return hete_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97a919c-7a2a-4e15-be27-8e72151f182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_graph(contract_path):\n",
    "#     print(contract_path)\n",
    "    slither = Slither(contract_path, solc=\"/home/minhnn/.py-solc/solc-v0.4.24/bin/solc\")\n",
    "    merge_contract_graph = None\n",
    "    for contract in slither.contracts:\n",
    "        merged_graph = None\n",
    "        for function in contract.functions + contract.modifiers:\n",
    "            if len(function.nodes) == 0:\n",
    "                continue\n",
    "            nx_g = nx.MultiDiGraph()\n",
    "            for node in function.nodes:\n",
    "#                 print('Node:', node, 'NodeType:', node.type, 'NodeExpression:', node.expression)\n",
    "                node_label = \"Node Type: {}\\n\".format(str(node.type))\n",
    "                node_type = str(node.type)\n",
    "                if node.expression:\n",
    "                    node_label += \"\\nEXPRESSION:\\n{}\\n\".format(node.expression)\n",
    "                    node_expression = str(node.expression)\n",
    "                else:\n",
    "                    node_expression = None\n",
    "                if node.irs:\n",
    "                    node_label += \"\\nIRs:\\n\" + \"\\n\".join([str(ir) for ir in node.irs])\n",
    "                    node_irs = \"\\n\".join([str(ir) for ir in node.irs])\n",
    "                else:\n",
    "                    node_irs = None\n",
    "                nx_g.add_node(node.node_id, label=node_label,\n",
    "                              node_type=node_type, node_expression=node_expression, node_irs=node_irs,\n",
    "                              function_fullname=function.full_name, contract_name=contract.name)\n",
    "\n",
    "                if node.type in [NodeType.IF, NodeType.IFLOOP]:\n",
    "                    true_node = node.son_true\n",
    "                    if true_node:\n",
    "                        nx_g.add_edge(node.node_id, true_node.node_id, edge_type='if_true', label='True')\n",
    "                    false_node = node.son_false\n",
    "                    if false_node:\n",
    "                        nx_g.add_edge(node.node_id, false_node.node_id, edge_type='if_false', label='False')\n",
    "                else:\n",
    "                    for son in node.sons:\n",
    "                        nx_g.add_edge(node.node_id, son.node_id, edge_type='next', label='Next')\n",
    "            nx_graph = nx_g\n",
    "#             print(nx.info(nx_graph))\n",
    "            # add FUNCTION_NAME node\n",
    "            nx_graph.add_node('function.name', label=contract.name + '_' + function.full_name,\n",
    "                              node_type='FUNCTION_NAME', node_expression=None, node_irs=None,\n",
    "                              function_fullname=function.full_name, contract_name=contract.name)\n",
    "            nx_graph.add_edge('function.name', 0, edge_type='next', label='Next')\n",
    "            \n",
    "            if merged_graph is None:\n",
    "                nx_graph = nx.relabel_nodes(nx_graph, lambda x: contract.name + '_' + function.name + '_' + str(x), copy=False)\n",
    "                merged_graph = deepcopy(nx_graph)\n",
    "            else:\n",
    "                nx_graph = nx.relabel_nodes(nx_graph, lambda x: contract.name + '_' + function.name + '_' + str(x), copy=False)\n",
    "                merged_graph = nx.disjoint_union(merged_graph, nx_graph)\n",
    "#             print('merged_graph: ', nx.info(merged_graph))\n",
    "        if merge_contract_graph is None:\n",
    "            merge_contract_graph = deepcopy(merged_graph)\n",
    "        elif merged_graph is not None:\n",
    "            merge_contract_graph = nx.disjoint_union(merge_contract_graph, merged_graph)\n",
    "#     print(nx.infor(merge_contract_graph))\n",
    "    return merge_contract_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb7e465-76b9-461a-af43-2bf65f0b9566",
   "metadata": {},
   "source": [
    "# Retrieve graph structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc786b-4d13-4631-b610-b33eafa02717",
   "metadata": {},
   "source": [
    "## Get meta-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6faf6291-a306-4600-b337-d2683bc69bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_contract_path = './datasets/Etherscan_Contract/source_code'\n",
    "smart_contracts = sorted(sorted([f for f in os.listdir(smart_contract_path) if f.endswith('.sol')]), key=len)\n",
    "len(smart_contracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789e001f-5520-45b6-a2e1-7e79cc94fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path_types  = []\n",
    "extracted_contracts = []\n",
    "excepted_contracts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946dbcd0-1170-4afa-ac21-4b1eb96ec8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 186/186 [00:54<00:00,  3.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sc in tqdm(smart_contracts):\n",
    "    sc_path = join(smart_contract_path, sc)\n",
    "    try:\n",
    "        full_graph = get_full_graph(sc_path)\n",
    "        nx.write_gpickle(full_graph, join(smart_contract_path, '../extracted_graph', sc.replace('.sol', '.gpickle')))\n",
    "        full_graph, list_node_type = add_node_type_feature(full_graph)\n",
    "        full_graph, list_edge_type = add_edge_type_feature(full_graph)\n",
    "        full_graph = nx.convert_node_labels_to_integers(full_graph)\n",
    "    #     print(\"graph info: \", nx.info(full_graph))\n",
    "    #     for graph in full_graph.nodes(data=True):\n",
    "    #         print(graph)\n",
    "        nx_g_data = generate_hetero_graph_data(full_graph)\n",
    "        for meta_path in nx_g_data.keys():\n",
    "            if meta_path not in meta_path_types:\n",
    "                meta_path_types.append(meta_path)\n",
    "        extracted_contracts.append(sc)\n",
    "    except:\n",
    "        excepted_contracts.append(sc)\n",
    "len(meta_path_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af5100b-1dcc-42e7-8514-b0ca9fedbb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted/Excepted contracts: 179/186\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted/Excepted contracts: {}/{}\".format(len(extracted_contracts), len(excepted_contracts) + len(extracted_contracts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b1cd7b-a1d7-43c6-b6b5-928bffca22ae",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "metapath_path = './ge-sc/metapaths.txt'\n",
    "meta_path_str = [str(mt) for mt in meta_path_types]\n",
    "with open(metapath_path, 'w') as f:\n",
    "    f.write('\\n'.join([str(meta_path) for meta_path in meta_path_types]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64841e2d-99a9-432c-8668-1fd3e62f8f50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'BEGIN_LOOP': 49024, 'BREAK': 45362, 'CONTINUE': 44867, 'END_IF': 48975, 'END_LOOP': 49025, 'ENTRY_POINT': 49085, 'EXPRESSION': 49086, 'FUNCTION_NAME': 49088, 'IF': 48971, 'IF_LOOP': 49027, 'INLINE ASM': 48934, 'NEW VARIABLE': 49018, 'OTHER_ENTRYPOINT': 49075, 'RETURN': 49033, 'THROW': 48267, '_': 49087},\n",
      "      num_edges={('BEGIN_LOOP', 'next', 'EXPRESSION'): 2, ('BEGIN_LOOP', 'next', 'IF_LOOP'): 357, ('BREAK', 'next', 'END_LOOP'): 29, ('CONTINUE', 'next', 'BEGIN_LOOP'): 15, ('END_IF', 'next', 'BEGIN_LOOP'): 4, ('END_IF', 'next', 'END_IF'): 279, ('END_IF', 'next', 'EXPRESSION'): 902, ('END_IF', 'next', 'IF'): 577, ('END_IF', 'next', 'IF_LOOP'): 12, ('END_IF', 'next', 'INLINE ASM'): 8, ('END_IF', 'next', 'NEW VARIABLE'): 287, ('END_IF', 'next', 'RETURN'): 203, ('END_IF', 'next', 'THROW'): 1, ('END_IF', 'next', '_'): 148, ('END_LOOP', 'next', 'BEGIN_LOOP'): 8, ('END_LOOP', 'next', 'END_IF'): 11, ('END_LOOP', 'next', 'EXPRESSION'): 117, ('END_LOOP', 'next', 'IF'): 28, ('END_LOOP', 'next', 'IF_LOOP'): 1, ('END_LOOP', 'next', 'INLINE ASM'): 2, ('END_LOOP', 'next', 'NEW VARIABLE'): 15, ('END_LOOP', 'next', 'RETURN'): 69, ('ENTRY_POINT', 'next', 'BEGIN_LOOP'): 1, ('ENTRY_POINT', 'next', 'EXPRESSION'): 4122, ('ENTRY_POINT', 'next', 'IF'): 955, ('ENTRY_POINT', 'next', 'INLINE ASM'): 26, ('ENTRY_POINT', 'next', 'NEW VARIABLE'): 798, ('ENTRY_POINT', 'next', 'RETURN'): 985, ('ENTRY_POINT', 'next', 'THROW'): 8, ('EXPRESSION', 'next', 'BEGIN_LOOP'): 77, ('EXPRESSION', 'next', 'BREAK'): 17, ('EXPRESSION', 'next', 'CONTINUE'): 4, ('EXPRESSION', 'next', 'END_IF'): 1660, ('EXPRESSION', 'next', 'EXPRESSION'): 8315, ('EXPRESSION', 'next', 'IF'): 633, ('EXPRESSION', 'next', 'IF_LOOP'): 343, ('EXPRESSION', 'next', 'INLINE ASM'): 10, ('EXPRESSION', 'next', 'NEW VARIABLE'): 761, ('EXPRESSION', 'next', 'RETURN'): 1222, ('EXPRESSION', 'next', 'THROW'): 3, ('EXPRESSION', 'next', '_'): 593, ('FUNCTION_NAME', 'next', 'ENTRY_POINT'): 7122, ('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT'): 271, ('IF', 'if_false', 'END_IF'): 2433, ('IF', 'if_false', 'EXPRESSION'): 342, ('IF', 'if_false', 'IF'): 212, ('IF', 'if_false', 'INLINE ASM'): 1, ('IF', 'if_false', 'NEW VARIABLE'): 28, ('IF', 'if_false', 'RETURN'): 263, ('IF', 'if_false', 'THROW'): 8, ('IF', 'if_false', '_'): 3, ('IF', 'if_true', 'BREAK'): 12, ('IF', 'if_true', 'CONTINUE'): 11, ('IF', 'if_true', 'END_IF'): 1, ('IF', 'if_true', 'EXPRESSION'): 1428, ('IF', 'if_true', 'IF'): 123, ('IF', 'if_true', 'INLINE ASM'): 6, ('IF', 'if_true', 'NEW VARIABLE'): 143, ('IF', 'if_true', 'RETURN'): 812, ('IF', 'if_true', 'THROW'): 697, ('IF', 'if_true', '_'): 57, ('IF_LOOP', 'if_false', 'END_LOOP'): 358, ('IF_LOOP', 'if_false', 'IF'): 1, ('IF_LOOP', 'if_true', 'BEGIN_LOOP'): 7, ('IF_LOOP', 'if_true', 'END_LOOP'): 1, ('IF_LOOP', 'if_true', 'EXPRESSION'): 192, ('IF_LOOP', 'if_true', 'IF'): 109, ('IF_LOOP', 'if_true', 'IF_LOOP'): 1, ('IF_LOOP', 'if_true', 'INLINE ASM'): 1, ('IF_LOOP', 'if_true', 'NEW VARIABLE'): 48, ('INLINE ASM', 'next', 'BEGIN_LOOP'): 2, ('INLINE ASM', 'next', 'END_IF'): 5, ('INLINE ASM', 'next', 'EXPRESSION'): 30, ('INLINE ASM', 'next', 'IF'): 13, ('INLINE ASM', 'next', 'IF_LOOP'): 2, ('INLINE ASM', 'next', 'NEW VARIABLE'): 3, ('INLINE ASM', 'next', 'RETURN'): 31, ('NEW VARIABLE', 'next', 'BEGIN_LOOP'): 260, ('NEW VARIABLE', 'next', 'EXPRESSION'): 971, ('NEW VARIABLE', 'next', 'IF'): 636, ('NEW VARIABLE', 'next', 'INLINE ASM'): 87, ('NEW VARIABLE', 'next', 'NEW VARIABLE'): 946, ('NEW VARIABLE', 'next', 'RETURN'): 129, ('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT'): 657, ('_', 'next', 'END_IF'): 62, ('_', 'next', 'EXPRESSION'): 9, ('_', 'next', 'IF'): 2},\n",
      "      metagraph=[('BEGIN_LOOP', 'EXPRESSION', 'next'), ('BEGIN_LOOP', 'IF_LOOP', 'next'), ('EXPRESSION', 'BEGIN_LOOP', 'next'), ('EXPRESSION', 'BREAK', 'next'), ('EXPRESSION', 'CONTINUE', 'next'), ('EXPRESSION', 'END_IF', 'next'), ('EXPRESSION', 'EXPRESSION', 'next'), ('EXPRESSION', 'IF', 'next'), ('EXPRESSION', 'IF_LOOP', 'next'), ('EXPRESSION', 'INLINE ASM', 'next'), ('EXPRESSION', 'NEW VARIABLE', 'next'), ('EXPRESSION', 'RETURN', 'next'), ('EXPRESSION', 'THROW', 'next'), ('EXPRESSION', '_', 'next'), ('IF_LOOP', 'END_LOOP', 'if_false'), ('IF_LOOP', 'END_LOOP', 'if_true'), ('IF_LOOP', 'IF', 'if_false'), ('IF_LOOP', 'IF', 'if_true'), ('IF_LOOP', 'BEGIN_LOOP', 'if_true'), ('IF_LOOP', 'EXPRESSION', 'if_true'), ('IF_LOOP', 'IF_LOOP', 'if_true'), ('IF_LOOP', 'INLINE ASM', 'if_true'), ('IF_LOOP', 'NEW VARIABLE', 'if_true'), ('BREAK', 'END_LOOP', 'next'), ('END_LOOP', 'BEGIN_LOOP', 'next'), ('END_LOOP', 'END_IF', 'next'), ('END_LOOP', 'EXPRESSION', 'next'), ('END_LOOP', 'IF', 'next'), ('END_LOOP', 'IF_LOOP', 'next'), ('END_LOOP', 'INLINE ASM', 'next'), ('END_LOOP', 'NEW VARIABLE', 'next'), ('END_LOOP', 'RETURN', 'next'), ('CONTINUE', 'BEGIN_LOOP', 'next'), ('END_IF', 'BEGIN_LOOP', 'next'), ('END_IF', 'END_IF', 'next'), ('END_IF', 'EXPRESSION', 'next'), ('END_IF', 'IF', 'next'), ('END_IF', 'IF_LOOP', 'next'), ('END_IF', 'INLINE ASM', 'next'), ('END_IF', 'NEW VARIABLE', 'next'), ('END_IF', 'RETURN', 'next'), ('END_IF', 'THROW', 'next'), ('END_IF', '_', 'next'), ('IF', 'END_IF', 'if_false'), ('IF', 'END_IF', 'if_true'), ('IF', 'EXPRESSION', 'if_false'), ('IF', 'EXPRESSION', 'if_true'), ('IF', 'IF', 'if_false'), ('IF', 'IF', 'if_true'), ('IF', 'INLINE ASM', 'if_false'), ('IF', 'INLINE ASM', 'if_true'), ('IF', 'NEW VARIABLE', 'if_false'), ('IF', 'NEW VARIABLE', 'if_true'), ('IF', 'RETURN', 'if_false'), ('IF', 'RETURN', 'if_true'), ('IF', 'THROW', 'if_false'), ('IF', 'THROW', 'if_true'), ('IF', '_', 'if_false'), ('IF', '_', 'if_true'), ('IF', 'BREAK', 'if_true'), ('IF', 'CONTINUE', 'if_true'), ('INLINE ASM', 'BEGIN_LOOP', 'next'), ('INLINE ASM', 'END_IF', 'next'), ('INLINE ASM', 'EXPRESSION', 'next'), ('INLINE ASM', 'IF', 'next'), ('INLINE ASM', 'IF_LOOP', 'next'), ('INLINE ASM', 'NEW VARIABLE', 'next'), ('INLINE ASM', 'RETURN', 'next'), ('NEW VARIABLE', 'BEGIN_LOOP', 'next'), ('NEW VARIABLE', 'EXPRESSION', 'next'), ('NEW VARIABLE', 'IF', 'next'), ('NEW VARIABLE', 'INLINE ASM', 'next'), ('NEW VARIABLE', 'NEW VARIABLE', 'next'), ('NEW VARIABLE', 'RETURN', 'next'), ('_', 'END_IF', 'next'), ('_', 'EXPRESSION', 'next'), ('_', 'IF', 'next'), ('ENTRY_POINT', 'BEGIN_LOOP', 'next'), ('ENTRY_POINT', 'EXPRESSION', 'next'), ('ENTRY_POINT', 'IF', 'next'), ('ENTRY_POINT', 'INLINE ASM', 'next'), ('ENTRY_POINT', 'NEW VARIABLE', 'next'), ('ENTRY_POINT', 'RETURN', 'next'), ('ENTRY_POINT', 'THROW', 'next'), ('FUNCTION_NAME', 'ENTRY_POINT', 'next'), ('FUNCTION_NAME', 'OTHER_ENTRYPOINT', 'next'), ('OTHER_ENTRYPOINT', 'OTHER_ENTRYPOINT', 'next')])\n",
      "['BEGIN_LOOP', 'BREAK', 'CONTINUE', 'END_IF', 'END_LOOP', 'ENTRY_POINT', 'EXPRESSION', 'FUNCTION_NAME', 'IF', 'IF_LOOP', 'INLINE ASM', 'NEW VARIABLE', 'OTHER_ENTRYPOINT', 'RETURN', 'THROW', '_'] 775924\n",
      "['next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'if_false', 'if_false', 'if_false', 'if_false', 'if_false', 'if_false', 'if_false', 'if_false', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_false', 'if_false', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'if_true', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next', 'next'] 42144\n"
     ]
    }
   ],
   "source": [
    "compressed_graph_path = './ge-sc/outputs/compress_graphs.gpickle'\n",
    "nx_graph = nx.read_gpickle(compressed_graph_path)\n",
    "# nx_graph, list_node_type = add_node_type_feature(nx_graph)\n",
    "# nx_graph, list_edge_type = add_edge_type_feature(nx_graph)\n",
    "nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
    "nx_g_data = generate_hetero_graph_data(nx_graph)\n",
    "dgl_hete_graph = dgl.heterograph(nx_g_data)\n",
    "print(dgl_hete_graph)\n",
    "print(dgl_hete_graph.ntypes, dgl_hete_graph.num_nodes())\n",
    "print(dgl_hete_graph.etypes, dgl_hete_graph.num_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36a182-ec1f-43a2-96ce-c4545c0290a0",
   "metadata": {},
   "source": [
    "## Get node types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d758c56b-b638-4abe-84c2-956c2d9439fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,\n",
       " ['BEGIN_LOOP',\n",
       "  'END_IF',\n",
       "  'FUNCTION_NAME',\n",
       "  'ENTRY_POINT',\n",
       "  '_',\n",
       "  'BREAK',\n",
       "  'END_LOOP',\n",
       "  'INLINE ASM',\n",
       "  'CONTINUE',\n",
       "  'EXPRESSION',\n",
       "  'OTHER_ENTRYPOINT',\n",
       "  'RETURN',\n",
       "  'THROW',\n",
       "  'NEW VARIABLE',\n",
       "  'IF',\n",
       "  'IF_LOOP'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntypes = list(set([e[0] for e in meta_path_types] + [e[2] for e in meta_path_types]))\n",
    "len(ntypes), ntypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ab8bd2-8732-4fdb-9440-9b8058fbee28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'BEGIN_LOOP': 0,\n",
       "  'END_IF': 1,\n",
       "  'FUNCTION_NAME': 2,\n",
       "  'ENTRY_POINT': 3,\n",
       "  '_': 4,\n",
       "  'BREAK': 5,\n",
       "  'END_LOOP': 6,\n",
       "  'INLINE ASM': 7,\n",
       "  'CONTINUE': 8,\n",
       "  'EXPRESSION': 9,\n",
       "  'OTHER_ENTRYPOINT': 10,\n",
       "  'RETURN': 11,\n",
       "  'THROW': 12,\n",
       "  'NEW VARIABLE': 13,\n",
       "  'IF': 14,\n",
       "  'IF_LOOP': 15},\n",
       " 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntypes_dict = {k: v for v, k in enumerate(ntypes)}\n",
    "ntypes_dict, len(ntypes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8642f5-6fcb-40d1-9260-07fc09f1ab9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'BEGIN_LOOP': Ellipsis,\n",
       "  'END_IF': Ellipsis,\n",
       "  'FUNCTION_NAME': Ellipsis,\n",
       "  'ENTRY_POINT': Ellipsis,\n",
       "  '_': Ellipsis,\n",
       "  'BREAK': Ellipsis,\n",
       "  'END_LOOP': Ellipsis,\n",
       "  'INLINE ASM': Ellipsis,\n",
       "  'CONTINUE': Ellipsis,\n",
       "  'EXPRESSION': Ellipsis,\n",
       "  'OTHER_ENTRYPOINT': Ellipsis,\n",
       "  'RETURN': Ellipsis,\n",
       "  'THROW': Ellipsis,\n",
       "  'NEW VARIABLE': Ellipsis,\n",
       "  'IF': Ellipsis,\n",
       "  'IF_LOOP': Ellipsis},\n",
       " 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntypes_dest_dict = {k: ... for k in ntypes}\n",
    "ntypes_dest_dict, len(ntypes_dest_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89c285d9-8700-4485-a50a-07053aaa19c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nodetype2onehot(ntype, ntypes_dicts):\n",
    "    feature = torch.zeros(len(ntypes_dicts), dtype=torch.float)\n",
    "    feature[ntypes_dicts[ntype]] = 1\n",
    "    return feature\n",
    "nodetype2onehot('FUNCTION_NAME', ntypes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1c17b-05b9-4a93-8a76-c479afcecadb",
   "metadata": {},
   "source": [
    "## GET edge types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9531221-1843-416b-8274-41416fa9102b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, ['next', 'if_false', 'if_true'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etypes = list(set([e[1] for e in meta_path_types]))\n",
    "len(etypes), etypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ede6e-b9fb-4682-b2d2-0cb0e1afca8b",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f9bf5a6-a569-4f1d-98a8-3771417d125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_path = './datasets/Etherscan_Contract/extracted_graph'\n",
    "pickle_files = sorted(sorted([f for f in os.listdir(pickle_path) if f.endswith('.gpickle')]), key=len)\n",
    "len(pickle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5202cd36-bd6f-44a4-8300-07b7de77620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_g_data = add_full_metapath(nx_g_data, meta_path_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167a2b0b-c971-447b-b132-dbe709b58bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_path = './datasets/Etherscan_Contract/Reentrancy_AutoExtract_corenodes.json'\n",
    "with open(label_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "label_dict = {}\n",
    "for l in content:\n",
    "    sc = json.loads(l.strip('\\n').strip(','))\n",
    "    label_dict[sc['contract_name']] = sc['targets']\n",
    "label_dict['No_Reentrance.sol'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3025a43a-fcf0-4602-844c-f6006826de59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b750a4d7-61a0-4463-87c5-98f253846835",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Cannot assign node feature \"feat\" on device cpu to a graph on device cuda:0. Call DGLGraph.to() to copy the graph to the same device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40384/4190698078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mEthdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEtherumSmartContract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_40384/4190698078.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, raw_dir, force_reload, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                           \u001b[0mraw_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                           \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                           verbose=verbose)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/dgl/data/dgl_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, url, raw_dir, save_dir, hash_key, force_reload, verbose)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/dgl/data/dgl_dataset.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mload_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_40384/4190698078.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_40384/4190698078.py\u001b[0m in \u001b[0;36m_load_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#                 h_data[ntype] = torch.tensor([], dtype=torch.int64).repeat(dgl_hete_graph.num_nodes(ntype), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mdgl_hete_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#             dgl_hete_graph.ndata['h'] = h_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgl_hete_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/dgl/view.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mntid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ntype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m_set_n_repr\u001b[0;34m(self, ntid, u, data)\u001b[0m\n\u001b[1;32m   4113\u001b[0m                 raise DGLError('Cannot assign node feature \"{}\" on device {} to a graph on'\n\u001b[1;32m   4114\u001b[0m                                \u001b[0;34m' device {}. Call DGLGraph.to() to copy the graph to the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                                ' same device.'.format(key, F.context(val), self.device))\n\u001b[0m\u001b[1;32m   4116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: Cannot assign node feature \"feat\" on device cpu to a graph on device cuda:0. Call DGLGraph.to() to copy the graph to the same device."
     ]
    }
   ],
   "source": [
    "\"\"\"QM7b dataset for graph property prediction (regression).\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "\n",
    "class EtherumSmartContract(DGLDataset):\n",
    "    _url = 'http://deepchem.io.s3-website-us-west-1.amazonaws.com/' \\\n",
    "           'datasets/qm7b.mat'\n",
    "    _sha1_str = '4102c744bb9d6fd7b40ac67a300e49cd87e28392'\n",
    "    _label = './datasets/Etherscan_Contract/Reentrancy_AutoExtract_corenodes.json'\n",
    "    _data_path = './datasets/Etherscan_Contract/extracted_graph'\n",
    "\n",
    "    def __init__(self, raw_dir=None, force_reload=False, verbose=False):\n",
    "        super(EtherumSmartContract, self).__init__(name='ethsc',\n",
    "                                          url=self._url,\n",
    "                                          raw_dir=raw_dir,\n",
    "                                          force_reload=force_reload,\n",
    "                                          verbose=verbose)\n",
    "\n",
    "    def process(self):\n",
    "        self.graphs, self.label = self._load_graph()\n",
    "\n",
    "    def _load_graph(self):\n",
    "        extracted_graph = [f for f in os.listdir(self._data_path) if f.endswith('.gpickle')]\n",
    "        num_graphs = len(extracted_graph)\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        for i in range(num_graphs):\n",
    "            nx_graph = nx.read_gpickle(join(self._data_path, extracted_graph[i]))\n",
    "            nx_graph, list_node_type = add_node_type_feature(nx_graph)\n",
    "            nx_graph, list_edge_type = add_edge_type_feature(nx_graph)\n",
    "            nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
    "            nx_g_data = generate_hetero_graph_data(nx_graph)\n",
    "            geo_g_data = {}\n",
    "            for k, v in nx_g_data.items():\n",
    "                geo_g_data[k] = torch.stack(list(v), dim=0)\n",
    "            \n",
    "            for k, v in geo_g_data.items():\n",
    "                if len(v[0]) == 0:\n",
    "                    print(k)\n",
    "            \n",
    "            geo_meta_path_types = list(geo_g_data.keys())\n",
    "            bidirect_geo_meta_path_types = geo_meta_path_types + [t[::-1] for t in geo_meta_path_types[::-1]]\n",
    "            \n",
    "            metapath_embedding = MetaPath2Vec(geo_g_data, embedding_dim=128,\n",
    "                     metapath=bidirect_geo_meta_path_types, walk_length=2, context_size=2,\n",
    "                     walks_per_node=1, num_negative_samples=1, num_nodes_dict=None,\n",
    "                     sparse=True).to(device).eval()\n",
    "            \n",
    "            nx_g_data = add_full_metapath(nx_g_data, meta_path_types)\n",
    "            dgl_hete_graph = dgl.heterograph(nx_g_data).to(device)\n",
    "            feature_data = {}\n",
    "            h_data = {}\n",
    "            \n",
    "            for ntype in dgl_hete_graph.ntypes:\n",
    "                feature_data[ntype] = nodetype2onehot(ntype, ntypes_dict).repeat(dgl_hete_graph.num_nodes(ntype), 1)\n",
    "#                 if ntype in list(metapath_embedding.num_nodes_dict.keys()):\n",
    "#                     feature_data[ntype] = metapath_embedding(ntype)\n",
    "#                 else:\n",
    "#                     feature_data[ntype] = torch.zeros((dgl_hete_graph.num_nodes(ntype), 128), device='cuda')\n",
    "#                 h_data[ntype] = torch.tensor([], dtype=torch.int64).repeat(dgl_hete_graph.num_nodes(ntype), 1)\n",
    "                \n",
    "            dgl_hete_graph.ndata['feat'] = feature_data\n",
    "#             dgl_hete_graph.ndata['h'] = h_data\n",
    "            graphs.append(dgl_hete_graph)\n",
    "            labels.append(int(label_dict[extracted_graph[i].replace('.gpickle', '.sol')]))\n",
    "        labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "#         print(graphs[0].ndata)\n",
    "        return graphs, labels\n",
    "\n",
    "\n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "Ethdataset = EtherumSmartContract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e6a75-4e99-4151-ac58-f3deecc7df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dgl.data\n",
    "# dataset = dgl.data.GINDataset('MUTAG', False)\n",
    "\n",
    "dataloader = GraphDataLoader(\n",
    "    Ethdataset,\n",
    "    batch_size=8,\n",
    "    drop_last=False,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d61f8d-bbbe-405c-ba9e-96f9d879f729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batched_graph, labels in dataloader:\n",
    "    for k, v in batched_graph.ndata['feat'].items():\n",
    "        print(k, v.get_device())\n",
    "    print(len(batched_graph.ndata['feat'].items()))\n",
    "    for k, v in batched_graph.ndata['feat'].items():\n",
    "        print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a9fe2-9d39-4cfe-a4ba-c99a3f19e844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs is features of nodes\n",
    "#         print(inputs.get_device())\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "\n",
    "class HeteroClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes, rel_names):\n",
    "        super().__init__()\n",
    "        self.rgcn = RGCN(in_dim, hidden_dim, hidden_dim, rel_names)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        h = g.ndata['feat']\n",
    "        h = self.rgcn(g, h)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Calculate graph representation by average readout.\n",
    "            hg = 0\n",
    "            for ntype in h.keys():\n",
    "                hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "            return self.classify(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f1d6b-0dc5-4ea7-a137-c9a35c283a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).sum().item() / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd145c7a-8664-47a9-b9a8-d6cde36ed67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6078fa1-6232-47e1-83bb-ac170b112d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = './ge-sc/logs/MetaPath2Vec_ConvHete'\n",
    "writer = SummaryWriter(tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "992cce5c-a820-4e81-b1e8-db32297f556f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.598901 - train_acc: 0.708333\n",
      "train_loss: 0.572211 - train_acc: 0.717391\n",
      "train_loss: 0.554274 - train_acc: 0.722826\n",
      "train_loss: 0.545845 - train_acc: 0.722826\n",
      "train_loss: 0.531457 - train_acc: 0.735507\n",
      "train_loss: 0.511614 - train_acc: 0.744565\n",
      "train_loss: 0.503671 - train_acc: 0.755435\n",
      "train_loss: 0.494461 - train_acc: 0.771739\n",
      "train_loss: 0.476461 - train_acc: 0.811594\n",
      "train_loss: 0.451947 - train_acc: 0.847826\n",
      "train_loss: 0.452879 - train_acc: 0.833333\n",
      "train_loss: 0.471005 - train_acc: 0.826087\n",
      "train_loss: 0.407677 - train_acc: 0.849638\n",
      "train_loss: 0.401293 - train_acc: 0.864130\n",
      "train_loss: 0.395225 - train_acc: 0.849638\n",
      "train_loss: 0.383232 - train_acc: 0.864130\n",
      "train_loss: 0.359902 - train_acc: 0.869565\n",
      "train_loss: 0.357986 - train_acc: 0.875000\n",
      "train_loss: 0.334401 - train_acc: 0.880435\n",
      "train_loss: 0.320253 - train_acc: 0.885870\n",
      "train_loss: 0.322470 - train_acc: 0.882246\n",
      "train_loss: 0.297752 - train_acc: 0.896739\n",
      "train_loss: 0.302313 - train_acc: 0.896739\n",
      "train_loss: 0.274552 - train_acc: 0.896739\n",
      "train_loss: 0.278119 - train_acc: 0.893116\n",
      "train_loss: 0.259146 - train_acc: 0.907609\n",
      "train_loss: 0.248757 - train_acc: 0.902174\n",
      "train_loss: 0.238827 - train_acc: 0.913043\n",
      "train_loss: 0.234953 - train_acc: 0.902174\n",
      "train_loss: 0.223665 - train_acc: 0.923913\n",
      "train_loss: 0.220403 - train_acc: 0.920290\n",
      "train_loss: 0.210919 - train_acc: 0.940217\n",
      "train_loss: 0.194081 - train_acc: 0.940217\n",
      "train_loss: 0.181906 - train_acc: 0.940217\n",
      "train_loss: 0.178289 - train_acc: 0.940217\n",
      "train_loss: 0.173424 - train_acc: 0.940217\n",
      "train_loss: 0.172317 - train_acc: 0.951087\n",
      "train_loss: 0.170044 - train_acc: 0.936594\n",
      "train_loss: 0.150278 - train_acc: 0.940217\n",
      "train_loss: 0.146283 - train_acc: 0.956522\n",
      "train_loss: 0.131502 - train_acc: 0.951087\n",
      "train_loss: 0.129307 - train_acc: 0.956522\n",
      "train_loss: 0.135086 - train_acc: 0.947464\n",
      "train_loss: 0.122628 - train_acc: 0.952899\n",
      "train_loss: 0.112652 - train_acc: 0.967391\n",
      "train_loss: 0.105000 - train_acc: 0.956522\n",
      "train_loss: 0.099764 - train_acc: 0.967391\n",
      "train_loss: 0.096273 - train_acc: 0.967391\n",
      "train_loss: 0.087459 - train_acc: 0.972826\n",
      "train_loss: 0.086718 - train_acc: 0.972826\n",
      "train_loss: 0.086373 - train_acc: 0.967391\n",
      "train_loss: 0.077301 - train_acc: 0.972826\n",
      "train_loss: 0.071527 - train_acc: 0.978261\n",
      "train_loss: 0.071942 - train_acc: 0.989130\n",
      "train_loss: 0.074374 - train_acc: 0.972826\n",
      "train_loss: 0.064153 - train_acc: 0.978261\n",
      "train_loss: 0.060201 - train_acc: 0.983696\n",
      "train_loss: 0.059825 - train_acc: 0.983696\n",
      "train_loss: 0.054298 - train_acc: 0.989130\n",
      "train_loss: 0.052056 - train_acc: 0.989130\n",
      "train_loss: 0.050636 - train_acc: 0.983696\n",
      "train_loss: 0.041527 - train_acc: 0.989130\n",
      "train_loss: 0.048956 - train_acc: 0.989130\n",
      "train_loss: 0.042319 - train_acc: 0.989130\n",
      "train_loss: 0.039711 - train_acc: 0.994565\n",
      "train_loss: 0.037294 - train_acc: 0.989130\n",
      "train_loss: 0.033100 - train_acc: 1.000000\n",
      "train_loss: 0.032686 - train_acc: 0.989130\n",
      "train_loss: 0.032055 - train_acc: 0.989130\n",
      "train_loss: 0.030999 - train_acc: 0.994565\n",
      "train_loss: 0.028313 - train_acc: 1.000000\n",
      "train_loss: 0.027295 - train_acc: 0.994565\n",
      "train_loss: 0.025742 - train_acc: 1.000000\n",
      "train_loss: 0.025686 - train_acc: 1.000000\n",
      "train_loss: 0.021992 - train_acc: 1.000000\n",
      "train_loss: 0.025742 - train_acc: 1.000000\n",
      "train_loss: 0.021178 - train_acc: 1.000000\n",
      "train_loss: 0.020486 - train_acc: 1.000000\n",
      "train_loss: 0.023551 - train_acc: 1.000000\n",
      "train_loss: 0.018985 - train_acc: 1.000000\n",
      "train_loss: 0.016953 - train_acc: 1.000000\n",
      "train_loss: 0.015346 - train_acc: 1.000000\n",
      "train_loss: 0.015702 - train_acc: 1.000000\n",
      "train_loss: 0.013368 - train_acc: 1.000000\n",
      "train_loss: 0.013313 - train_acc: 1.000000\n",
      "train_loss: 0.012605 - train_acc: 1.000000\n",
      "train_loss: 0.011891 - train_acc: 1.000000\n",
      "train_loss: 0.012187 - train_acc: 1.000000\n",
      "train_loss: 0.011149 - train_acc: 1.000000\n",
      "train_loss: 0.010486 - train_acc: 1.000000\n",
      "train_loss: 0.010145 - train_acc: 1.000000\n",
      "train_loss: 0.009381 - train_acc: 1.000000\n",
      "train_loss: 0.009063 - train_acc: 1.000000\n",
      "train_loss: 0.008781 - train_acc: 1.000000\n",
      "train_loss: 0.008469 - train_acc: 1.000000\n",
      "train_loss: 0.008135 - train_acc: 1.000000\n",
      "train_loss: 0.008416 - train_acc: 1.000000\n",
      "train_loss: 0.007677 - train_acc: 1.000000\n",
      "train_loss: 0.007762 - train_acc: 1.000000\n",
      "train_loss: 0.007689 - train_acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# etypes is the list of edge types as strings.\n",
    "model = HeteroClassifier(128, 32, 2, etypes).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(),  lr=0.0005)\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    train_acc = 0\n",
    "    steps = 0\n",
    "    for idx, (batched_graph, labels) in enumerate(dataloader):\n",
    "        logits = model(batched_graph)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        train_acc += accuracy(preds, labels)\n",
    "        loss = cross_entropy(logits, labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "        steps += 1\n",
    "    print('train_loss: {:4f} - train_acc: {:4f}'.format(total_loss/steps, train_acc/steps))\n",
    "#     writer.add_scalar('Loss/train', total_loss/steps, epoch)\n",
    "#     writer.add_scalar('Accuracy/train', train_acc/steps, epoch)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912cf43-f046-4bb6-a069-21fbb6b7e8ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "37d3dcd3-08b1-4ef7-bf1a-85c565aea924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "1cde8cff-d13a-449b-8927-24c3bbec669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542e039-fb59-4615-a26b-756a52e33291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = GraphDataLoader(\n",
    "    Ethdataset,\n",
    "    batch_size=8,\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    sampler=test_subsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a32762be-eee0-4078-b55f-2373fc2b0457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "26abaa4a-39e7-47de-8e31-02a5dec91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3dcaf973-3f10-4cb9-8b73-18e35ae0f9ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training fold 0 with 2/1 train/test smart contracts\n",
      "Fold 0 - Epochs 0\n",
      "train_loss: 0.689472 - train_acc: 0.497135\n",
      "valid_loss: 0.645526 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 1\n",
      "train_loss: 0.670638 - train_acc: 0.594531\n",
      "valid_loss: 0.615289 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 2\n",
      "train_loss: 0.602128 - train_acc: 0.722135\n",
      "valid_loss: 0.587283 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 3\n",
      "train_loss: 0.571964 - train_acc: 0.755469\n",
      "valid_loss: 0.565639 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 4\n",
      "train_loss: 0.520351 - train_acc: 0.751563\n",
      "valid_loss: 0.562791 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 5\n",
      "train_loss: 0.544928 - train_acc: 0.747656\n",
      "valid_loss: 0.581348 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 6\n",
      "train_loss: 0.545777 - train_acc: 0.747656\n",
      "valid_loss: 0.602942 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 7\n",
      "train_loss: 0.538961 - train_acc: 0.747656\n",
      "valid_loss: 0.605368 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 8\n",
      "train_loss: 0.644893 - train_acc: 0.688802\n",
      "valid_loss: 0.578208 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 9\n",
      "train_loss: 0.638002 - train_acc: 0.629948\n",
      "valid_loss: 0.552083 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 10\n",
      "train_loss: 0.524817 - train_acc: 0.771094\n",
      "valid_loss: 0.579727 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 11\n",
      "train_loss: 0.549183 - train_acc: 0.743490\n",
      "valid_loss: 0.607489 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 12\n",
      "train_loss: 0.517310 - train_acc: 0.925781\n",
      "valid_loss: 0.565766 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 13\n",
      "train_loss: 0.502601 - train_acc: 0.796354\n",
      "valid_loss: 0.549848 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 14\n",
      "train_loss: 0.474541 - train_acc: 0.802344\n",
      "valid_loss: 0.571580 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 15\n",
      "train_loss: 0.465683 - train_acc: 0.765104\n",
      "valid_loss: 0.559606 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 16\n",
      "train_loss: 0.446539 - train_acc: 0.802344\n",
      "valid_loss: 0.559595 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 17\n",
      "train_loss: 0.463063 - train_acc: 0.845313\n",
      "valid_loss: 0.593104 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 18\n",
      "train_loss: 0.381385 - train_acc: 0.904167\n",
      "valid_loss: 0.577965 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 19\n",
      "train_loss: 0.392917 - train_acc: 0.874740\n",
      "valid_loss: 0.596927 - valid_acc: 0.750000\n",
      "Fold 0 - Epochs 20\n",
      "train_loss: 0.318157 - train_acc: 0.904167\n",
      "valid_loss: 0.613406 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 21\n",
      "train_loss: 0.337342 - train_acc: 0.904167\n",
      "valid_loss: 0.627638 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 22\n",
      "train_loss: 0.322963 - train_acc: 0.874740\n",
      "valid_loss: 0.642982 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 23\n",
      "train_loss: 0.233511 - train_acc: 0.941406\n",
      "valid_loss: 0.663309 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 24\n",
      "train_loss: 0.291355 - train_acc: 0.882552\n",
      "valid_loss: 0.695132 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 25\n",
      "train_loss: 0.222612 - train_acc: 0.911979\n",
      "valid_loss: 0.722339 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 26\n",
      "train_loss: 0.236839 - train_acc: 0.915885\n",
      "valid_loss: 0.762241 - valid_acc: 0.722222\n",
      "Fold 0 - Epochs 27\n",
      "train_loss: 0.238906 - train_acc: 0.927604\n",
      "valid_loss: 0.805572 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 28\n",
      "train_loss: 0.177393 - train_acc: 0.939323\n",
      "valid_loss: 0.844976 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 29\n",
      "train_loss: 0.159685 - train_acc: 0.909896\n",
      "valid_loss: 0.882998 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 30\n",
      "train_loss: 0.129042 - train_acc: 0.976562\n",
      "valid_loss: 0.984279 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 31\n",
      "train_loss: 0.209689 - train_acc: 0.905990\n",
      "valid_loss: 0.948035 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 32\n",
      "train_loss: 0.125099 - train_acc: 0.984375\n",
      "valid_loss: 0.975224 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 33\n",
      "train_loss: 0.068291 - train_acc: 0.996094\n",
      "valid_loss: 1.262883 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 34\n",
      "train_loss: 0.119740 - train_acc: 0.960938\n",
      "valid_loss: 1.119019 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 35\n",
      "train_loss: 0.077175 - train_acc: 0.980469\n",
      "valid_loss: 1.048679 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 36\n",
      "train_loss: 0.099659 - train_acc: 0.996094\n",
      "valid_loss: 1.140581 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 37\n",
      "train_loss: 0.039143 - train_acc: 0.984375\n",
      "valid_loss: 1.246073 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 38\n",
      "train_loss: 0.043995 - train_acc: 0.980469\n",
      "valid_loss: 1.174721 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 39\n",
      "train_loss: 0.035218 - train_acc: 0.988281\n",
      "valid_loss: 1.172904 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 40\n",
      "train_loss: 0.031045 - train_acc: 1.000000\n",
      "valid_loss: 1.243248 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 41\n",
      "train_loss: 0.028376 - train_acc: 0.996094\n",
      "valid_loss: 1.349325 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 42\n",
      "train_loss: 0.022655 - train_acc: 0.984375\n",
      "valid_loss: 1.387727 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 43\n",
      "train_loss: 0.024063 - train_acc: 0.988281\n",
      "valid_loss: 1.368263 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 44\n",
      "train_loss: 0.014567 - train_acc: 1.000000\n",
      "valid_loss: 1.392203 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 45\n",
      "train_loss: 0.022636 - train_acc: 1.000000\n",
      "valid_loss: 1.407430 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 46\n",
      "train_loss: 0.018809 - train_acc: 1.000000\n",
      "valid_loss: 1.439429 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 47\n",
      "train_loss: 0.020176 - train_acc: 1.000000\n",
      "valid_loss: 1.502698 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 48\n",
      "train_loss: 0.014033 - train_acc: 1.000000\n",
      "valid_loss: 1.580908 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 49\n",
      "train_loss: 0.020650 - train_acc: 1.000000\n",
      "valid_loss: 1.628988 - valid_acc: 0.638889\n",
      "Fold 0 - Epochs 50\n",
      "train_loss: 0.011136 - train_acc: 1.000000\n",
      "valid_loss: 1.610910 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 51\n",
      "train_loss: 0.009068 - train_acc: 1.000000\n",
      "valid_loss: 1.608662 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 52\n",
      "train_loss: 0.013615 - train_acc: 1.000000\n",
      "valid_loss: 1.625314 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 53\n",
      "train_loss: 0.014421 - train_acc: 1.000000\n",
      "valid_loss: 1.659872 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 54\n",
      "train_loss: 0.019519 - train_acc: 1.000000\n",
      "valid_loss: 1.695168 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 55\n",
      "train_loss: 0.007664 - train_acc: 1.000000\n",
      "valid_loss: 1.704013 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 56\n",
      "train_loss: 0.010895 - train_acc: 1.000000\n",
      "valid_loss: 1.709275 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 57\n",
      "train_loss: 0.006777 - train_acc: 1.000000\n",
      "valid_loss: 1.716512 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 58\n",
      "train_loss: 0.007143 - train_acc: 1.000000\n",
      "valid_loss: 1.732722 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 59\n",
      "train_loss: 0.006301 - train_acc: 1.000000\n",
      "valid_loss: 1.754278 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 60\n",
      "train_loss: 0.004970 - train_acc: 1.000000\n",
      "valid_loss: 1.773268 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 61\n",
      "train_loss: 0.005024 - train_acc: 1.000000\n",
      "valid_loss: 1.792568 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 62\n",
      "train_loss: 0.006063 - train_acc: 1.000000\n",
      "valid_loss: 1.807675 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 63\n",
      "train_loss: 0.004486 - train_acc: 1.000000\n",
      "valid_loss: 1.817623 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 64\n",
      "train_loss: 0.004778 - train_acc: 1.000000\n",
      "valid_loss: 1.826106 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 65\n",
      "train_loss: 0.010291 - train_acc: 1.000000\n",
      "valid_loss: 1.830110 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 66\n",
      "train_loss: 0.005131 - train_acc: 1.000000\n",
      "valid_loss: 1.830492 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 67\n",
      "train_loss: 0.004074 - train_acc: 1.000000\n",
      "valid_loss: 1.831409 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 68\n",
      "train_loss: 0.007493 - train_acc: 1.000000\n",
      "valid_loss: 1.832373 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 69\n",
      "train_loss: 0.005884 - train_acc: 1.000000\n",
      "valid_loss: 1.833328 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 70\n",
      "train_loss: 0.007074 - train_acc: 1.000000\n",
      "valid_loss: 1.834223 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 71\n",
      "train_loss: 0.004474 - train_acc: 1.000000\n",
      "valid_loss: 1.834823 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 72\n",
      "train_loss: 0.008599 - train_acc: 1.000000\n",
      "valid_loss: 1.835011 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 73\n",
      "train_loss: 0.006461 - train_acc: 1.000000\n",
      "valid_loss: 1.835335 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 74\n",
      "train_loss: 0.005411 - train_acc: 1.000000\n",
      "valid_loss: 1.835557 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 75\n",
      "train_loss: 0.005833 - train_acc: 1.000000\n",
      "valid_loss: 1.835952 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 76\n",
      "train_loss: 0.004075 - train_acc: 1.000000\n",
      "valid_loss: 1.836276 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 77\n",
      "train_loss: 0.008981 - train_acc: 1.000000\n",
      "valid_loss: 1.836443 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 78\n",
      "train_loss: 0.004078 - train_acc: 1.000000\n",
      "valid_loss: 1.836557 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 79\n",
      "train_loss: 0.006150 - train_acc: 1.000000\n",
      "valid_loss: 1.836562 - valid_acc: 0.611111\n",
      "Saving model fold 0\n",
      "Start training fold 1 with 2/1 train/test smart contracts\n",
      "Fold 1 - Epochs 0\n",
      "train_loss: 0.589510 - train_acc: 0.747656\n",
      "valid_loss: 0.571107 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 1\n",
      "train_loss: 0.620286 - train_acc: 0.688802\n",
      "valid_loss: 0.557887 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 2\n",
      "train_loss: 0.579973 - train_acc: 0.718229\n",
      "valid_loss: 0.551202 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 3\n",
      "train_loss: 0.539527 - train_acc: 0.747656\n",
      "valid_loss: 0.552000 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 4\n",
      "train_loss: 0.746098 - train_acc: 0.571094\n",
      "valid_loss: 0.553001 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 5\n",
      "train_loss: 0.609288 - train_acc: 0.688802\n",
      "valid_loss: 0.546023 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 6\n",
      "train_loss: 0.537646 - train_acc: 0.747656\n",
      "valid_loss: 0.542154 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 7\n",
      "train_loss: 0.603750 - train_acc: 0.667188\n",
      "valid_loss: 0.542869 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 8\n",
      "train_loss: 0.562715 - train_acc: 0.729948\n",
      "valid_loss: 0.546085 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 9\n",
      "train_loss: 0.560759 - train_acc: 0.737760\n",
      "valid_loss: 0.536960 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 10\n",
      "train_loss: 0.539653 - train_acc: 0.745573\n",
      "valid_loss: 0.522834 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 11\n",
      "train_loss: 0.515521 - train_acc: 0.745573\n",
      "valid_loss: 0.523001 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 12\n",
      "train_loss: 0.470928 - train_acc: 0.745573\n",
      "valid_loss: 0.521618 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 13\n",
      "train_loss: 0.441383 - train_acc: 0.841667\n",
      "valid_loss: 0.513067 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 14\n",
      "train_loss: 0.537732 - train_acc: 0.717969\n",
      "valid_loss: 0.504204 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 15\n",
      "train_loss: 0.491028 - train_acc: 0.759115\n",
      "valid_loss: 0.609900 - valid_acc: 0.694444\n",
      "Fold 1 - Epochs 16\n",
      "train_loss: 0.436840 - train_acc: 0.906250\n",
      "valid_loss: 0.528561 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 17\n",
      "train_loss: 0.398287 - train_acc: 0.888542\n",
      "valid_loss: 0.640277 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 18\n",
      "train_loss: 0.375151 - train_acc: 0.888542\n",
      "valid_loss: 0.509705 - valid_acc: 0.694444\n",
      "Fold 1 - Epochs 19\n",
      "train_loss: 0.368544 - train_acc: 0.863021\n",
      "valid_loss: 0.530754 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 20\n",
      "train_loss: 0.351391 - train_acc: 0.908073\n",
      "valid_loss: 0.537058 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 21\n",
      "train_loss: 0.448042 - train_acc: 0.811979\n",
      "valid_loss: 0.523016 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 22\n",
      "train_loss: 0.262977 - train_acc: 0.904167\n",
      "valid_loss: 0.676744 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 23\n",
      "train_loss: 0.303744 - train_acc: 0.902083\n",
      "valid_loss: 0.637086 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 24\n",
      "train_loss: 0.323890 - train_acc: 0.866927\n",
      "valid_loss: 0.646575 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 25\n",
      "train_loss: 0.222458 - train_acc: 0.933594\n",
      "valid_loss: 0.591546 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 26\n",
      "train_loss: 0.211471 - train_acc: 0.935417\n",
      "valid_loss: 0.601470 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 27\n",
      "train_loss: 0.147265 - train_acc: 0.960938\n",
      "valid_loss: 0.662091 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 28\n",
      "train_loss: 0.243643 - train_acc: 0.894271\n",
      "valid_loss: 0.642318 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 29\n",
      "train_loss: 0.201763 - train_acc: 0.921615\n",
      "valid_loss: 0.998588 - valid_acc: 0.416667\n",
      "Fold 1 - Epochs 30\n",
      "train_loss: 0.257262 - train_acc: 0.872917\n",
      "valid_loss: 0.813459 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 31\n",
      "train_loss: 0.126725 - train_acc: 0.949219\n",
      "valid_loss: 1.006318 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 32\n",
      "train_loss: 0.183711 - train_acc: 0.933594\n",
      "valid_loss: 0.730367 - valid_acc: 0.694444\n",
      "Fold 1 - Epochs 33\n",
      "train_loss: 0.138516 - train_acc: 0.935417\n",
      "valid_loss: 0.851691 - valid_acc: 0.611111\n",
      "Fold 1 - Epochs 34\n",
      "train_loss: 0.134856 - train_acc: 0.988281\n",
      "valid_loss: 0.661830 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 35\n",
      "train_loss: 0.056195 - train_acc: 0.988281\n",
      "valid_loss: 0.806985 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 36\n",
      "train_loss: 0.096362 - train_acc: 0.964844\n",
      "valid_loss: 0.811070 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 37\n",
      "train_loss: 0.074291 - train_acc: 0.964844\n",
      "valid_loss: 0.697335 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 38\n",
      "train_loss: 0.065019 - train_acc: 0.988281\n",
      "valid_loss: 0.733766 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 39\n",
      "train_loss: 0.048168 - train_acc: 0.992188\n",
      "valid_loss: 0.730065 - valid_acc: 0.722222\n",
      "Fold 1 - Epochs 40\n",
      "train_loss: 0.048967 - train_acc: 0.988281\n",
      "valid_loss: 0.766617 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 41\n",
      "train_loss: 0.034961 - train_acc: 0.988281\n",
      "valid_loss: 0.770626 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 42\n",
      "train_loss: 0.067469 - train_acc: 0.958854\n",
      "valid_loss: 0.772207 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 43\n",
      "train_loss: 0.051570 - train_acc: 0.996094\n",
      "valid_loss: 0.819287 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 44\n",
      "train_loss: 0.038925 - train_acc: 1.000000\n",
      "valid_loss: 0.814378 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 45\n",
      "train_loss: 0.032085 - train_acc: 1.000000\n",
      "valid_loss: 0.844604 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 46\n",
      "train_loss: 0.044852 - train_acc: 0.958854\n",
      "valid_loss: 0.915895 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 47\n",
      "train_loss: 0.026066 - train_acc: 0.988281\n",
      "valid_loss: 0.908922 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 48\n",
      "train_loss: 0.036786 - train_acc: 0.996094\n",
      "valid_loss: 0.869212 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 49\n",
      "train_loss: 0.031681 - train_acc: 1.000000\n",
      "valid_loss: 0.875369 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 50\n",
      "train_loss: 0.023782 - train_acc: 1.000000\n",
      "valid_loss: 0.884374 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 51\n",
      "train_loss: 0.018060 - train_acc: 1.000000\n",
      "valid_loss: 0.895381 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 52\n",
      "train_loss: 0.010980 - train_acc: 1.000000\n",
      "valid_loss: 0.941774 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 53\n",
      "train_loss: 0.010928 - train_acc: 1.000000\n",
      "valid_loss: 0.984533 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 54\n",
      "train_loss: 0.012303 - train_acc: 0.996094\n",
      "valid_loss: 1.005959 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 55\n",
      "train_loss: 0.013787 - train_acc: 0.996094\n",
      "valid_loss: 1.004840 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 56\n",
      "train_loss: 0.012389 - train_acc: 0.996094\n",
      "valid_loss: 0.986504 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 57\n",
      "train_loss: 0.013142 - train_acc: 0.996094\n",
      "valid_loss: 0.966455 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 58\n",
      "train_loss: 0.010859 - train_acc: 1.000000\n",
      "valid_loss: 0.951734 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 59\n",
      "train_loss: 0.009850 - train_acc: 1.000000\n",
      "valid_loss: 0.942957 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 60\n",
      "train_loss: 0.010585 - train_acc: 1.000000\n",
      "valid_loss: 0.940567 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 61\n",
      "train_loss: 0.010209 - train_acc: 1.000000\n",
      "valid_loss: 0.942056 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 62\n",
      "train_loss: 0.007562 - train_acc: 1.000000\n",
      "valid_loss: 0.945865 - valid_acc: 0.750000\n",
      "Fold 1 - Epochs 63\n",
      "train_loss: 0.008898 - train_acc: 1.000000\n",
      "valid_loss: 0.950898 - valid_acc: 0.777778\n",
      "Fold 1 - Epochs 64\n",
      "train_loss: 0.008857 - train_acc: 1.000000\n",
      "valid_loss: 0.956653 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 65\n",
      "train_loss: 0.008397 - train_acc: 1.000000\n",
      "valid_loss: 0.962840 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 66\n",
      "train_loss: 0.008248 - train_acc: 1.000000\n",
      "valid_loss: 0.969933 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 67\n",
      "train_loss: 0.013611 - train_acc: 1.000000\n",
      "valid_loss: 0.975471 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 68\n",
      "train_loss: 0.005797 - train_acc: 1.000000\n",
      "valid_loss: 0.978669 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 69\n",
      "train_loss: 0.006294 - train_acc: 1.000000\n",
      "valid_loss: 0.981531 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 70\n",
      "train_loss: 0.006176 - train_acc: 1.000000\n",
      "valid_loss: 0.983509 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 71\n",
      "train_loss: 0.008335 - train_acc: 1.000000\n",
      "valid_loss: 0.984556 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 72\n",
      "train_loss: 0.007369 - train_acc: 1.000000\n",
      "valid_loss: 0.985049 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 73\n",
      "train_loss: 0.019487 - train_acc: 1.000000\n",
      "valid_loss: 0.984577 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 74\n",
      "train_loss: 0.006348 - train_acc: 1.000000\n",
      "valid_loss: 0.983856 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 75\n",
      "train_loss: 0.005596 - train_acc: 1.000000\n",
      "valid_loss: 0.983187 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 76\n",
      "train_loss: 0.006254 - train_acc: 1.000000\n",
      "valid_loss: 0.982903 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 77\n",
      "train_loss: 0.018190 - train_acc: 1.000000\n",
      "valid_loss: 0.982813 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 78\n",
      "train_loss: 0.005704 - train_acc: 1.000000\n",
      "valid_loss: 0.982760 - valid_acc: 0.805556\n",
      "Fold 1 - Epochs 79\n",
      "train_loss: 0.007025 - train_acc: 1.000000\n",
      "valid_loss: 0.982723 - valid_acc: 0.805556\n",
      "Saving model fold 1\n",
      "Start training fold 2 with 2/1 train/test smart contracts\n",
      "Fold 2 - Epochs 0\n",
      "train_loss: 0.686803 - train_acc: 0.624479\n",
      "valid_loss: 0.653510 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 1\n",
      "train_loss: 0.620016 - train_acc: 0.792708\n",
      "valid_loss: 0.605892 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 2\n",
      "train_loss: 0.652752 - train_acc: 0.596615\n",
      "valid_loss: 0.566995 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 3\n",
      "train_loss: 0.580395 - train_acc: 0.680990\n",
      "valid_loss: 0.539558 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 4\n",
      "train_loss: 0.589832 - train_acc: 0.680990\n",
      "valid_loss: 0.524686 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 5\n",
      "train_loss: 0.499884 - train_acc: 0.769271\n",
      "valid_loss: 0.521594 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 6\n",
      "train_loss: 0.518041 - train_acc: 0.769271\n",
      "valid_loss: 0.524508 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 7\n",
      "train_loss: 0.639936 - train_acc: 0.684896\n",
      "valid_loss: 0.521101 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 8\n",
      "train_loss: 0.480334 - train_acc: 0.802604\n",
      "valid_loss: 0.512640 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 9\n",
      "train_loss: 0.532605 - train_acc: 0.743750\n",
      "valid_loss: 0.511889 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 10\n",
      "train_loss: 0.511364 - train_acc: 0.773177\n",
      "valid_loss: 0.521841 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 11\n",
      "train_loss: 0.511733 - train_acc: 0.796615\n",
      "valid_loss: 0.528177 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 12\n",
      "train_loss: 0.492041 - train_acc: 0.827865\n",
      "valid_loss: 0.518134 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 13\n",
      "train_loss: 0.478792 - train_acc: 0.827865\n",
      "valid_loss: 0.504889 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 14\n",
      "train_loss: 0.498451 - train_acc: 0.810156\n",
      "valid_loss: 0.503424 - valid_acc: 0.777778\n",
      "Fold 2 - Epochs 15\n",
      "train_loss: 0.481332 - train_acc: 0.806250\n",
      "valid_loss: 0.518434 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 16\n",
      "train_loss: 0.463217 - train_acc: 0.800260\n",
      "valid_loss: 0.541536 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 17\n",
      "train_loss: 0.419241 - train_acc: 0.829688\n",
      "valid_loss: 0.518010 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 18\n",
      "train_loss: 0.424816 - train_acc: 0.829688\n",
      "valid_loss: 0.529908 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 19\n",
      "train_loss: 0.311475 - train_acc: 0.888542\n",
      "valid_loss: 0.548295 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 20\n",
      "train_loss: 0.316403 - train_acc: 0.866927\n",
      "valid_loss: 0.577771 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 21\n",
      "train_loss: 0.317965 - train_acc: 0.908073\n",
      "valid_loss: 0.612039 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 22\n",
      "train_loss: 0.285627 - train_acc: 0.845313\n",
      "valid_loss: 0.660063 - valid_acc: 0.694444\n",
      "Fold 2 - Epochs 23\n",
      "train_loss: 0.221353 - train_acc: 0.927604\n",
      "valid_loss: 0.784896 - valid_acc: 0.583333\n",
      "Fold 2 - Epochs 24\n",
      "train_loss: 0.223987 - train_acc: 0.947135\n",
      "valid_loss: 0.885769 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 25\n",
      "train_loss: 0.210555 - train_acc: 0.941406\n",
      "valid_loss: 0.783976 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 26\n",
      "train_loss: 0.164672 - train_acc: 0.960938\n",
      "valid_loss: 0.848890 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 27\n",
      "train_loss: 0.103132 - train_acc: 0.972656\n",
      "valid_loss: 1.015961 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 28\n",
      "train_loss: 0.130487 - train_acc: 0.957031\n",
      "valid_loss: 1.024128 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 29\n",
      "train_loss: 0.096824 - train_acc: 0.976562\n",
      "valid_loss: 1.194749 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 30\n",
      "train_loss: 0.094014 - train_acc: 0.972656\n",
      "valid_loss: 1.303559 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 31\n",
      "train_loss: 0.122110 - train_acc: 0.943229\n",
      "valid_loss: 1.303859 - valid_acc: 0.583333\n",
      "Fold 2 - Epochs 32\n",
      "train_loss: 0.103316 - train_acc: 0.968750\n",
      "valid_loss: 1.659829 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 33\n",
      "train_loss: 0.176550 - train_acc: 0.931510\n",
      "valid_loss: 1.436923 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 34\n",
      "train_loss: 0.063120 - train_acc: 0.980469\n",
      "valid_loss: 1.495358 - valid_acc: 0.416667\n",
      "Fold 2 - Epochs 35\n",
      "train_loss: 0.176715 - train_acc: 0.915885\n",
      "valid_loss: 1.768412 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 36\n",
      "train_loss: 0.183650 - train_acc: 0.935417\n",
      "valid_loss: 1.598126 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 37\n",
      "train_loss: 0.060786 - train_acc: 0.976562\n",
      "valid_loss: 1.465593 - valid_acc: 0.388889\n",
      "Fold 2 - Epochs 38\n",
      "train_loss: 0.083192 - train_acc: 0.988281\n",
      "valid_loss: 1.377573 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 39\n",
      "train_loss: 0.023492 - train_acc: 0.996094\n",
      "valid_loss: 1.596221 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 40\n",
      "train_loss: 0.040002 - train_acc: 0.980469\n",
      "valid_loss: 1.590718 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 41\n",
      "train_loss: 0.055286 - train_acc: 0.984375\n",
      "valid_loss: 1.430971 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 42\n",
      "train_loss: 0.025027 - train_acc: 0.996094\n",
      "valid_loss: 1.408970 - valid_acc: 0.666667\n",
      "Fold 2 - Epochs 43\n",
      "train_loss: 0.049912 - train_acc: 1.000000\n",
      "valid_loss: 1.446342 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 44\n",
      "train_loss: 0.017078 - train_acc: 1.000000\n",
      "valid_loss: 1.646380 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 45\n",
      "train_loss: 0.020193 - train_acc: 0.988281\n",
      "valid_loss: 1.744459 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 46\n",
      "train_loss: 0.032295 - train_acc: 0.984375\n",
      "valid_loss: 1.650390 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 47\n",
      "train_loss: 0.015673 - train_acc: 0.992188\n",
      "valid_loss: 1.515005 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 48\n",
      "train_loss: 0.012735 - train_acc: 1.000000\n",
      "valid_loss: 1.487868 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 49\n",
      "train_loss: 0.016289 - train_acc: 1.000000\n",
      "valid_loss: 1.503489 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 50\n",
      "train_loss: 0.015851 - train_acc: 1.000000\n",
      "valid_loss: 1.554328 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 51\n",
      "train_loss: 0.008011 - train_acc: 1.000000\n",
      "valid_loss: 1.649532 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 52\n",
      "train_loss: 0.007890 - train_acc: 1.000000\n",
      "valid_loss: 1.732412 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 53\n",
      "train_loss: 0.023870 - train_acc: 1.000000\n",
      "valid_loss: 1.740950 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 54\n",
      "train_loss: 0.020011 - train_acc: 1.000000\n",
      "valid_loss: 1.675516 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 55\n",
      "train_loss: 0.008402 - train_acc: 1.000000\n",
      "valid_loss: 1.612778 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 56\n",
      "train_loss: 0.010971 - train_acc: 1.000000\n",
      "valid_loss: 1.589530 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 57\n",
      "train_loss: 0.006941 - train_acc: 1.000000\n",
      "valid_loss: 1.586139 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 58\n",
      "train_loss: 0.011089 - train_acc: 1.000000\n",
      "valid_loss: 1.595341 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 59\n",
      "train_loss: 0.009348 - train_acc: 1.000000\n",
      "valid_loss: 1.613410 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 60\n",
      "train_loss: 0.005665 - train_acc: 1.000000\n",
      "valid_loss: 1.638746 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 61\n",
      "train_loss: 0.007303 - train_acc: 1.000000\n",
      "valid_loss: 1.666865 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 62\n",
      "train_loss: 0.005784 - train_acc: 1.000000\n",
      "valid_loss: 1.695438 - valid_acc: 0.722222\n",
      "Fold 2 - Epochs 63\n",
      "train_loss: 0.005045 - train_acc: 1.000000\n",
      "valid_loss: 1.723136 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 64\n",
      "train_loss: 0.004991 - train_acc: 1.000000\n",
      "valid_loss: 1.746676 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 65\n",
      "train_loss: 0.004616 - train_acc: 1.000000\n",
      "valid_loss: 1.764242 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 66\n",
      "train_loss: 0.005156 - train_acc: 1.000000\n",
      "valid_loss: 1.775632 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 67\n",
      "train_loss: 0.006310 - train_acc: 1.000000\n",
      "valid_loss: 1.782931 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 68\n",
      "train_loss: 0.004207 - train_acc: 1.000000\n",
      "valid_loss: 1.786903 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 69\n",
      "train_loss: 0.009831 - train_acc: 1.000000\n",
      "valid_loss: 1.786723 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 70\n",
      "train_loss: 0.005525 - train_acc: 1.000000\n",
      "valid_loss: 1.782848 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 71\n",
      "train_loss: 0.009163 - train_acc: 1.000000\n",
      "valid_loss: 1.778451 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 72\n",
      "train_loss: 0.009722 - train_acc: 1.000000\n",
      "valid_loss: 1.773528 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 73\n",
      "train_loss: 0.003576 - train_acc: 1.000000\n",
      "valid_loss: 1.769650 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 74\n",
      "train_loss: 0.003951 - train_acc: 1.000000\n",
      "valid_loss: 1.767093 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 75\n",
      "train_loss: 0.009103 - train_acc: 1.000000\n",
      "valid_loss: 1.765465 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 76\n",
      "train_loss: 0.007471 - train_acc: 1.000000\n",
      "valid_loss: 1.764290 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 77\n",
      "train_loss: 0.005622 - train_acc: 1.000000\n",
      "valid_loss: 1.763503 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 78\n",
      "train_loss: 0.004451 - train_acc: 1.000000\n",
      "valid_loss: 1.763307 - valid_acc: 0.750000\n",
      "Fold 2 - Epochs 79\n",
      "train_loss: 0.005677 - train_acc: 1.000000\n",
      "valid_loss: 1.763281 - valid_acc: 0.750000\n",
      "Saving model fold 2\n",
      "Start training fold 3 with 2/1 train/test smart contracts\n",
      "Fold 3 - Epochs 0\n",
      "train_loss: 0.650430 - train_acc: 0.788802\n",
      "valid_loss: 0.651101 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 1\n",
      "train_loss: 0.616214 - train_acc: 0.733854\n",
      "valid_loss: 0.628807 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 2\n",
      "train_loss: 0.560764 - train_acc: 0.755469\n",
      "valid_loss: 0.618352 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 3\n",
      "train_loss: 0.605958 - train_acc: 0.696615\n",
      "valid_loss: 0.625655 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 4\n",
      "train_loss: 0.468655 - train_acc: 0.784896\n",
      "valid_loss: 0.648460 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 5\n",
      "train_loss: 0.573651 - train_acc: 0.726042\n",
      "valid_loss: 0.675255 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 6\n",
      "train_loss: 0.697428 - train_acc: 0.667188\n",
      "valid_loss: 0.673597 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 7\n",
      "train_loss: 0.619409 - train_acc: 0.726042\n",
      "valid_loss: 0.636266 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 8\n",
      "train_loss: 0.531588 - train_acc: 0.726042\n",
      "valid_loss: 0.601100 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 9\n",
      "train_loss: 0.530312 - train_acc: 0.759375\n",
      "valid_loss: 0.597749 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 10\n",
      "train_loss: 0.551880 - train_acc: 0.757292\n",
      "valid_loss: 0.606136 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 11\n",
      "train_loss: 0.525431 - train_acc: 0.810156\n",
      "valid_loss: 0.600710 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 12\n",
      "train_loss: 0.526633 - train_acc: 0.814063\n",
      "valid_loss: 0.578133 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 13\n",
      "train_loss: 0.465697 - train_acc: 0.806250\n",
      "valid_loss: 0.576803 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 14\n",
      "train_loss: 0.547181 - train_acc: 0.743490\n",
      "valid_loss: 0.562136 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 15\n",
      "train_loss: 0.439456 - train_acc: 0.843490\n",
      "valid_loss: 0.564038 - valid_acc: 0.722222\n",
      "Fold 3 - Epochs 16\n",
      "train_loss: 0.426763 - train_acc: 0.896354\n",
      "valid_loss: 0.542954 - valid_acc: 0.750000\n",
      "Fold 3 - Epochs 17\n",
      "train_loss: 0.418631 - train_acc: 0.808073\n",
      "valid_loss: 0.526458 - valid_acc: 0.722222\n",
      "Fold 3 - Epochs 18\n",
      "train_loss: 0.349000 - train_acc: 0.896354\n",
      "valid_loss: 0.523533 - valid_acc: 0.750000\n",
      "Fold 3 - Epochs 19\n",
      "train_loss: 0.409219 - train_acc: 0.815885\n",
      "valid_loss: 0.551690 - valid_acc: 0.722222\n",
      "Fold 3 - Epochs 20\n",
      "train_loss: 0.379444 - train_acc: 0.845313\n",
      "valid_loss: 0.551369 - valid_acc: 0.750000\n",
      "Fold 3 - Epochs 21\n",
      "train_loss: 0.343105 - train_acc: 0.878646\n",
      "valid_loss: 0.626742 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 22\n",
      "train_loss: 0.261102 - train_acc: 0.933594\n",
      "valid_loss: 0.598829 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 23\n",
      "train_loss: 0.225490 - train_acc: 0.957031\n",
      "valid_loss: 0.648590 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 24\n",
      "train_loss: 0.183499 - train_acc: 0.953125\n",
      "valid_loss: 0.759983 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 25\n",
      "train_loss: 0.236269 - train_acc: 0.923698\n",
      "valid_loss: 0.760129 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 26\n",
      "train_loss: 0.196472 - train_acc: 0.927604\n",
      "valid_loss: 0.790219 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 27\n",
      "train_loss: 0.180355 - train_acc: 0.939323\n",
      "valid_loss: 0.914331 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 28\n",
      "train_loss: 0.158724 - train_acc: 0.935417\n",
      "valid_loss: 0.908916 - valid_acc: 0.638889\n",
      "Fold 3 - Epochs 29\n",
      "train_loss: 0.113268 - train_acc: 0.972656\n",
      "valid_loss: 1.016896 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 30\n",
      "train_loss: 0.111032 - train_acc: 0.939323\n",
      "valid_loss: 1.130257 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 31\n",
      "train_loss: 0.073121 - train_acc: 0.972656\n",
      "valid_loss: 1.155429 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 32\n",
      "train_loss: 0.116728 - train_acc: 0.958854\n",
      "valid_loss: 1.299058 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 33\n",
      "train_loss: 0.071291 - train_acc: 0.988281\n",
      "valid_loss: 1.484014 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 34\n",
      "train_loss: 0.053521 - train_acc: 0.980469\n",
      "valid_loss: 1.667559 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 35\n",
      "train_loss: 0.056031 - train_acc: 0.976562\n",
      "valid_loss: 1.677182 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 36\n",
      "train_loss: 0.053591 - train_acc: 0.988281\n",
      "valid_loss: 1.765468 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 37\n",
      "train_loss: 0.053941 - train_acc: 0.992188\n",
      "valid_loss: 1.822687 - valid_acc: 0.694444\n",
      "Fold 3 - Epochs 38\n",
      "train_loss: 0.030794 - train_acc: 0.992188\n",
      "valid_loss: 1.864182 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 39\n",
      "train_loss: 0.032324 - train_acc: 0.992188\n",
      "valid_loss: 1.981204 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 40\n",
      "train_loss: 0.049192 - train_acc: 0.958854\n",
      "valid_loss: 1.961924 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 41\n",
      "train_loss: 0.030519 - train_acc: 1.000000\n",
      "valid_loss: 2.021257 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 42\n",
      "train_loss: 0.040370 - train_acc: 1.000000\n",
      "valid_loss: 2.159775 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 43\n",
      "train_loss: 0.030053 - train_acc: 0.992188\n",
      "valid_loss: 2.127850 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 44\n",
      "train_loss: 0.018292 - train_acc: 1.000000\n",
      "valid_loss: 2.155452 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 45\n",
      "train_loss: 0.021802 - train_acc: 1.000000\n",
      "valid_loss: 2.255944 - valid_acc: 0.638889\n",
      "Fold 3 - Epochs 46\n",
      "train_loss: 0.016940 - train_acc: 1.000000\n",
      "valid_loss: 2.287934 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 47\n",
      "train_loss: 0.012888 - train_acc: 1.000000\n",
      "valid_loss: 2.321046 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 48\n",
      "train_loss: 0.013499 - train_acc: 1.000000\n",
      "valid_loss: 2.373841 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 49\n",
      "train_loss: 0.011208 - train_acc: 1.000000\n",
      "valid_loss: 2.423159 - valid_acc: 0.638889\n",
      "Fold 3 - Epochs 50\n",
      "train_loss: 0.011704 - train_acc: 1.000000\n",
      "valid_loss: 2.446678 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 51\n",
      "train_loss: 0.028515 - train_acc: 1.000000\n",
      "valid_loss: 2.393972 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 52\n",
      "train_loss: 0.008983 - train_acc: 1.000000\n",
      "valid_loss: 2.359157 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 53\n",
      "train_loss: 0.016759 - train_acc: 1.000000\n",
      "valid_loss: 2.414434 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 54\n",
      "train_loss: 0.010853 - train_acc: 1.000000\n",
      "valid_loss: 2.532535 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 55\n",
      "train_loss: 0.006049 - train_acc: 1.000000\n",
      "valid_loss: 2.639485 - valid_acc: 0.638889\n",
      "Fold 3 - Epochs 56\n",
      "train_loss: 0.008824 - train_acc: 1.000000\n",
      "valid_loss: 2.685468 - valid_acc: 0.666667\n",
      "Fold 3 - Epochs 57\n",
      "train_loss: 0.009751 - train_acc: 1.000000\n",
      "valid_loss: 2.672173 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 58\n",
      "train_loss: 0.008633 - train_acc: 1.000000\n",
      "valid_loss: 2.631697 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 59\n",
      "train_loss: 0.022097 - train_acc: 1.000000\n",
      "valid_loss: 2.559939 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 60\n",
      "train_loss: 0.009538 - train_acc: 1.000000\n",
      "valid_loss: 2.493208 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 61\n",
      "train_loss: 0.012356 - train_acc: 1.000000\n",
      "valid_loss: 2.478599 - valid_acc: 0.555556\n",
      "Fold 3 - Epochs 62\n",
      "train_loss: 0.015193 - train_acc: 1.000000\n",
      "valid_loss: 2.496492 - valid_acc: 0.555556\n",
      "Fold 3 - Epochs 63\n",
      "train_loss: 0.012625 - train_acc: 1.000000\n",
      "valid_loss: 2.534561 - valid_acc: 0.583333\n",
      "Fold 3 - Epochs 64\n",
      "train_loss: 0.008076 - train_acc: 1.000000\n",
      "valid_loss: 2.587756 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 65\n",
      "train_loss: 0.004572 - train_acc: 1.000000\n",
      "valid_loss: 2.642271 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 66\n",
      "train_loss: 0.004304 - train_acc: 1.000000\n",
      "valid_loss: 2.691578 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 67\n",
      "train_loss: 0.004351 - train_acc: 1.000000\n",
      "valid_loss: 2.732413 - valid_acc: 0.638889\n",
      "Fold 3 - Epochs 68\n",
      "train_loss: 0.004665 - train_acc: 1.000000\n",
      "valid_loss: 2.761864 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 69\n",
      "train_loss: 0.005390 - train_acc: 1.000000\n",
      "valid_loss: 2.780534 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 70\n",
      "train_loss: 0.009910 - train_acc: 1.000000\n",
      "valid_loss: 2.787768 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 71\n",
      "train_loss: 0.006343 - train_acc: 1.000000\n",
      "valid_loss: 2.786776 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 72\n",
      "train_loss: 0.006452 - train_acc: 1.000000\n",
      "valid_loss: 2.783410 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 73\n",
      "train_loss: 0.004931 - train_acc: 1.000000\n",
      "valid_loss: 2.780486 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 74\n",
      "train_loss: 0.004214 - train_acc: 1.000000\n",
      "valid_loss: 2.777710 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 75\n",
      "train_loss: 0.009733 - train_acc: 1.000000\n",
      "valid_loss: 2.775044 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 76\n",
      "train_loss: 0.004061 - train_acc: 1.000000\n",
      "valid_loss: 2.772983 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 77\n",
      "train_loss: 0.005172 - train_acc: 1.000000\n",
      "valid_loss: 2.771994 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 78\n",
      "train_loss: 0.012537 - train_acc: 1.000000\n",
      "valid_loss: 2.771678 - valid_acc: 0.611111\n",
      "Fold 3 - Epochs 79\n",
      "train_loss: 0.005908 - train_acc: 1.000000\n",
      "valid_loss: 2.771588 - valid_acc: 0.611111\n",
      "Saving model fold 3\n",
      "Start training fold 4 with 2/1 train/test smart contracts\n",
      "Fold 4 - Epochs 0\n",
      "train_loss: 0.635091 - train_acc: 0.738281\n",
      "valid_loss: 0.634293 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 1\n",
      "train_loss: 0.612046 - train_acc: 0.734375\n",
      "valid_loss: 0.625824 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 2\n",
      "train_loss: 0.555047 - train_acc: 0.761719\n",
      "valid_loss: 0.625715 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 3\n",
      "train_loss: 0.599026 - train_acc: 0.707031\n",
      "valid_loss: 0.639680 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 4\n",
      "train_loss: 0.559947 - train_acc: 0.734375\n",
      "valid_loss: 0.667393 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 5\n",
      "train_loss: 0.523728 - train_acc: 0.761719\n",
      "valid_loss: 0.700343 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 6\n",
      "train_loss: 0.517914 - train_acc: 0.761719\n",
      "valid_loss: 0.723361 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 7\n",
      "train_loss: 0.655561 - train_acc: 0.679688\n",
      "valid_loss: 0.712753 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 8\n",
      "train_loss: 0.462468 - train_acc: 0.816406\n",
      "valid_loss: 0.679469 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 9\n",
      "train_loss: 0.562965 - train_acc: 0.707031\n",
      "valid_loss: 0.646643 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 10\n",
      "train_loss: 0.484890 - train_acc: 0.765625\n",
      "valid_loss: 0.624966 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 11\n",
      "train_loss: 0.526690 - train_acc: 0.722656\n",
      "valid_loss: 0.618866 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 12\n",
      "train_loss: 0.484555 - train_acc: 0.808594\n",
      "valid_loss: 0.619980 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 13\n",
      "train_loss: 0.510058 - train_acc: 0.765625\n",
      "valid_loss: 0.645882 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 14\n",
      "train_loss: 0.468818 - train_acc: 0.785156\n",
      "valid_loss: 0.673081 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 15\n",
      "train_loss: 0.474438 - train_acc: 0.796875\n",
      "valid_loss: 0.639845 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 16\n",
      "train_loss: 0.452068 - train_acc: 0.914062\n",
      "valid_loss: 0.656463 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 17\n",
      "train_loss: 0.434571 - train_acc: 0.828125\n",
      "valid_loss: 0.707156 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 18\n",
      "train_loss: 0.352293 - train_acc: 0.882812\n",
      "valid_loss: 0.665442 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 19\n",
      "train_loss: 0.326350 - train_acc: 0.890625\n",
      "valid_loss: 0.670684 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 20\n",
      "train_loss: 0.328746 - train_acc: 0.890625\n",
      "valid_loss: 0.732299 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 21\n",
      "train_loss: 0.229818 - train_acc: 0.917969\n",
      "valid_loss: 0.824386 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 22\n",
      "train_loss: 0.199896 - train_acc: 0.890625\n",
      "valid_loss: 0.714222 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 23\n",
      "train_loss: 0.164623 - train_acc: 0.964844\n",
      "valid_loss: 0.777189 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 24\n",
      "train_loss: 0.141358 - train_acc: 0.964844\n",
      "valid_loss: 1.050515 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 25\n",
      "train_loss: 0.228000 - train_acc: 0.906250\n",
      "valid_loss: 0.684464 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 26\n",
      "train_loss: 0.160635 - train_acc: 0.984375\n",
      "valid_loss: 0.693757 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 27\n",
      "train_loss: 0.084403 - train_acc: 0.980469\n",
      "valid_loss: 1.231988 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 28\n",
      "train_loss: 0.103454 - train_acc: 0.964844\n",
      "valid_loss: 1.209509 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 29\n",
      "train_loss: 0.089642 - train_acc: 0.968750\n",
      "valid_loss: 0.736553 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 30\n",
      "train_loss: 0.087599 - train_acc: 0.964844\n",
      "valid_loss: 0.798092 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 31\n",
      "train_loss: 0.045163 - train_acc: 0.992188\n",
      "valid_loss: 1.143983 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 32\n",
      "train_loss: 0.132212 - train_acc: 0.953125\n",
      "valid_loss: 0.832791 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 33\n",
      "train_loss: 0.077195 - train_acc: 0.996094\n",
      "valid_loss: 0.832268 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 34\n",
      "train_loss: 0.030513 - train_acc: 1.000000\n",
      "valid_loss: 1.586570 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 35\n",
      "train_loss: 0.040029 - train_acc: 0.980469\n",
      "valid_loss: 1.672744 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 36\n",
      "train_loss: 0.048384 - train_acc: 0.984375\n",
      "valid_loss: 1.175943 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 37\n",
      "train_loss: 0.011727 - train_acc: 1.000000\n",
      "valid_loss: 0.899510 - valid_acc: 0.600000\n",
      "Fold 4 - Epochs 38\n",
      "train_loss: 0.052710 - train_acc: 1.000000\n",
      "valid_loss: 1.427890 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 39\n",
      "train_loss: 0.012581 - train_acc: 0.996094\n",
      "valid_loss: 2.235129 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 40\n",
      "train_loss: 0.041147 - train_acc: 0.984375\n",
      "valid_loss: 2.196207 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 41\n",
      "train_loss: 0.072175 - train_acc: 0.960938\n",
      "valid_loss: 1.402876 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 42\n",
      "train_loss: 0.011602 - train_acc: 1.000000\n",
      "valid_loss: 0.973453 - valid_acc: 0.514286\n",
      "Fold 4 - Epochs 43\n",
      "train_loss: 0.063059 - train_acc: 0.996094\n",
      "valid_loss: 1.259559 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 44\n",
      "train_loss: 0.003670 - train_acc: 1.000000\n",
      "valid_loss: 1.974427 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 45\n",
      "train_loss: 0.006114 - train_acc: 1.000000\n",
      "valid_loss: 2.466340 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 46\n",
      "train_loss: 0.038693 - train_acc: 0.992188\n",
      "valid_loss: 2.381603 - valid_acc: 0.714286\n",
      "Fold 4 - Epochs 47\n",
      "train_loss: 0.013121 - train_acc: 0.988281\n",
      "valid_loss: 1.889975 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 48\n",
      "train_loss: 0.002375 - train_acc: 1.000000\n",
      "valid_loss: 1.531380 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 49\n",
      "train_loss: 0.003442 - train_acc: 1.000000\n",
      "valid_loss: 1.323567 - valid_acc: 0.628571\n",
      "Fold 4 - Epochs 50\n",
      "train_loss: 0.004057 - train_acc: 1.000000\n",
      "valid_loss: 1.246590 - valid_acc: 0.628571\n",
      "Fold 4 - Epochs 51\n",
      "train_loss: 0.009532 - train_acc: 1.000000\n",
      "valid_loss: 1.271229 - valid_acc: 0.628571\n",
      "Fold 4 - Epochs 52\n",
      "train_loss: 0.006352 - train_acc: 1.000000\n",
      "valid_loss: 1.376490 - valid_acc: 0.628571\n",
      "Fold 4 - Epochs 53\n",
      "train_loss: 0.004966 - train_acc: 1.000000\n",
      "valid_loss: 1.522449 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 54\n",
      "train_loss: 0.002857 - train_acc: 1.000000\n",
      "valid_loss: 1.684209 - valid_acc: 0.657143\n",
      "Fold 4 - Epochs 55\n",
      "train_loss: 0.000946 - train_acc: 1.000000\n",
      "valid_loss: 1.835288 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 56\n",
      "train_loss: 0.000804 - train_acc: 1.000000\n",
      "valid_loss: 1.961833 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 57\n",
      "train_loss: 0.000972 - train_acc: 1.000000\n",
      "valid_loss: 2.062191 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 58\n",
      "train_loss: 0.002042 - train_acc: 1.000000\n",
      "valid_loss: 2.134615 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 59\n",
      "train_loss: 0.001906 - train_acc: 1.000000\n",
      "valid_loss: 2.182038 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 60\n",
      "train_loss: 0.001538 - train_acc: 1.000000\n",
      "valid_loss: 2.209462 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 61\n",
      "train_loss: 0.001531 - train_acc: 1.000000\n",
      "valid_loss: 2.221776 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 62\n",
      "train_loss: 0.000954 - train_acc: 1.000000\n",
      "valid_loss: 2.225725 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 63\n",
      "train_loss: 0.001138 - train_acc: 1.000000\n",
      "valid_loss: 2.224279 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 64\n",
      "train_loss: 0.000861 - train_acc: 1.000000\n",
      "valid_loss: 2.220202 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 65\n",
      "train_loss: 0.001028 - train_acc: 1.000000\n",
      "valid_loss: 2.213668 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 66\n",
      "train_loss: 0.001250 - train_acc: 1.000000\n",
      "valid_loss: 2.206142 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 67\n",
      "train_loss: 0.001058 - train_acc: 1.000000\n",
      "valid_loss: 2.198456 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 68\n",
      "train_loss: 0.000964 - train_acc: 1.000000\n",
      "valid_loss: 2.190999 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 69\n",
      "train_loss: 0.001212 - train_acc: 1.000000\n",
      "valid_loss: 2.184165 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 70\n",
      "train_loss: 0.000872 - train_acc: 1.000000\n",
      "valid_loss: 2.178039 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 71\n",
      "train_loss: 0.000933 - train_acc: 1.000000\n",
      "valid_loss: 2.173036 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 72\n",
      "train_loss: 0.000806 - train_acc: 1.000000\n",
      "valid_loss: 2.168559 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 73\n",
      "train_loss: 0.000685 - train_acc: 1.000000\n",
      "valid_loss: 2.165534 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 74\n",
      "train_loss: 0.001040 - train_acc: 1.000000\n",
      "valid_loss: 2.163142 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 75\n",
      "train_loss: 0.000969 - train_acc: 1.000000\n",
      "valid_loss: 2.161539 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 76\n",
      "train_loss: 0.000767 - train_acc: 1.000000\n",
      "valid_loss: 2.160884 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 77\n",
      "train_loss: 0.000927 - train_acc: 1.000000\n",
      "valid_loss: 2.160407 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 78\n",
      "train_loss: 0.000901 - train_acc: 1.000000\n",
      "valid_loss: 2.160247 - valid_acc: 0.685714\n",
      "Fold 4 - Epochs 79\n",
      "train_loss: 0.000881 - train_acc: 1.000000\n",
      "valid_loss: 2.160221 - valid_acc: 0.685714\n",
      "Saving model fold 4\n"
     ]
    }
   ],
   "source": [
    "train_results = {}\n",
    "test_results = {}\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(range(num_graphs))):\n",
    "    train_results[fold] = {'loss': [], 'acc': []}\n",
    "    test_results[fold] = {'loss': [], 'acc': []}\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    train_dataloader = GraphDataLoader(\n",
    "    Ethdataset,\n",
    "    batch_size=128,\n",
    "    drop_last=False,\n",
    "    sampler=train_subsampler)\n",
    "    test_dataloader = GraphDataLoader(\n",
    "    Ethdataset,\n",
    "    batch_size=128,\n",
    "    drop_last=False,\n",
    "    sampler=test_subsampler)\n",
    "    print('Start training fold {} with {}/{} train/test smart contracts'.format(fold, len(train_dataloader), len(test_dataloader)))\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    model = HeteroClassifier(128, 32, 2, etypes).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(),  lr=0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=0.01, total_steps=total_steps)\n",
    "    lrs = []\n",
    "    for epoch in range(epochs):\n",
    "        print('Fold {} - Epochs {}'.format(fold, epoch))\n",
    "        total_loss = 0\n",
    "        train_acc = 0\n",
    "        steps = 0\n",
    "        for idx, (batched_graph, labels) in enumerate(train_dataloader):\n",
    "            logits = model(batched_graph)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            train_acc += accuracy(preds, labels)\n",
    "            loss = cross_entropy(logits, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            lrs.append(opt.param_groups[0][\"lr\"])\n",
    "        print('train_loss: {:4f} - train_acc: {:4f}'.format(total_loss/steps, train_acc/steps))\n",
    "        train_results[fold]['loss'].append(total_loss/steps)\n",
    "        train_results[fold]['acc'].append(train_acc/steps)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            test_acc = 0\n",
    "            steps = 0\n",
    "            for idx, (batched_graph, labels) in enumerate(test_dataloader):\n",
    "                logits = model(batched_graph)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                test_acc += accuracy(preds, labels)\n",
    "                loss = cross_entropy(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "            print('valid_loss: {:4f} - valid_acc: {:4f}'.format(total_loss/steps, test_acc/steps))\n",
    "            test_results[fold]['loss'].append(total_loss/steps)\n",
    "            test_results[fold]['acc'].append(test_acc/steps)\n",
    "    print('Saving model fold {}'.format(fold))\n",
    "    save_path = f'./models/model_conv_fold_{fold}.pth'\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e232adcd-dd2d-4225-89e6-ec5fbedec1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training fold 4 with 144/35 train/test smart contracts\n"
     ]
    }
   ],
   "source": [
    "print('Start training fold {} with {}/{} train/test smart contracts'.format(fold, len(train_ids), len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5bbb8fa6-17e5-41e8-ab9b-769d5645e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "print(len(lrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aebfaebd-ba37-4114-8232-214f17ec756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = './ge-sc/logs/MetaPath2Vec_ConvHete_CrossVal'\n",
    "writer = SummaryWriter(tensorboard_path)\n",
    "tensorboard_acc = {'train': train_results[0]['acc'], 'valid': test_results[0]['acc']}\n",
    "tensorboard_loss = {'train': train_results[0]['loss'], 'valid': test_results[0]['loss']}\n",
    "# for key, results in train_results[0].items():\n",
    "#     tensorboard_acc[] = \n",
    "#     writer.add_scalars('Loss', train_res, epoch)\n",
    "# for idx, lr in enumerate(lrs):\n",
    "#     writer.add_scalar('Learning rate', lr, idx)\n",
    "for idx, lr in enumerate(lrs):\n",
    "    writer.add_scalar('Learning rate', lr, idx)\n",
    "\n",
    "for fold in range(k_folds):\n",
    "    for idx in range(epochs):\n",
    "        writer.add_scalars('Accuracy', {f'train_{fold+1}': train_results[fold]['acc'][idx],\n",
    "                                        f'valid_{fold+1}': test_results[fold]['acc'][idx]}, idx)\n",
    "        writer.add_scalars('Loss', {f'train_{fold+1}': train_results[fold]['loss'][idx],\n",
    "                                    f'valid_{fold+1}': test_results[fold]['loss'][idx]}, idx)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ee01f-51f9-4580-8c1d-c51795aa6e04",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdb38ce7-8e65-4dbb-a24c-89e98e19d905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENTRY_POINT': 14017,\n",
       " 'IF': 9869,\n",
       " 'RETURN': 3714,\n",
       " 'END_IF': 6872,\n",
       " 'EXPRESSION': 30068,\n",
       " 'FUNCTION_NAME': 7393,\n",
       " 'NEW VARIABLE': 6058,\n",
       " 'BEGIN_LOOP': 733,\n",
       " 'IF_LOOP': 1434,\n",
       " 'END_LOOP': 639,\n",
       " 'INLINE ASM': 227,\n",
       " 'OTHER_ENTRYPOINT': 1585,\n",
       " '_': 874,\n",
       " 'THROW': 717,\n",
       " 'BREAK': 58,\n",
       " 'CONTINUE': 30}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_num_node_dict(g_data):\n",
    "    num_node_dict = {}\n",
    "    for k, v in g_data.items():\n",
    "        if not num_node_dict.get(k[0]):\n",
    "            num_node_dict[k[0]] = v[0].shape[0]\n",
    "        else:\n",
    "            num_node_dict[k[0]] += v[0].shape[0]\n",
    "        if not num_node_dict.get(k[2]):\n",
    "            num_node_dict[k[2]] = v[1].shape[0]\n",
    "        else:\n",
    "            num_node_dict[k[2]] += v[1].shape[0]\n",
    "    return num_node_dict\n",
    "get_num_node_dict(nx_g_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b935d66d-5197-4439-b659-91001b98d473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('ENTRY_POINT', 'next', 'NEW VARIABLE'): tensor([[0],\n",
      "        [1]]), ('NEW VARIABLE', 'next', 'EXPRESSION'): tensor([[1],\n",
      "        [2]]), ('EXPRESSION', 'next', 'IF'): tensor([[2],\n",
      "        [3]]), ('IF', 'if_true', 'THROW'): tensor([[3, 8],\n",
      "        [4, 9]]), ('IF', 'if_false', 'END_IF'): tensor([[ 3,  8],\n",
      "        [ 5, 10]]), ('FUNCTION_NAME', 'next', 'ENTRY_POINT'): tensor([[ 6, 14],\n",
      "        [ 0,  7]]), ('ENTRY_POINT', 'next', 'IF'): tensor([[7],\n",
      "        [8]]), ('END_IF', 'next', 'EXPRESSION'): tensor([[10],\n",
      "        [11]]), ('EXPRESSION', 'next', 'EXPRESSION'): tensor([[11, 12],\n",
      "        [12, 13]])}\n"
     ]
    }
   ],
   "source": [
    "# convert dgl to geomatric graph format\n",
    "nx_g_data\n",
    "geo_g_data = {}\n",
    "for k, v in nx.items():\n",
    "    geo_g_data[k] = torch.stack(list(v), dim=0)\n",
    "\n",
    "print(geo_g_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "33ab660b-b891-4ab5-8fdb-778e6b0a8afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENTRY_POINT': 240,\n",
       " 'IF': 208,\n",
       " 'RETURN': 230,\n",
       " 'END_IF': 210,\n",
       " 'NEW VARIABLE': 233,\n",
       " 'EXPRESSION': 241,\n",
       " 'FUNCTION_NAME': 243,\n",
       " '_': 242}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get num node dict of graph sample\n",
    "num_nodes_dict = {}\n",
    "for n in list_node_type:\n",
    "    num_nodes_dict[n] = dgl_hete_graph.number_of_nodes(n)\n",
    "num_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d59e4e29-8733-4685-966a-06aeee0c1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import AMiner\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "\n",
    "path = osp.join(osp.dirname('./pytorch_geometric/data/AMiner/processed'))\n",
    "dataset = AMiner(path)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0734e8f6-6f0e-411d-876b-fa6931754b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': 3194405, 'author': 1693531, 'venue': 3883}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f152c2b1-9b90-48e2-85d5-093b5037cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num graphs: 179\n"
     ]
    }
   ],
   "source": [
    "pickle_path = './datasets/Etherscan_Contract/extracted_graph'\n",
    "pickle_files = sorted(sorted([f for f in os.listdir(pickle_path) if f.endswith('.gpickle')]), key=len)\n",
    "len(pickle_files)\n",
    "extracted_graph = [f for f in os.listdir(pickle_path) if f.endswith('.gpickle')]\n",
    "num_graphs = len(extracted_graph)\n",
    "print('num graphs: {}'.format(num_graphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c5c2b-1e74-461b-bf6f-1bd42cbb7a99",
   "metadata": {},
   "source": [
    "## Get Geometric graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33c870de-7101-456b-9531-3e5085d3b8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "{'ENTRY_POINT': 14017, 'EXPRESSION': 30068, 'FUNCTION_NAME': 7393, 'RETURN': 3714, '_': 874, 'NEW VARIABLE': 6058, 'IF': 9869, 'BEGIN_LOOP': 733, 'IF_LOOP': 1434, 'END_LOOP': 639, 'END_IF': 6872, 'OTHER_ENTRYPOINT': 1585, 'THROW': 717, 'INLINE ASM': 227, 'CONTINUE': 30, 'BREAK': 58}\n"
     ]
    }
   ],
   "source": [
    "geo_graph_data = {}\n",
    "dgl_graph_data = {}\n",
    "for i in range(num_graphs):\n",
    "    nx_graph = nx.read_gpickle(join(pickle_path, extracted_graph[i]))\n",
    "    nx_graph, list_node_type = add_node_type_feature(nx_graph)\n",
    "    nx_graph, list_edge_type = add_edge_type_feature(nx_graph)\n",
    "    nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
    "    nx_g_data = generate_hetero_graph_data(nx_graph)\n",
    "#     nx_g_data = add_full_metapath(nx_g_data, meta_path_types)\n",
    "#     dgl_hete_graph = dgl.heterograph(nx_g_data)\n",
    "    for k, v in nx_g_data.items():\n",
    "        v_tensor = torch.stack(list(v), dim=0)\n",
    "        if k in geo_graph_data.keys():\n",
    "            geo_graph_data[k] = torch.cat((geo_graph_data[k], v_tensor), 1)\n",
    "            dgl_graph_data[k] = (torch.cat((dgl_graph_data[k][0], v[0])), torch.cat((dgl_graph_data[k][1], v[1])))\n",
    "        else:\n",
    "            geo_graph_data[k] = v_tensor\n",
    "            dgl_graph_data[k] = v\n",
    "print(len(geo_graph_data.keys()))\n",
    "num_nodes_dict = get_num_node_dict(geo_graph_data)\n",
    "print(num_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e4669e9-24e8-486c-8442-41bc226f0051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2117)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_graph_data = dict(sorted(geo_graph_data.items(), key=lambda item: max(item[1][0].max().item(), item[1][1].max().item()), reverse=True))\n",
    "geo_graph_data[list(geo_graph_data.keys())[0]][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a515dde8-af8d-4fc2-840f-a5be2719c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4137, -1.3403, -0.7644,  ...,  1.1586, -1.7808, -0.9873],\n",
       "         [-0.2050,  0.1426, -0.7685,  ...,  0.1940, -0.5895,  0.3973],\n",
       "         [-0.4074,  1.6159,  0.4083,  ...,  1.5002, -1.1373, -0.6756],\n",
       "         ...,\n",
       "         [ 0.4665, -0.1268, -0.1598,  ...,  0.9926, -0.0658, -0.5501],\n",
       "         [ 0.5310, -0.1618, -1.3928,  ...,  0.8657,  0.3620, -0.2389],\n",
       "         [-2.2811,  0.3663,  0.1405,  ...,  0.0659, -1.4784, -0.6843]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward>),\n",
       " torch.Size([325, 128]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_graph_meta_path = list(nx_g_data.keys())\n",
    "bi_single_graph_meta_path= single_graph_meta_path + [t[::-1] for t in single_graph_meta_path[::-1]]\n",
    "single_meta_path_embedding =  MetaPath2Vec(nx_g_data, embedding_dim=128,\n",
    "                     metapath=bi_single_graph_meta_path, walk_length=2, context_size=2,\n",
    "                     walks_per_node=1, num_negative_samples=5, num_nodes_dict=None,\n",
    "                     sparse=True).to(device)\n",
    "single_meta_path_embedding\n",
    "z = single_meta_path_embedding('EXPRESSION')\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6e396-beb6-43f9-9929-53bbe416d0ca",
   "metadata": {},
   "source": [
    "## Get DGL graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9b1c08f-0e8d-4f0d-b042-15fa3c2a562d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dgl_graph_data = {}\n",
    "for k, v in geo_graph_data.items():\n",
    "    dgl_graph_data[k] = (v[0], v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbe17c2d-0f33-4325-b182-6fd9b446c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "geo_meta_path = list(geo_graph_data.keys())\n",
    "bidirect_geo_meta_path_types = geo_meta_path + [t[::-1] for t in geo_meta_path[::-1]]\n",
    "print(len(bidirect_geo_meta_path_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f4fa04b-5592-4a2c-97ab-563cae0b7fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7393"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes_dict[bidirect_geo_meta_path_types[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e778e7a-b5e4-4357-9d17-129abaa2de08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BEGIN_LOOP': 1559,\n",
       " 'BREAK': 1567,\n",
       " 'CONTINUE': 1076,\n",
       " 'END_IF': 2049,\n",
       " 'END_LOOP': 1560,\n",
       " 'ENTRY_POINT': 2115,\n",
       " 'EXPRESSION': 2116,\n",
       " 'FUNCTION_NAME': 2118,\n",
       " 'IF': 2046,\n",
       " 'IF_LOOP': 1562,\n",
       " 'INLINE ASM': 1241,\n",
       " 'NEW VARIABLE': 2097,\n",
       " 'OTHER_ENTRYPOINT': 2113,\n",
       " 'RETURN': 2094,\n",
       " 'THROW': 1036,\n",
       " '_': 2117}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_hete_graph = dgl.heterograph(dgl_graph_data)\n",
    "num_nodes_dict = {}\n",
    "for n in dgl_hete_graph.ntypes:\n",
    "    num_nodes_dict[n] = dgl_hete_graph.number_of_nodes(n)\n",
    "# num_nodes_dict = dict(sorted(num_nodes_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "num_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b64b72a-6c18-4b5d-ba7b-5eab09317b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import save_graphs\n",
    "save_graphs('./outputs/graph.bin', [dgl_hete_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dcf8156-7769-42ba-a0ac-fa11df3a5283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dgl_hete_graph.canonical_etypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3927228e-cee9-4741-8e96-6e8172db7356",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dgl_graph_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15179/2265073927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexplicated_dgl_graph_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdgl_graph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mexplicated_dgl_graph_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexplicated_dgl_hete_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheterograph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplicated_dgl_graph_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dgl_graph_data' is not defined"
     ]
    }
   ],
   "source": [
    "explicated_dgl_graph_data = {}\n",
    "for k, v in dgl_graph_data.items():\n",
    "    explicated_dgl_graph_data[(k[0], '_'.join(k), k[-1])] = v\n",
    "\n",
    "explicated_dgl_hete_graph = dgl.heterograph(explicated_dgl_graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9fc8371f-3b8a-40d3-bc37-0bcbba3c7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "bi_dgl_graph_data = {}\n",
    "for k, v in dgl_graph_data.items():\n",
    "    bi_dgl_graph_data[k] = v\n",
    "    if k[::-1] in dgl_graph_data.keys():\n",
    "#         print(k)\n",
    "#         bi_dgl_graph_data[k[::-1]] = (torch.cat((v[0], v[1])), torch.cat((v[1], v[0])))\n",
    "        continue\n",
    "    else:\n",
    "        bi_dgl_graph_data[k[::-1]] = v[::-1]\n",
    "\n",
    "bi_dgl_hete_graph = dgl.heterograph(bi_dgl_graph_data)\n",
    "print(len(bi_dgl_hete_graph.canonical_etypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8e9f5f10-8c00-4f6a-b679-f380ebb4d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28468\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for n in bi_dgl_hete_graph.ntypes:\n",
    "    total += bi_dgl_hete_graph.number_of_nodes(n)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c412ef3-57f6-405a-9527-416b38437d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27414"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_dgl_hete_graph.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "219250e8-1a2b-472d-aebe-4ad6061bec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graphs('./outputs/symmetric_graph.bin', [bi_dgl_hete_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7fe8d83b-2123-465f-a421-0063c8700eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28466\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for v in num_nodes_dict.values():\n",
    "    total += v\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "748cceb7-1254-4ad5-a445-f273303ddf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  3,  9,  ..., 15, 23, 29]) tensor([ 1,  7, 10,  ..., 16, 24, 30])\n"
     ]
    }
   ],
   "source": [
    "row, col = geo_graph_data[('ENTRY_POINT', 'next', 'EXPRESSION')]\n",
    "print(row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b4ce906-c328-4bbc-8767-5e90141837b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ENTRY_POINT', 'next', 'EXPRESSION')\n",
      "('FUNCTION_NAME', 'next', 'ENTRY_POINT')\n",
      "('EXPRESSION', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'RETURN')\n",
      "('EXPRESSION', 'next', '_')\n",
      "('ENTRY_POINT', 'next', 'NEW VARIABLE')\n",
      "('NEW VARIABLE', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'NEW VARIABLE')\n",
      "('NEW VARIABLE', 'next', 'RETURN')\n",
      "('ENTRY_POINT', 'next', 'IF')\n",
      "('IF', 'if_true', 'RETURN')\n",
      "('IF', 'if_false', 'RETURN')\n",
      "('ENTRY_POINT', 'next', 'RETURN')\n",
      "('BEGIN_LOOP', 'next', 'IF_LOOP')\n",
      "('NEW VARIABLE', 'next', 'BEGIN_LOOP')\n",
      "('IF_LOOP', 'if_false', 'END_LOOP')\n",
      "('IF_LOOP', 'if_true', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'IF_LOOP')\n",
      "('NEW VARIABLE', 'next', 'NEW VARIABLE')\n",
      "('END_LOOP', 'next', 'EXPRESSION')\n",
      "('IF_LOOP', 'if_true', 'IF')\n",
      "('IF', 'if_false', 'END_IF')\n",
      "('END_IF', 'next', 'EXPRESSION')\n",
      "('END_LOOP', 'next', 'RETURN')\n",
      "('IF', 'if_true', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'END_IF')\n",
      "('IF', 'if_true', 'IF')\n",
      "('IF', 'if_false', 'NEW VARIABLE')\n",
      "('NEW VARIABLE', 'next', 'IF')\n",
      "('IF', 'if_true', 'NEW VARIABLE')\n",
      "('END_LOOP', 'next', 'END_IF')\n",
      "('END_IF', 'next', 'NEW VARIABLE')\n",
      "('END_IF', 'next', 'END_IF')\n",
      "('EXPRESSION', 'next', 'IF')\n",
      "('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT')\n",
      "('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT')\n",
      "('END_IF', 'next', 'IF')\n",
      "('IF', 'if_true', 'THROW')\n",
      "('END_IF', 'next', '_')\n",
      "('IF_LOOP', 'if_true', 'NEW VARIABLE')\n",
      "('IF', 'if_false', 'EXPRESSION')\n",
      "('IF', 'if_false', 'IF')\n",
      "('END_IF', 'next', 'RETURN')\n",
      "('NEW VARIABLE', 'next', 'INLINE ASM')\n",
      "('INLINE ASM', 'next', 'RETURN')\n",
      "('EXPRESSION', 'next', 'BEGIN_LOOP')\n",
      "('IF', 'if_true', 'END_IF')\n",
      "('INLINE ASM', 'next', 'EXPRESSION')\n",
      "('ENTRY_POINT', 'next', 'THROW')\n",
      "('IF', 'if_true', 'CONTINUE')\n",
      "('CONTINUE', 'next', 'BEGIN_LOOP')\n",
      "('IF', 'if_true', 'BREAK')\n",
      "('BREAK', 'next', 'END_LOOP')\n",
      "('IF_LOOP', 'if_true', 'END_LOOP')\n",
      "('IF_LOOP', 'if_false', 'IF')\n",
      "('END_LOOP', 'next', 'IF')\n",
      "('EXPRESSION', 'next', 'INLINE ASM')\n",
      "('END_LOOP', 'next', 'INLINE ASM')\n",
      "('IF', 'if_true', 'INLINE ASM')\n",
      "('INLINE ASM', 'next', 'END_IF')\n",
      "('IF', 'if_true', '_')\n",
      "('_', 'next', 'END_IF')\n",
      "('EXPRESSION', 'next', 'BREAK')\n",
      "('END_IF', 'next', 'IF_LOOP')\n",
      "('END_IF', 'next', 'INLINE ASM')\n",
      "('END_LOOP', 'next', 'NEW VARIABLE')\n",
      "('ENTRY_POINT', 'next', 'INLINE ASM')\n",
      "('_', 'next', 'EXPRESSION')\n",
      "('IF', 'if_false', 'THROW')\n",
      "('END_LOOP', 'next', 'BEGIN_LOOP')\n",
      "('END_LOOP', 'next', 'IF_LOOP')\n",
      "('EXPRESSION', 'next', 'CONTINUE')\n",
      "('IF_LOOP', 'if_true', 'BEGIN_LOOP')\n",
      "('IF', 'if_false', '_')\n",
      "('_', 'next', 'IF')\n",
      "('INLINE ASM', 'next', 'IF')\n",
      "('END_IF', 'next', 'BEGIN_LOOP')\n",
      "('BEGIN_LOOP', 'next', 'EXPRESSION')\n",
      "('ENTRY_POINT', 'next', 'BEGIN_LOOP')\n",
      "('IF_LOOP', 'if_true', 'INLINE ASM')\n",
      "('INLINE ASM', 'next', 'NEW VARIABLE')\n",
      "('INLINE ASM', 'next', 'BEGIN_LOOP')\n",
      "('INLINE ASM', 'next', 'IF_LOOP')\n",
      "('EXPRESSION', 'next', 'THROW')\n",
      "('END_IF', 'next', 'THROW')\n",
      "('IF_LOOP', 'if_true', 'IF_LOOP')\n",
      "('IF', 'if_false', 'INLINE ASM')\n"
     ]
    }
   ],
   "source": [
    "for keys, edge_index in geo_graph_data.items():\n",
    "    sizes = (num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]])\n",
    "    row, col = edge_index\n",
    "    print(keys)\n",
    "#     adj = SparseTensor(row=row, col=col, sparse_sizes=sizes)\n",
    "#     adj = adj.to('cpu')\n",
    "#     adj_dict[keys] = adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0447813e-7156-40f1-a6ae-f4770a933924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaPath2Vec(28466, 128)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MetaPath2Vec(geo_graph_data, embedding_dim=128,\n",
    "                     metapath=bidirect_geo_meta_path_types, walk_length=2, context_size=2,\n",
    "                     walks_per_node=1, num_negative_samples=5, num_nodes_dict=num_nodes_dict,\n",
    "                     sparse=True).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e9697c2-27ce-4e37-a8ba-8a1c778028da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': range(0, 2118), 'num_workers': 0, 'prefetch_factor': 2, 'pin_memory': False, 'timeout': 0, 'worker_init_fn': None, '_DataLoader__multiprocessing_context': None, '_dataset_kind': 0, 'batch_size': 1, 'drop_last': True, 'sampler': <torch.utils.data.sampler.SequentialSampler object at 0x7fca726ad490>, 'batch_sampler': <torch.utils.data.sampler.BatchSampler object at 0x7fca726ade90>, 'generator': None, 'collate_fn': <bound method MetaPath2Vec.sample of MetaPath2Vec(28466, 128)>, 'persistent_workers': False, '_DataLoader__initialized': True, '_IterableDataset_len_called': None, '_iterator': None}\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0463,  0.8867, -0.6852,  ...,  0.2716, -0.6193,  0.4267],\n",
      "        [-0.4505,  0.6084, -1.4680,  ...,  1.0100, -0.1702,  0.3225],\n",
      "        [ 0.5846, -0.2967,  1.7025,  ...,  0.1056, -2.2379,  1.8692],\n",
      "        ...,\n",
      "        [ 1.7640, -0.2811,  0.3371,  ...,  1.5825,  0.6105, -1.0502],\n",
      "        [-0.8129,  1.0114,  0.3339,  ..., -1.1144, -0.2738, -0.6533],\n",
      "        [-0.2343,  0.4974,  0.2016,  ...,  0.3355,  0.6733, -0.4386]],\n",
      "       device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "loader = model.loader(batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "print(loader.__dict__)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "087d39f3-d69f-4e7c-955a-aa63c56f3014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = model.loader(batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.001)\n",
    "\n",
    "def train(epoch, log_steps=100, eval_steps=2000):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "#         print(i)\n",
    "#         print((pos_rw.shape, neg_rw.shape))\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
    "            total_loss = 0\n",
    "\n",
    "        if (i + 1) % eval_steps == 0:\n",
    "            acc = test()\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Acc: {acc:.4f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4b0f058b-59f0-4ac7-b5c2-19236286e278",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "dimension specified as 0 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_128410/1667234467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_geometric/nn/models/metapath2vec.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_geometric/nn/models/metapath2vec.py\u001b[0m in \u001b[0;36mpos_sample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetapath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mrws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_sparse/sample.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(src, num_neighbors, subset)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrowptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrowptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: dimension specified as 0 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "    print(i, pos_rw.shape, neg_rw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "643da8f2-9a77-4d63-b9d4-e045ef72d70d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1660 is out of bounds for dimension 0 with size 1660",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_128410/4163989017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for epoch in range(1, 6):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     train(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     acc = test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_128410/2367136119.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_steps, eval_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         print((pos_rw.shape, neg_rw.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_geometric/nn/models/metapath2vec.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_geometric/nn/models/metapath2vec.py\u001b[0m in \u001b[0;36mpos_sample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetapath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mrws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_sparse/sample.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(src, num_neighbors, subset)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1660 is out of bounds for dimension 0 with size 1660"
     ]
    }
   ],
   "source": [
    "train(1)\n",
    "            \n",
    "# for epoch in range(1, 6):\n",
    "#     train(epoch)\n",
    "#     acc = test()\n",
    "#     print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3707154-b9b9-4d47-be44-4f82386d13ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metapath2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e91f5c24-6aff-4567-b59a-dff93b0f1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MetaPath2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53b6e031-588f-4216-8ef0-edc8dbb24eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46b9eda9-dea0-4ed5-9a33-08b5c90d2cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('ENTRY_POINT', 'next', 'EXPRESSION'), ('FUNCTION_NAME', 'next', 'ENTRY_POINT'), ('EXPRESSION', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'RETURN'), ('EXPRESSION', 'next', '_'), ('ENTRY_POINT', 'next', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'RETURN'), ('ENTRY_POINT', 'next', 'IF'), ('IF', 'if_true', 'RETURN'), ('IF', 'if_false', 'RETURN'), ('ENTRY_POINT', 'next', 'RETURN'), ('BEGIN_LOOP', 'next', 'IF_LOOP'), ('NEW VARIABLE', 'next', 'BEGIN_LOOP'), ('IF_LOOP', 'if_false', 'END_LOOP'), ('IF_LOOP', 'if_true', 'EXPRESSION'), ('EXPRESSION', 'next', 'IF_LOOP'), ('NEW VARIABLE', 'next', 'NEW VARIABLE'), ('END_LOOP', 'next', 'EXPRESSION'), ('IF_LOOP', 'if_true', 'IF'), ('IF', 'if_false', 'END_IF'), ('END_IF', 'next', 'EXPRESSION'), ('END_LOOP', 'next', 'RETURN'), ('IF', 'if_true', 'EXPRESSION'), ('EXPRESSION', 'next', 'END_IF'), ('IF', 'if_true', 'IF'), ('IF', 'if_false', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'IF'), ('IF', 'if_true', 'NEW VARIABLE'), ('END_LOOP', 'next', 'END_IF'), ('END_IF', 'next', 'NEW VARIABLE'), ('END_IF', 'next', 'END_IF'), ('EXPRESSION', 'next', 'IF'), ('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT'), ('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT'), ('END_IF', 'next', 'IF'), ('IF', 'if_true', 'THROW'), ('END_IF', 'next', '_'), ('IF_LOOP', 'if_true', 'NEW VARIABLE'), ('IF', 'if_false', 'EXPRESSION'), ('IF', 'if_false', 'IF'), ('END_IF', 'next', 'RETURN'), ('NEW VARIABLE', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'RETURN'), ('EXPRESSION', 'next', 'BEGIN_LOOP'), ('IF', 'if_true', 'END_IF'), ('INLINE ASM', 'next', 'EXPRESSION'), ('ENTRY_POINT', 'next', 'THROW'), ('IF', 'if_true', 'CONTINUE'), ('CONTINUE', 'next', 'BEGIN_LOOP'), ('IF', 'if_true', 'BREAK'), ('BREAK', 'next', 'END_LOOP'), ('IF_LOOP', 'if_true', 'END_LOOP'), ('IF_LOOP', 'if_false', 'IF'), ('END_LOOP', 'next', 'IF'), ('EXPRESSION', 'next', 'INLINE ASM'), ('END_LOOP', 'next', 'INLINE ASM'), ('IF', 'if_true', 'INLINE ASM'), ('INLINE ASM', 'next', 'END_IF'), ('IF', 'if_true', '_'), ('_', 'next', 'END_IF'), ('EXPRESSION', 'next', 'BREAK'), ('END_IF', 'next', 'IF_LOOP'), ('END_IF', 'next', 'INLINE ASM'), ('END_LOOP', 'next', 'NEW VARIABLE'), ('ENTRY_POINT', 'next', 'INLINE ASM'), ('_', 'next', 'EXPRESSION'), ('IF', 'if_false', 'THROW'), ('END_LOOP', 'next', 'BEGIN_LOOP'), ('END_LOOP', 'next', 'IF_LOOP'), ('EXPRESSION', 'next', 'CONTINUE'), ('IF_LOOP', 'if_true', 'BEGIN_LOOP'), ('IF', 'if_false', '_'), ('_', 'next', 'IF'), ('INLINE ASM', 'next', 'IF'), ('END_IF', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'EXPRESSION'), ('ENTRY_POINT', 'next', 'BEGIN_LOOP'), ('IF_LOOP', 'if_true', 'INLINE ASM'), ('INLINE ASM', 'next', 'NEW VARIABLE'), ('INLINE ASM', 'next', 'BEGIN_LOOP'), ('INLINE ASM', 'next', 'IF_LOOP'), ('EXPRESSION', 'next', 'THROW'), ('END_IF', 'next', 'THROW'), ('IF_LOOP', 'if_true', 'IF_LOOP'), ('IF', 'if_false', 'INLINE ASM')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_graph_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2ba982b-9273-4bdb-a090-2b6fea13a7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28466, 128])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metapath_embedding = MetaPath2Vec(geo_graph_data, embedding_dim=128,\n",
    "                     metapath=bidirect_geo_meta_path_types, walk_length=20, context_size=15,\n",
    "                     walks_per_node=1, num_negative_samples=5, num_nodes_dict=None,\n",
    "                     sparse=True).to(device)\n",
    "\n",
    "# metapath_embedding.eval()\n",
    "metapath_embedding.embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "533f60b2-e3f6-4c06-8a88-77647ec4831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33872, 128])\n"
     ]
    }
   ],
   "source": [
    "features = None\n",
    "for node in bi_dgl_hete_graph.ntypes:\n",
    "    if features is None:\n",
    "        features = metapath_embedding(n)\n",
    "    else:\n",
    "        features = torch.cat((features, metapath_embedding(n)))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e270d127-4aba-4b46-8996-2a432df4f6bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('FUNCTION_NAME', 'next', 'ENTRY_POINT'), tensor([[ 2,  8, 12,  ..., 22, 28, 33],\n",
      "        [ 0,  3,  9,  ..., 15, 23, 29]]))\n",
      "(('EXPRESSION', 'next', '_'), tensor([[ 10,  83,  87,  ..., 748, 752, 759],\n",
      "        [ 11,  84,  88,  ..., 749, 753, 760]]))\n",
      "(('ENTRY_POINT', 'next', 'EXPRESSION'), tensor([[ 0,  3,  9,  ..., 15, 23, 29],\n",
      "        [ 1,  7, 10,  ..., 16, 24, 30]]))\n",
      "(('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT'), tensor([[  83,   39,   76,   80,  144,   16,  622,  784,   20,  150,  214,  260,\n",
      "          456,  463,  551,   20,   21,  485,  493,  189,  256,  157,  327,  331,\n",
      "          108,  169,  272,  301,   86,  194,  202,   10,   30,   77,   50,  199,\n",
      "          176,  180,  192,  748,  751,   81,  606,  244,   24,  345,  711,  718,\n",
      "           79,   52,   23,   88,   90,  189,  289,  350,  352,  364,  664,  684,\n",
      "          251,  524,  532,  201,   29,   67,  181,  183,  235,  143,  362,  163,\n",
      "          166,   46,   28,  112,  114,  401,  357,  360,  142,  186,  408,  410,\n",
      "          534,  235,  237,  440,  780,  787,   69,  144,  353,  429,  371,   16,\n",
      "           38,   40,   30,  216,    8,   20,  268,  278,   13,  167,   28,   52,\n",
      "          258,   13,   61,  164,  458,  775,  893,   94,  134,  158,  257,  393,\n",
      "          466,  678,    8,  130,  317,  508,  712, 1020,  495, 1144,   43,  151,\n",
      "          350,   56,  301,  308,   87,  162,  193,  208,  243,  606,  609,  191,\n",
      "          194,  124,   35,   87,  144,  205,   12,  426,  175,  377,  634,  637,\n",
      "           50,   81,  340,  206,   20,   19,   28,  117,  243,  345,  470,  353,\n",
      "          357,  104,  312,   53,  118,  135,  501,  516,  568,  808,  823, 1068,\n",
      "         1083, 1199, 1311, 1689,   78,  307,  508,  199,   47,  119,  200,   63,\n",
      "          187,  560,  579,   27,   71,   81,   87,  411,  418,  487,  246,   20,\n",
      "           83,   85,  214,  216,  399,  401,  647,  650,  912,  915, 1231, 1234,\n",
      "         1640, 1643, 2110, 2113,   91,   60,  140,  238,  375,  380,  706,  784,\n",
      "          929,  250,  160,  353,  296,  611,  614,  189,   37,    5,   59,   87,\n",
      "          443,  641,  647,  829,  845,  303,  384,  388,   93,  169,  265,  371,\n",
      "           74,  131,   93,  279,  154,  257,  286,  422,  764,  766,   35,  179,\n",
      "          140,  229,  412,  415,  737,  740,   38],\n",
      "        [  79,   38,   73,   77,  143,   15,  619,  780,   19,  146,  213,  257,\n",
      "          454,  457,  550,   19,   20,  478,  486,  178,  253,  156,  323,  328,\n",
      "          107,  167,  269,  300,   85,  193,  195,    9,   29,   76,   48,  181,\n",
      "          169,  177,  191,  742,  749,   78,  603,  240,   23,  344,  706,  712,\n",
      "           78,   50,   22,   79,   89,  180,  284,  345,  351,  353,  663,  665,\n",
      "          248,  520,  525,  192,   28,   66,  179,  182,  231,  139,  355,  160,\n",
      "          164,   45,   27,  109,  113,  392,  355,  358,  137,  185,  401,  409,\n",
      "          531,  234,  236,  437,  775,  781,   65,  143,  350,  428,  356,   14,\n",
      "           36,   39,   29,  199,    7,   19,  263,  269,   12,  161,   27,   51,\n",
      "          257,   12,   60,  161,  454,  771,  890,   93,  132,  155,  256,  392,\n",
      "          463,  673,    5,  127,  316,  507,  709, 1017,  483, 1128,   42,  150,\n",
      "          349,   55,  300,  302,   85,  160,  192,  207,  241,  600,  607,  183,\n",
      "          193,  109,   34,   86,  143,  203,   11,  425,  173,  375,  631,  635,\n",
      "           49,   80,  339,  204,   19,   16,   27,  116,  242,  344,  468,  352,\n",
      "          354,  101,  307,   52,  117,  121,  498,  502,  567,  805,  809, 1065,\n",
      "         1069, 1195, 1310, 1688,   75,  305,  501,  185,   46,  117,  198,   62,\n",
      "          169,  559,  561,   26,   70,   80,   82,  410,  412,  485,  243,   19,\n",
      "           80,   84,  211,  215,  396,  400,  644,  648,  909,  913, 1228, 1232,\n",
      "         1637, 1641, 2107, 2111,   87,   58,  139,  237,  374,  376,  705,  783,\n",
      "          928,  249,  158,  351,  295,  610,  612,  188,   35,    0,   44,   86,\n",
      "          442,  636,  642,  826,  830,  297,  380,  385,   92,  168,  257,  360,\n",
      "           69,  127,   92,  273,  152,  254,  285,  419,  756,  765,   34,  178,\n",
      "          138,  227,  410,  413,  735,  738,   34]]))\n",
      "(('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT'), tensor([[79, 80, 81,  ..., 34, 35, 36],\n",
      "        [80, 81, 82,  ..., 35, 36, 37]]))\n",
      "(('EXPRESSION', 'next', 'EXPRESSION'), tensor([[ 4,  7, 42,  ..., 26, 30, 31],\n",
      "        [ 5,  4, 43,  ..., 27, 31, 32]]))\n",
      "(('NEW VARIABLE', 'next', 'EXPRESSION'), tensor([[ 14,  24,  64,  ..., 730,  18,  25],\n",
      "        [ 15,  25,  65,  ..., 731,  19,  26]]))\n",
      "(('ENTRY_POINT', 'next', 'NEW VARIABLE'), tensor([[ 13,  23, 138,  ..., 424, 708, 755],\n",
      "        [ 14,  24, 139,  ..., 425, 709, 756]]))\n",
      "(('NEW VARIABLE', 'next', 'RETURN'), tensor([[  20,  145,  592,    6,  190,  198,    9,  128,  163,   24,  243,  248,\n",
      "          287,  308,  313,  352,  532,  537,  576,  705,  744,  801,  850,  855,\n",
      "          894, 1058, 1097, 1154, 1191, 1196, 1235, 1438, 1472,   23,   27,   92,\n",
      "           96,  373,    9,   10,   15,  575,  685,  689,   20,   25,  104,  136,\n",
      "          141,  235,  441,  503,   60,  297,  305,    9,  218,  246,  230,  238,\n",
      "            9,  188,  173,  111,  208,  280,  433,    6,  339,    9,  123,  275,\n",
      "          177,  149,  170,  179,  186,  194,  245,  251,  315,  349,  662,    6,\n",
      "            9,  258,  422,  618,  879,  281,  443,  576,  732, 1048,  195,   92,\n",
      "          254,  191,    9,    9,   62,    4,  590,  403,  156,  214,  297, 2092,\n",
      "           88,  471,  507,  537,  548,  552,  689,  754,  855,  866,  870,  910,\n",
      "          161,  384,  123,  145,  130,    6,   18,  593,   57],\n",
      "        [  21,  146,  593,    7,  191,  199,   10,  129,  164,   25,  244,  249,\n",
      "          288,  309,  314,  353,  533,  538,  577,  706,  745,  802,  851,  856,\n",
      "          895, 1059, 1098, 1155, 1192, 1197, 1236, 1439, 1473,   24,   28,   93,\n",
      "           97,  374,   10,   11,   16,  576,  686,  690,   21,   26,  105,  137,\n",
      "          142,  236,  442,  504,   61,  298,  306,   10,  219,  247,  231,  239,\n",
      "           10,  189,  174,  112,  209,  281,  434,    7,  340,   10,  124,  276,\n",
      "          178,  150,  171,  180,  187,  195,  246,  252,  316,  350,  663,    7,\n",
      "           10,  259,  423,  619,  880,  282,  444,  577,  733, 1049,  196,   93,\n",
      "          255,  192,   10,   10,   63,    5,  591,  404,  157,  215,  298, 2093,\n",
      "           89,  472,  508,  538,  549,  553,  690,  755,  856,  867,  871,  911,\n",
      "          162,  385,  124,  146,  131,    7,   19,  594,   58]]))\n",
      "(('END_IF', 'next', 'EXPRESSION'), tensor([[201, 259, 280,  ..., 669, 674, 704],\n",
      "        [202, 260, 281,  ..., 670, 675, 705]]))\n",
      "(('EXPRESSION', 'next', 'END_IF'), tensor([[258, 266, 279,  ..., 673,   5,  12],\n",
      "        [259, 287, 280,  ..., 674,   6,  13]]))\n",
      "(('IF', 'if_false', 'EXPRESSION'), tensor([[ 327,  359,  574,  686,   73,  118,  408,   28,   44,   74,   90,  107,\n",
      "          402,  406,  421,  536,   81,  122,  216,   53,  144,  276,  341,  363,\n",
      "          565,  587,  725,  883,  905, 1078, 1224, 1246, 1367, 1496, 1554,  150,\n",
      "          208,  239,  179,   34,   38,  110,  147,  271,  419,  442,  478,  510,\n",
      "          569,  615,  271,  277,  286,  294,  376,  485,  117,   20,   29,   95,\n",
      "          104,   73,  105,  211,   57,  125,  142,  159,  190,  207,  225,  250,\n",
      "          614,  618,  639,  151,  163,   17,   31,  197,  595,  607,  611,  619,\n",
      "          638,  650,  704,   21,   75,   92,  109,  115,  132,  138,  153,  159,\n",
      "          169,  231,   65,   82,  114,  131,  149,  448,  452,  467,  579,   74,\n",
      "          106,  136,   73,  105,   87,   51,   55,   96,  101,  140,  144,  184,\n",
      "          189,  226,  231,  268,  273,  310,  315,  454,  463,  485,  597,  606,\n",
      "          629,   20,   75,  158,  163,  265,  329,  101,  117,   91,  154,   58,\n",
      "          220,  193,   34,   73,  101,  253,  315,   53,  297,  225,  230,  298,\n",
      "          128,  183,  212,  224,  225,  399,  448,  234,  295,  276,  440,  636,\n",
      "          897,   97,  147,  263,  426,  558,  715,  937,  980, 1000, 1004, 1012,\n",
      "         1036,  110,  272,  128,  142,  197,  258,  395,  404,  484,  504,  565,\n",
      "           74,  106,   92,   97,  262,  356,    7,   47,  103,  168,  181,  287,\n",
      "          351,  419,  159,  327,  566,   73,  131,  166,  331,  345,  420,  251,\n",
      "          123,  435,   47,   74,  191,  253,  261,  269,  271,  330,  241,  248,\n",
      "          294,  351,   98,  267,  317,  434,  728, 1024, 1456, 1472, 1515, 1607,\n",
      "          117,  141,  121,  202,   25,  318,  425,    6,   38,   95,  211,  358,\n",
      "          456,   10,   42,  140,  204,   76,  144,  169,  193,  238,  262,  338,\n",
      "          477,  501,  577,  789,  813,  889,  905,  928, 1070, 1094, 1170, 1203,\n",
      "         1264, 1301, 1443, 1467, 1543, 1767, 1804, 1946, 1970, 2046,   66,   23,\n",
      "           49,   79,   60,   92,  199,  317,  774,  803,  893,  923,   28,   35,\n",
      "           36,  144,  176,  195,   37,   44,   45,  207,  224,  226,  279,  430,\n",
      "          447,  449,  502,  563,   92,  343,  401,  551,  182,   62,   70,   78,\n",
      "           86,  124,  149,  174,   18,   91,  135,  193,  224,  347,  402,  494,\n",
      "          549,  112,  133,  192,  344,  626],\n",
      "        [ 329,  361,  576,  688,   75,  120,  410,   30,   46,   76,   92,  118,\n",
      "          404,  408,  424,  541,   83,  124,  218,   55,  146,  278,  343,  365,\n",
      "          567,  589,  731,  885,  907, 1084, 1226, 1248, 1369, 1498, 1560,  153,\n",
      "          211,  241,  181,   42,   40,  115,  149,  273,  421,  447,  480,  515,\n",
      "          571,  617,  273,  282,  303,  299,  378,  487,  121,   22,   36,   97,\n",
      "          111,   75,  107,  213,   62,  127,  144,  161,  192,  209,  236,  261,\n",
      "          616,  620,  642,  153,  169,   19,   33,  199,  599,  609,  613,  621,\n",
      "          641,  652,  706,   23,   83,   99,  111,  118,  134,  141,  155,  162,\n",
      "          172,  245,   67,   84,  116,  133,  160,  450,  454,  470,  584,   76,\n",
      "          108,  138,   75,  107,   89,   74,   65,  120,  111,  163,  154,  208,\n",
      "          199,  250,  241,  292,  283,  330,  321,  479,  470,  487,  599,  608,\n",
      "          631,   22,   77,  160,  168,  271,  331,  108,  119,   93,  156,   60,\n",
      "          231,  195,   36,   75,  103,  255,  317,   55,  300,  227,  234,  302,\n",
      "          130,  198,  214,  229,  227,  402,  450,  236,  297,  280,  444,  640,\n",
      "          901,  103,  149,  265,  428,  560,  717,  939,  985, 1011, 1007, 1019,\n",
      "         1038,  114,  276,  131,  144,  202,  260,  399,  408,  487,  506,  567,\n",
      "           76,  108,   94,   99,  264,  358,    9,   49,  105,  170,  186,  292,\n",
      "          353,  421,  161,  329,  568,   75,  133,  169,  333,  347,  435,  255,\n",
      "          129,  437,   49,   79,  198,  255,  266,  280,  273,  332,  243,  250,\n",
      "          296,  353,  100,  275,  322,  436,  730, 1026, 1458, 1477, 1517, 1609,\n",
      "          120,  143,  123,  204,   29,  322,  430,    8,   40,   97,  213,  360,\n",
      "          458,   12,   44,  142,  206,   78,  146,  174,  197,  243,  266,  340,\n",
      "          482,  505,  579,  794,  817,  891,  907,  930, 1075, 1098, 1172, 1205,\n",
      "         1266, 1303, 1448, 1471, 1545, 1769, 1806, 1951, 1974, 2048,   70,   27,\n",
      "           53,   81,   62,   94,  201,  319,  776,  805,  898,  925,   30,   40,\n",
      "           38,  146,  178,  201,   39,   49,   47,  210,  231,  228,  285,  433,\n",
      "          454,  451,  508,  566,   94,  345,  403,  553,  184,   64,   72,   80,\n",
      "           88,  126,  151,  176,   22,   93,  138,  196,  226,  349,  405,  496,\n",
      "          552,  114,  135,  194,  346,  628]]))\n",
      "(('IF', 'if_true', 'EXPRESSION'), tensor([[256, 265, 278,  ..., 725,   4,  11],\n",
      "        [257, 266, 279,  ..., 726,   5,  12]]))\n",
      "(('NEW VARIABLE', 'next', 'IF'), tensor([[271, 283, 297,  ..., 157, 167, 709],\n",
      "        [272, 284, 298,  ..., 158, 168, 710]]))\n",
      "(('NEW VARIABLE', 'next', 'NEW VARIABLE'), tensor([[ 72, 119, 223,  ..., 425, 729, 756],\n",
      "        [ 73, 120, 224,  ..., 426, 730, 757]]))\n",
      "(('EXPRESSION', 'next', 'NEW VARIABLE'), tensor([[ 19,  54,  63,  ..., 172,  17,  24],\n",
      "        [ 20,  57,  64,  ..., 167,  18,  25]]))\n",
      "(('IF', 'if_false', 'END_IF'), tensor([[199, 256, 264,  ..., 742,   4,  11],\n",
      "        [201, 259, 288,  ..., 744,   6,  13]]))\n",
      "(('ENTRY_POINT', 'next', 'IF'), tensor([[ 28,  33, 153,  ..., 716, 741,   3],\n",
      "        [ 29,  34, 154,  ..., 717, 742,   4]]))\n",
      "(('ENTRY_POINT', 'next', 'RETURN'), tensor([[ 50,  97, 166,  ..., 558, 661, 678],\n",
      "        [ 51,  98, 167,  ..., 559, 662, 679]]))\n",
      "(('EXPRESSION', 'next', 'RETURN'), tensor([[  5,  15,  25,  ..., 675, 705, 726],\n",
      "        [  6,  16,  26,  ..., 676, 706, 727]]))\n",
      "(('IF', 'if_false', 'RETURN'), tensor([[  29,   34,  154,  159,   32,   38,   55,   16,   24,   53,   61,  586,\n",
      "           10,   15,   20,   25,   39,   44,   49,   54,   19,   24,   29,   34,\n",
      "          163,  170,  171,  178,  179,  295,  302,  414,   21,   29,   69,   77,\n",
      "           77,  159,  170,   84,   85,   91,   92,  172,  207,  216,  225,  245,\n",
      "          265,  655,  696,  697,  700,   37,  153,   32,  107,  299,  310,  316,\n",
      "          272,  279,  280,  287,  288,  478,  485,  557,  625,  205,  212,  213,\n",
      "          220,  221,  330,  337,  389,  459,   34,   39,   44,   49,   79,   84,\n",
      "           89,   94,  174,  179,  184,  189,   29,   21,   26,   31,   36,  344,\n",
      "          412,  417,  422,  427,  483,  488,  493,  498,  653,  654,  439,   35,\n",
      "           79,   90,  176,  187,  302,  446,  451,  456,  461,   21,   26,   31,\n",
      "           36,  322,  327,  332,  337,  367,  372,  377,  382,  462,  467,  472,\n",
      "          477,  568,  688,   44,   52,   91,   99,  138,   85,  155,   25,   33,\n",
      "           53,   61,   43,   44,  163,  164,  169,  170,  253,   77,  257,  330,\n",
      "          561,  868,  105,  293,  588, 1054, 1098,   49,   54,  284,  289,  417,\n",
      "          424,  435,  440,  151,  272,  279,   11,   26,   78,   83,  100,  105,\n",
      "          110,  115,  195,  246,  251,  268,  273,  278,  283,  429,  485,  490,\n",
      "          507,  512,  517,  522,  526,   65,   73,   82,  112,  120,  129,   25,\n",
      "           33,   55,   63, 1140, 1153, 1159,   65,  457,   44,   52,   91,   99,\n",
      "          136,  175,   16,  309,  169,    1,    6,   11,   16,  203,  272,  511,\n",
      "          823, 1104, 1477, 1980,    8,   17,   22,   56,   26,   31,  133,  183,\n",
      "          191,  100,  167,   19,   53,   92,   97,  102,  107,  151,  156,  161,\n",
      "          166,  259,  303,  308,  313,  318,  541,  585,  590,  595,  600],\n",
      "        [  31,   36,  156,  161,   35,   43,   61,   21,   30,   58,   67,  588,\n",
      "           12,   17,   22,   27,   41,   46,   51,   56,   21,   26,   31,   36,\n",
      "          165,  175,  173,  184,  181,  297,  304,  416,   26,   35,   74,   83,\n",
      "           79,  164,  176,   89,   87,   96,   94,  174,  209,  218,  228,  248,\n",
      "          267,  657,  705,  704,  702,   39,  155,   34,  109,  307,  312,  318,\n",
      "          274,  284,  282,  292,  290,  480,  487,  559,  627,  207,  217,  215,\n",
      "          225,  223,  332,  339,  391,  461,   36,   41,   46,   51,   81,   86,\n",
      "           91,   96,  176,  181,  186,  191,   31,   23,   28,   33,   38,  346,\n",
      "          414,  419,  424,  429,  485,  490,  495,  500,  658,  656,  441,   37,\n",
      "           81,   92,  178,  189,  304,  448,  453,  458,  463,   23,   28,   33,\n",
      "           38,  324,  329,  334,  339,  369,  374,  379,  384,  464,  469,  474,\n",
      "          479,  574,  690,   49,   58,   96,  105,  140,   87,  157,   30,   39,\n",
      "           58,   67,   48,   46,  168,  166,  173,  172,  255,   79,  259,  332,\n",
      "          563,  870,  107,  295,  590, 1056, 1100,   51,   56,  286,  291,  419,\n",
      "          426,  437,  442,  155,  274,  281,   13,   28,   80,   85,  102,  107,\n",
      "          112,  117,  197,  248,  253,  270,  275,  280,  285,  431,  487,  492,\n",
      "          509,  514,  519,  524,  528,   70,   79,   86,  117,  126,  133,   30,\n",
      "           39,   60,   69, 1150, 1155, 1161,   67,  459,   49,   58,   96,  105,\n",
      "          138,  177,   18,  311,  171,    3,    8,   13,   18,  205,  274,  513,\n",
      "          825, 1106, 1479, 1982,   10,   19,   24,   58,   28,   33,  135,  185,\n",
      "          205,  102,  169,   21,   55,   94,   99,  104,  109,  153,  158,  163,\n",
      "          168,  261,  305,  310,  315,  320,  543,  587,  592,  597,  602]]))\n",
      "(('IF', 'if_true', 'RETURN'), tensor([[ 29,  34, 154,  ..., 595, 600, 710],\n",
      "        [ 30,  35, 155,  ..., 596, 601, 711]]))\n",
      "(('IF', 'if_true', 'NEW VARIABLE'), tensor([[ 272,  298,   23,   96,   66,   80,  107,  235,  241,  252,  274,  339,\n",
      "          563,  725,  881, 1078, 1222, 1343, 1554, 1578,  171,  206,  353,   64,\n",
      "           80,  101,  279,  155,  234,  254,  276,  434,  442,  501,  510,   98,\n",
      "           29,  104,  225,  250,  357,  363,  377,  417,  423,  437,   33,   58,\n",
      "           16,   75,  231,  149,  275,  289,   46,  184,  226,  268,  310,  454,\n",
      "          515,  648,  265,  383,  395,  151,  220,  337,  155,  174,  252,  266,\n",
      "          136,  107,   11,  110,  126,  136,  204,  152,  233,  636,  844,  635,\n",
      "           51,  135,  215,  331,  197,  219,  234,  268,  497,  508,   89,  170,\n",
      "          100,  248,  284,  420,  123,  104,  172,  304,   74,   96,  111,  155,\n",
      "          191,  243, 1118, 1293, 1329, 1566,   54,  330,  184,  197,  897,  920,\n",
      "         1208, 1221, 1269, 1282, 1293, 1772, 1785, 1796,   14,   23,   41,   49,\n",
      "           31,   89,  786,  270,  322,   18,    1,   32,  158,  654,  671],\n",
      "        [ 273,  299,   24,   97,   67,   81,  108,  236,  242,  253,  275,  340,\n",
      "          564,  726,  882, 1079, 1223, 1344, 1555, 1579,  172,  207,  354,   65,\n",
      "           81,  102,  280,  156,  235,  255,  277,  435,  443,  504,  511,   99,\n",
      "           30,  105,  226,  251,  358,  364,  378,  418,  424,  438,   34,   59,\n",
      "           17,   76,  232,  150,  276,  290,   47,  185,  227,  269,  311,  455,\n",
      "          516,  651,  266,  384,  396,  152,  221,  338,  156,  175,  253,  267,\n",
      "          137,  108,   12,  113,  127,  137,  207,  153,  234,  637,  845,  636,\n",
      "           52,  136,  216,  332,  198,  220,  235,  269,  498,  509,   90,  171,\n",
      "          101,  249,  285,  421,  124,  105,  173,  305,   75,   97,  112,  156,\n",
      "          194,  244, 1119, 1294, 1330, 1567,   55,  331,  185,  198,  898,  921,\n",
      "         1209, 1222, 1270, 1283, 1294, 1773, 1786, 1797,   15,   24,   42,   50,\n",
      "           32,   90,  787,  271,  323,   19,    2,   33,  159,  655,  672]]))\n",
      "(('EXPRESSION', 'next', 'IF'), tensor([[ 22,  63,   6,  ..., 670, 733,  10],\n",
      "        [ 23,  64,   7,  ..., 671, 725,  11]]))\n",
      "(('END_IF', 'next', 'NEW VARIABLE'), tensor([[ 282,  308,  109,    3,   76,  197,  530,    3,  151,   82,   98,  173,\n",
      "          189,  260,  325,  392,  408,  549,  616,  632,  758,  766,  867,  934,\n",
      "          950, 1111, 1119, 1208, 1275, 1291, 1600, 1604,  175,  295,  310,  332,\n",
      "          351,    3,   58,    3,  209,  100,  141,  184,  391,  508,  591,  602,\n",
      "          586,   95,  159,    3,   51,  304,  637,  108,  301,  622,    6,   50,\n",
      "          206,  237,  573,    3,  169,  548,  620,  624,   43,   86,  130,  175,\n",
      "          217,  259,  301,  339,  378,  493,  537,   36,   13,   27,   42,   53,\n",
      "           57,   67,  279,  161,  553,  590,  652,  669,  755,  108,  334,    3,\n",
      "          160,  208,  343,  168,  309,   48,   89,  111,  124,  140,  170,  192,\n",
      "          205,  221,  286,  324,  328,  387,  392,  396,  417,  522,  573,  595,\n",
      "          608,  624,  706,  712,  727,  781,  803,  816,  832,   31,   48,    3,\n",
      "          640,  181,  193,  257,  265,  272,  345,  357,  421,  429,  436,  541,\n",
      "          553,  617,  625,  632,  802,  814,  878,  886,  893,   77,   91,  145,\n",
      "          150,  161,  258,  326,  346,  449,  464,  553,  615,  635,  738,  753,\n",
      "          817,  833,  940, 1071, 1088,   15,   27,   91,   99,  106,  177,  189,\n",
      "          253,  261,  268,  216,  261,  265,  526,  547,    3,  162,    3,  221,\n",
      "          360,   90,  104,  123,  154,  176,  199,  207,  221,  225,  233,  376,\n",
      "            6,  150,  202,  293,  328,    8,  190,   83,  121,  411,  427,    3,\n",
      "           93,  333,  337,  184,  208,  584, 1498,   24,  137,  170,  328,  341,\n",
      "          491,  160,   50,   54,  154,  212,  343,  347,  461,  469,  549,  198,\n",
      "          259,  207,   88,  465,  899,  191,  210,  214,  437,  570,   49,  192,\n",
      "          235,  239,  243,  314,  121,   29,    3,   25,   52,   59,   66,   75,\n",
      "           92,  108,  118,  132,  143,  155,  161,  174,  180,  194,  206,  241,\n",
      "          334,  342,  364,  387,  399,  412,  427,  441,  460,   51,  728],\n",
      "        [ 283,  309,  110,    4,   77,  198,  531,    4,  152,   83,   99,  174,\n",
      "          190,  261,  326,  393,  409,  550,  617,  633,  759,  767,  868,  935,\n",
      "          951, 1112, 1120, 1209, 1276, 1292, 1601, 1605,  176,  296,  311,  333,\n",
      "          352,    4,   59,    4,  210,  101,  142,  185,  394,  509,  594,  603,\n",
      "          587,   96,  162,    4,   52,  305,  638,  109,  302,  590,    7,   51,\n",
      "          207,  238,  574,    4,  170,  549,  621,  625,   44,   87,  131,  176,\n",
      "          218,  260,  302,  340,  379,  494,  538,   37,   14,   28,   43,   54,\n",
      "           58,   68,  280,  162,  554,  591,  653,  670,  756,  109,  335,    4,\n",
      "          161,  209,  344,  169,  310,   49,   90,  112,  125,  143,  171,  193,\n",
      "          206,  224,  287,  325,  329,  388,  393,  397,  418,  523,  574,  596,\n",
      "          609,  627,  707,  713,  728,  782,  804,  817,  835,   34,   51,    4,\n",
      "          641,  182,  194,  258,  266,  273,  346,  358,  422,  430,  437,  542,\n",
      "          554,  618,  626,  633,  803,  815,  879,  887,  894,   78,   92,  146,\n",
      "          151,  162,  259,  327,  347,  450,  465,  554,  616,  636,  739,  754,\n",
      "          818,  834,  931, 1072, 1089,   16,   28,   92,  100,  107,  178,  190,\n",
      "          254,  262,  269,  217,  262,  266,  527,  548,    4,  163,    4,  222,\n",
      "          361,   91,  105,  124,  155,  179,  200,  208,  222,  226,  234,  377,\n",
      "            7,  151,  205,  294,  329,    9,  191,   84,  122,  412,  428,    4,\n",
      "           94,  334,  338,  185,  209,  585, 1499,   25,  138,  171,  329,  342,\n",
      "          492,  161,   51,   55,  155,  213,  344,  348,  462,  470,  550,  199,\n",
      "          260,  186,   89,  466,  900,  192,  211,  215,  438,  571,   50,  193,\n",
      "          236,  240,  246,  315,  122,   30,    4,   26,   53,   60,   67,   76,\n",
      "           93,  109,  119,  133,  144,  156,  162,  175,  181,  195,  207,  242,\n",
      "          335,  343,  365,  388,  400,  413,  428,  442,  461,   52,  729]]))\n",
      "(('END_IF', 'next', 'END_IF'), tensor([[ 286,  287,  312,   13,  165,   24,   14,   17,   33,   49,   63,   79,\n",
      "           95,  228,  269,  270,  275,  540,  547,  156,  279,  344,  568,  735,\n",
      "          886, 1088, 1227, 1563,   72,   41,   89,  274,  357,  358,  359,  360,\n",
      "          390,  465,  545,  488,  494,   37,  112,   61,   68,  113,  130,  147,\n",
      "          164,  178,  195,  212,  350,  394,  395,  400,  454,  455,  460,  288,\n",
      "          289,  293,  294,  610,  614,   24,   25,  112,  113,  135,  136,  156,\n",
      "          157,  242,  244,  264,   53,   70,   87,  102,  119,  136,  268,  306,\n",
      "          307,  312,  583,  590,  165,  168,   69,   70,  115,  116,  158,  159,\n",
      "          203,  204,  245,  246,  287,  288,  325,  326,  411,  437,  474,  475,\n",
      "           31,   81,   85,  109,  120,   29,   95,  158,  355,  303,  312,  207,\n",
      "           31,   47,   39,   78,  157,  158,  228,  155,  156,  236,  237,  639,\n",
      "          640,  847,  848,   32,  154,  282,  446,  642,  749,  903,  986, 1047,\n",
      "          380,  391,  392,  478,  669,  680,  681,  767, 1009, 1010, 1024,  116,\n",
      "          278,  146,  232,  247,  462,  534,  552,  553,   96,  100,  101,  102,\n",
      "          103,   10,   50,  106,  171,  175,  295,   76,   77,   78,   79,  108,\n",
      "          134,  135,  171,  172,  277,  312,  546,  552,   11,  155,  182,  183,\n",
      "          184,  185,  186,  187,  188,  189,   14,   50,  109,  124,  265,  274,\n",
      "          279,  101,  107,  437,  443,  731,  737, 1027, 1033, 1508, 1572, 1598,\n",
      "           53,   54,   55,  159,  222,  287,  295,  340,  469,  480,  492,  547,\n",
      "          548,    9,   41,   98,  209,  398,  459,   48,   69,   71,   84,   39,\n",
      "           43,  153,  203,   48,   52,  143,  211,  212,  213,  230,  366,  434,\n",
      "          435,  436,  453,  567,  568,  569,   96,    4,   26,   84,  182,  183,\n",
      "          187,  188,   11,   14,   94,   42,  233,  234,  235,  638,  644,  651,\n",
      "          668,  685,  720],\n",
      "        [ 287,  288,  313,   14,  166,   25,   15,   18,   34,   50,   64,   80,\n",
      "           96,  229,  270,  271,  276,  548,  548,  157,  280,  345,  569,  736,\n",
      "          887, 1089, 1228, 1564,   73,   43,   90,  275,  358,  359,  360,  361,\n",
      "          391,  466,  546,  489,  495,   38,  113,   69,   69,  114,  131,  148,\n",
      "          165,  179,  196,  213,  351,  395,  396,  401,  455,  456,  461,  289,\n",
      "          295,  294,  295,  615,  615,   25,   26,  113,  114,  136,  137,  157,\n",
      "          158,  244,  246,  265,   54,   71,   88,  103,  120,  137,  269,  307,\n",
      "          308,  313,  591,  591,  169,  169,   70,   71,  116,  117,  159,  160,\n",
      "          204,  205,  246,  247,  288,  289,  326,  327,  412,  438,  475,  476,\n",
      "           32,   86,   86,  110,  121,   30,   96,  159,  356,  304,  313,  208,\n",
      "           32,   48,   40,   79,  158,  159,  230,  156,  157,  237,  238,  640,\n",
      "          641,  848,  849,   33,  155,  283,  447,  643,  750,  904,  987, 1048,\n",
      "          381,  392,  393,  479,  670,  681,  682,  768, 1010, 1025, 1025,  117,\n",
      "          279,  147,  233,  248,  463,  535,  553,  554,   97,  101,  102,  103,\n",
      "          104,    6,   46,  102,  167,  176,  296,   77,   78,   79,   80,  109,\n",
      "          135,  136,  172,  173,  278,  313,  547,  553,   12,  156,  183,  184,\n",
      "          185,  186,  187,  188,  189,  190,   15,   51,  110,  125,  267,  275,\n",
      "          281,  102,  108,  438,  444,  732,  738, 1028, 1034, 1509, 1573, 1599,\n",
      "           54,   55,   56,  160,  223,  288,  296,  341,  470,  481,  493,  548,\n",
      "          549,    5,   37,   94,  210,  399,  455,   49,   71,   72,   85,   44,\n",
      "           44,  154,  204,   53,   53,  144,  212,  213,  214,  232,  367,  435,\n",
      "          436,  437,  455,  568,  569,  570,   97,    5,   27,   85,  183,  189,\n",
      "          188,  189,   15,   15,   95,   43,  234,  235,  236,  639,  645,  652,\n",
      "          669,  686,  722]]))\n",
      "(('END_IF', 'next', 'IF'), tensor([[ 26,  37,  54,  ..., 374, 416, 607],\n",
      "        [ 27,  38,  55,  ..., 375, 417, 608]]))\n",
      "(('IF', 'if_true', 'IF'), tensor([[ 264,  596,  597,    9,  156,   20,   10,  170,  178,  241,  153,  273,\n",
      "          338,  562,  724,  880, 1077, 1221, 1553,   69,   84,   91,  270,  522,\n",
      "          696,  697,  483,  484,  116,  164,    7,  279,  287,  278,  285,  290,\n",
      "          606,   92,  234,  235,  212,  220,  162,  653,   51,  140,  428,    1,\n",
      "           28,   77,  116,   25,  350,  281,  203,   28,   44,   34,   43,  125,\n",
      "          162,  163,  169,  183,  224,   22,  144,  998,  382,  395,  671,  684,\n",
      "          980, 1012,  256,  286,  247,  283,    8,  152,   10,  269,  270,   96,\n",
      "           97,  432,  433,  726,  727, 1022, 1023, 1471, 1595,  109,  219,  281,\n",
      "          289,  332,  466,  477,  542,  204,   44,   66,   35,   44,  279,  502,\n",
      "            1,   23,   81,  172,  179,  184,  191,  331,    8,  635,  641,  648,\n",
      "          665,  682,  717],\n",
      "        [ 265,  597,  598,   10,  157,   21,   11,  171,  179,  242,  154,  274,\n",
      "          339,  563,  725,  881, 1078, 1222, 1554,   70,   85,   92,  271,  523,\n",
      "          697,  698,  484,  485,  117,  165,    8,  280,  288,  279,  286,  291,\n",
      "          607,   93,  235,  236,  213,  221,  163,  654,   52,  141,  429,    2,\n",
      "           29,   78,  117,   26,  351,  282,  204,   29,   45,   35,   44,  126,\n",
      "          163,  164,  170,  184,  225,   23,  145,  999,  383,  396,  672,  685,\n",
      "          981, 1013,  257,  287,  248,  284,    9,  153,   11,  270,  271,   97,\n",
      "           98,  433,  434,  727,  728, 1023, 1024, 1472, 1596,  110,  220,  282,\n",
      "          290,  333,  467,  478,  543,  205,   45,   67,   36,   45,  280,  503,\n",
      "            2,   24,   82,  173,  180,  185,  192,  332,    9,  636,  642,  649,\n",
      "          666,  683,  718]]))\n",
      "(('EXPRESSION', 'next', 'IF_LOOP'), tensor([[  60,  107,  202,  232,  245,  260,  281,  307,  140,  449,  546,  549,\n",
      "          578,  740, 1093, 1365, 1568,   81,  141,   45,   54,   72,   91,  106,\n",
      "          139,  148,  214,  242,  305,  318,  331,  340,  397,  449,  464,  474,\n",
      "          475,  519,  543,  560,  566,  606,   52,   69,   75,  168,  185,  191,\n",
      "          333,  496,  518,  524,  530,  547,  553,  559,  565,  571,  592,  599,\n",
      "           21,   59,   83,  129,  153,  171,   35,   88,  186,  236,  262,  289,\n",
      "           65,  140,   23,   40,   70,  242,  256,  303,  317,  486,  498,  510,\n",
      "          526,  617,  592,  621,  638,   14,   16,   62,  358,  654,  659,   12,\n",
      "           36,   54,  111,  128,  138,  155,  162,  176,  183,   59,   84,  102,\n",
      "          148,  177,  187,  204,  211,  225,  232,  100,  250,  304,  387,  419,\n",
      "           99,  111,  301,  317,  325,  225,  357,  203,  224,  260,   15,   69,\n",
      "           88,   98,  120,  144,  154,  235,  249,  104,  120,  131,  158,  185,\n",
      "          201,  212,  239,  588,  604,  615,  642,  796,  812,  823,  850,   26,\n",
      "           42,   59,   44,   84,  105,  130,  517,  542,  174,  291,  295,  313,\n",
      "          338,  455,  459,  477,  534,  651,  655,  673,  795,  912,  916,  934,\n",
      "         1014,  113,  131,  177,  193,  336,  394,  439,  459,  480,  625,  683,\n",
      "          728,  748,  769,    8,  125,  129,  147,  170,  287,  291,  309,  346,\n",
      "          125,  227,  241,  288,   12,   36,   54,  114,  132,  142,  159,  166,\n",
      "          180,  187,  212,  232,  267,  322,  346,  396,  158,  326,  389,  398,\n",
      "          565,    7,   81,  112,  187,  276,  310,  359,  383,  397,  416,  431,\n",
      "          452,  462,  507,  522,  555,  584,  602,  184,  190,  196,  210,  217,\n",
      "          239,  262,  178,  187,  196,  205,  214,  223,  440,   37,  104,  118,\n",
      "          147,  197,  206,  223,  292,  109,  445,  739, 1035, 1301, 1575,   17,\n",
      "           77,   96,  109,  122,  131,    4,   12,   33,  253,  254,  266,  276,\n",
      "           70,  126,  223,  279,   70,  227,  231,  246,   95,  123,  222,  250,\n",
      "           28,   40,   50,   16,  176,  290,  399,  513,   12,   36,   54,  114,\n",
      "          131,  141,  158,  165,  179,  186,  624,   10,   26,   11,   35,   56,\n",
      "           92,  116,  137,  243,  256,  262,  265,  281,  303,   29,   81,   85,\n",
      "          126,  329,  353,  132,  191,  343,  625],\n",
      "        [  58,  105,  198,  228,  241,  255,  277,  303,  115,  445,  542,  535,\n",
      "          576,  719, 1072, 1363, 1550,   77,  137,   40,   50,   70,   79,  100,\n",
      "          137,  146,  209,  237,  301,  314,  326,  336,  395,  440,  457,  470,\n",
      "          433,  505,  531,  551,  494,  595,   46,   67,   73,  162,  183,  189,\n",
      "          331,  482,  516,  522,  528,  545,  551,  557,  563,  569,  590,  597,\n",
      "           18,   55,   75,  115,  143,  163,   33,   86,  184,  234,  256,  283,\n",
      "           57,  132,   21,   38,   56,  240,  255,  301,  316,  484,  495,  506,\n",
      "          521,  592,  578,  619,  636,   11,    6,   54,  354,  652,  646,    9,\n",
      "           31,   49,  104,  124,  134,  150,  160,  171,  181,   54,   79,   97,\n",
      "          141,  173,  183,  199,  209,  220,  230,   98,  248,  302,  385,  417,\n",
      "           95,  107,  297,  314,  322,  220,  348,  194,  212,  258,   10,   65,\n",
      "           86,   96,  114,  141,  135,  208,  244,   94,  116,  129,  144,  175,\n",
      "          197,  210,  225,  578,  600,  613,  628,  786,  808,  821,  836,   24,\n",
      "           35,   52,   42,   82,  101,  125,  513,  537,  171,  290,  294,  309,\n",
      "          335,  454,  458,  473,  531,  650,  654,  669,  792,  911,  915,  930,\n",
      "         1012,  111,  127,  175,  190,  331,  362,  436,  455,  469,  620,  651,\n",
      "          725,  744,  758,    5,  124,  128,  143,  167,  286,  290,  305,  344,\n",
      "          123,  225,  239,  286,    9,   31,   49,  107,  128,  138,  154,  164,\n",
      "          175,  185,  210,  227,  254,  313,  337,  375,  153,  321,  387,  396,\n",
      "          560,    3,   62,   96,  180,  269,  304,  357,  381,  390,  414,  428,\n",
      "          448,  460,  502,  516,  538,  579,  597,  182,  188,  194,  206,  215,\n",
      "          234,  249,  176,  185,  194,  203,  212,  221,  434,   35,  102,  116,\n",
      "          145,  195,  203,  219,  290,   95,  431,  725, 1021, 1288, 1561,   12,\n",
      "           75,   92,  105,  117,  127,    3,   10,   29,  248,  242,  262,  274,\n",
      "           69,  124,  222,  277,   67,  226,  230,  244,   92,  121,  219,  248,\n",
      "           24,   38,   45,   14,  170,  271,  393,  494,    9,   31,   49,  107,\n",
      "          127,  137,  153,  163,  174,  184,  617,    6,   22,    7,   30,   52,\n",
      "           88,  111,  133,  239,  252,  256,  247,  279,  301,   26,   78,   83,\n",
      "          124,  325,  337,  127,  186,  338,  620]]))\n",
      "(('END_IF', 'next', 'RETURN'), tensor([[ 600,  602,  604,   76,   99,  166,  350,  427,  461,  116,  247,  249,\n",
      "          258,  102,  193,  264,  282,  329,  347,  412,  553,  571,  636,  772,\n",
      "          796,  871,  889,  954, 1125, 1149, 1212, 1230, 1295, 1571,  175,  210,\n",
      "           45,   68,   70,  107,   33,   51,  651,  216,  284,  301,  367,  499,\n",
      "          533,  553,  648,  685,   37,   61,  478,  385,  504,  539,  591,    8,\n",
      "           19,   30,   41,   89,  133,  178,  220,  262,  304,  342,  386,  412,\n",
      "          496,  521,   36,   52,  264,  290,  297,  304,  311,  318,  325,  386,\n",
      "           23,   32,   41,   50,  561,  763,  140,  341,  161,  173,  110,  152,\n",
      "          158,   32,   34,   40,   48,  121,  177,  236,  102,  183,  345,  482,\n",
      "          497,  586,  794,  500,  957,  410,  424,  699,  713, 1075, 1092,   55,\n",
      "          139,  339,   39,  215,  241,  278,  313,  335,  348,   38,  227,  157,\n",
      "            9,   15,   24,   32,   38,   47,  187,  193,  202,  227,  233,  239,\n",
      "          319,  325,  334,  238,  256,  281,  201,  213,   40,   58,   66,  112,\n",
      "          230,  376,  394,  402,  448,  670,  688,  696,  742,  966,  984,  992,\n",
      "         1038, 1481,   56,   72,  121,  130,  234,  302,   12,   85,   91,  238,\n",
      "          244,  305,  400,  363,  371,  215,  232,  455,  581,  769,   54,  221,\n",
      "          114,  126,   95,    3,   14,   43,  218,  257,  270,  294,  686],\n",
      "        [ 601,  603,  605,   77,  100,  167,  351,  428,  462,  117,  248,  250,\n",
      "          259,  103,  194,  265,  283,  330,  348,  413,  554,  572,  637,  773,\n",
      "          797,  872,  890,  955, 1126, 1150, 1213, 1231, 1296, 1572,  176,  211,\n",
      "           46,   69,   71,  108,   34,   52,  652,  217,  285,  302,  368,  500,\n",
      "          534,  554,  649,  686,   38,   62,  479,  386,  505,  540,  592,    9,\n",
      "           20,   31,   42,   90,  134,  179,  221,  263,  305,  343,  387,  413,\n",
      "          497,  522,   37,   53,  265,  291,  298,  305,  312,  319,  326,  387,\n",
      "           24,   33,   42,   51,  562,  764,  141,  342,  162,  174,  111,  153,\n",
      "          159,   33,   35,   41,   49,  122,  178,  237,  103,  184,  346,  483,\n",
      "          498,  587,  795,  501,  958,  411,  425,  700,  714, 1076, 1093,   56,\n",
      "          140,  340,   40,  216,  242,  279,  314,  336,  349,   39,  228,  158,\n",
      "           10,   16,   25,   33,   39,   48,  188,  194,  203,  228,  234,  240,\n",
      "          320,  326,  335,  239,  257,  282,  202,  214,   41,   59,   67,  113,\n",
      "          231,  377,  395,  403,  449,  671,  689,  697,  743,  967,  985,  993,\n",
      "         1039, 1482,   57,   73,  122,  131,  235,  303,   13,   86,   92,  239,\n",
      "          245,  306,  401,  364,  372,  216,  233,  456,  582,  770,   55,  222,\n",
      "          115,  127,   96,    4,   15,   44,  219,  258,  271,  295,  687]]))\n",
      "(('END_LOOP', 'next', 'IF'), tensor([[1548,  299,  438,  480,  605,  133,  296,  460,  656,  917,  360,  649,\n",
      "          130,  292,  233,  268,  446,  432,   93,  429,  723, 1019,   90,  256,\n",
      "          232,   50,  131,  237],\n",
      "        [1569,  306,  450,  497,  606,  155,  297,  461,  657,  918,  395,  684,\n",
      "          131,  293,  234,  269,  453,  441,  110,  446,  740, 1036,   97,  257,\n",
      "          233,   57,  138,  244]]))\n",
      "(('IF', 'if_true', 'BREAK'), tensor([[ 737, 1090, 1565,   78,  138,  485,  606,  199,   98,  434,  728, 1024],\n",
      "        [ 738, 1091, 1566,   79,  139,  486,  607,  200,   99,  435,  729, 1025]]))\n",
      "(('BREAK', 'next', 'END_LOOP'), tensor([[ 738, 1091, 1566,   79,  139,  240,  486,  607,   34,   52,   82,  100,\n",
      "          223,  200,   34,   52,  261,  582,  600,   99,  435,  729, 1025,   15,\n",
      "           34,   52,   33,  114,  260],\n",
      "        [ 717, 1070, 1548,   82,  142,  235,  480,  610,   29,   47,   77,   95,\n",
      "          218,  192,   29,   47,  268,  577,  595,   93,  429,  723, 1019,   10,\n",
      "           29,   47,   28,  109,  254]]))\n",
      "(('IF_LOOP', 'if_true', 'EXPRESSION'), tensor([[  58,  105,  228,  241,  576,   70,  137,  146,  395,  457,  470,   67,\n",
      "           73,  183,  189,  331,  516,  522,  528,  545,  551,  557,  563,  569,\n",
      "          590,  597,   18,   75,   33,   86,  184,  234,  256,  283,   21,   38,\n",
      "          240,  255,  301,  316,  484,  495,  592,  619,  636,   11,  354,  584,\n",
      "          588,  612,  620,  646,  652,    9,  160,  181,  209,  230,   98,  248,\n",
      "          302,  385,  417,   95,  107,  297,  314,  322,  258,   86,   96,  114,\n",
      "          244,  129,  210,  613,  821,   24,   42,   82,  171,  290,  294,  335,\n",
      "          454,  458,  531,  650,  654,  792,  911,  915, 1012,  111,  127,  175,\n",
      "          190,  362,  436,  455,  469,  651,  725,  744,  758,    5,  124,  128,\n",
      "          167,  286,  290,  344,  123,  225,  239,  286,    9,  164,  185,  210,\n",
      "          227,  254,  313,  337,  375,  153,  321,  387,  396,  560,  180,  357,\n",
      "          381,  390,  414,  460,  538,  182,  188,  194,  215,  176,  185,  194,\n",
      "          203,  212,  221,   35,  102,  116,  145,  195,  203,  290, 1288, 1561,\n",
      "           75,    3,   10,  248,  274,   69,  124,  222,  277,  391,   67,  226,\n",
      "          230,  244,   92,  121,  219,  248,   38,   14,    9,  163,  184,    6,\n",
      "            7,   88,  279,  301,   26,   78,   83,  124,  127,  186,  338,  620],\n",
      "        [  59,  106,  229,  242,  577,   71,  138,  147,  396,  458,  471,   68,\n",
      "           74,  184,  190,  332,  517,  523,  529,  546,  552,  558,  564,  570,\n",
      "          591,  598,   19,   76,   34,   87,  185,  235,  257,  284,   22,   39,\n",
      "          241,  256,  302,  317,  485,  496,  593,  620,  637,   12,  355,  585,\n",
      "          589,  613,  621,  647,  653,   10,  161,  182,  210,  231,   99,  249,\n",
      "          303,  386,  418,   96,  108,  298,  315,  323,  259,   87,   97,  115,\n",
      "          245,  130,  211,  614,  822,   25,   43,   83,  172,  291,  295,  336,\n",
      "          455,  459,  532,  651,  655,  793,  912,  916, 1013,  112,  128,  176,\n",
      "          191,  363,  437,  456,  470,  652,  726,  745,  759,    6,  125,  129,\n",
      "          168,  287,  291,  345,  124,  226,  240,  287,   10,  165,  186,  211,\n",
      "          228,  255,  314,  338,  376,  154,  322,  388,  397,  561,  181,  358,\n",
      "          382,  391,  415,  461,  539,  183,  189,  195,  216,  177,  186,  195,\n",
      "          204,  213,  222,   36,  103,  117,  146,  196,  204,  291, 1289, 1562,\n",
      "           76,    4,   11,  249,  275,   70,  125,  223,  278,  392,   68,  227,\n",
      "          231,  245,   93,  122,  220,  249,   39,   15,   10,  164,  185,    7,\n",
      "            8,   89,  280,  302,   27,   79,   84,  125,  128,  187,  339,  621]]))\n",
      "(('BEGIN_LOOP', 'next', 'IF_LOOP'), tensor([[  55,  102,  195,  225,  238,  252,  274,  300,  112,  442,  539,  532,\n",
      "          575,  716, 1069, 1360, 1547,   76,  136,   37,   47,   67,   76,   97,\n",
      "          134,  143,  206,  234,  298,  311,  323,  333,  144,  392,  430,  437,\n",
      "          454,  467,  491,  502,  528,  548,  592,   43,   64,   70,  159,  180,\n",
      "          186,  328,  479,  513,  519,  525,  542,  548,  554,  560,  566,  589,\n",
      "          596,   15,   52,   72,  114,  140,  160,   30,   83,  181,  231,  253,\n",
      "          280,   54,  129,   20,   35,   53,  239,  254,  300,  315,  483,  494,\n",
      "          505,  520,  591,  575,  618,  633,    3,    8,   51,  351,  583,  587,\n",
      "          611,  619,  643,  649,    6,   28,   46,  101,  121,  131,  147,  157,\n",
      "          168,  178,   51,   76,   94,  138,  170,  180,  196,  206,  217,  227,\n",
      "           95,  245,  299,  382,  414,   92,  104,  294,  311,  319,  217,  345,\n",
      "          191,  209,  257,    7,   62,   83,   93,  111,  132,  138,  205,  241,\n",
      "           91,  113,  126,  141,  172,  194,  207,  222,  575,  597,  610,  625,\n",
      "          783,  805,  818,  833,   21,   32,   49,   39,   79,   98,  122,  510,\n",
      "          534,  168,  287,  289,  293,  306,  332,  451,  453,  457,  470,  528,\n",
      "          647,  649,  653,  666,  789,  908,  910,  914,  927, 1009,  110,  126,\n",
      "          174,  189,  328,  359,  433,  452,  468,  617,  648,  722,  741,  757,\n",
      "            2,  121,  123,  127,  140,  164,  283,  285,  289,  302,  341,  120,\n",
      "          222,  236,  283,    6,   28,   46,  104,  125,  135,  151,  161,  172,\n",
      "          182,  207,  312,  336,  374,  150,  318,  384,  393,  557,    1,   59,\n",
      "           93,  177,  255,  266,  291,  303,  356,  378,  387,  411,  425,  445,\n",
      "          457,  499,  513,  535,  576,  594,  179,  185,  191,  203,  212,  231,\n",
      "          246,  173,  182,  191,  200,  209,  218,  431,   32,   99,  113,  142,\n",
      "          192,  200,  216,  287,   92,  428,  722, 1018, 1285, 1558,    9,   72,\n",
      "           89,  102,  114,  124,    2,    7,   26,  239,  245,  259,  271,   68,\n",
      "          121,  221,  274,  254,  390,   64,  223,  225,  229,  241,   89,  118,\n",
      "          216,  245,   21,   35,   42,   11,  167,  268,  390,  491,    6,   28,\n",
      "           46,  104,  124,  134,  150,  160,  171,  181,  614,    3,   19,    4,\n",
      "           27,   49,   85,  108,  130,  236,  249,  244,  253,  276,  298,   23,\n",
      "           75,   82,  123,  322,  336,  124,  183,  335,  617],\n",
      "        [  58,  105,  198,  228,  241,  255,  277,  303,  115,  445,  542,  535,\n",
      "          576,  719, 1072, 1363, 1550,   77,  137,   40,   50,   70,   79,  100,\n",
      "          137,  146,  209,  237,  301,  314,  326,  336,  145,  395,  433,  440,\n",
      "          457,  470,  494,  505,  531,  551,  595,   46,   67,   73,  162,  183,\n",
      "          189,  331,  482,  516,  522,  528,  545,  551,  557,  563,  569,  590,\n",
      "          597,   18,   55,   75,  115,  143,  163,   33,   86,  184,  234,  256,\n",
      "          283,   57,  132,   21,   38,   56,  240,  255,  301,  316,  484,  495,\n",
      "          506,  521,  592,  578,  619,  636,    6,   11,   54,  354,  584,  588,\n",
      "          612,  620,  646,  652,    9,   31,   49,  104,  124,  134,  150,  160,\n",
      "          171,  181,   54,   79,   97,  141,  173,  183,  199,  209,  220,  230,\n",
      "           98,  248,  302,  385,  417,   95,  107,  297,  314,  322,  220,  348,\n",
      "          194,  212,  258,   10,   65,   86,   96,  114,  135,  141,  208,  244,\n",
      "           94,  116,  129,  144,  175,  197,  210,  225,  578,  600,  613,  628,\n",
      "          786,  808,  821,  836,   24,   35,   52,   42,   82,  101,  125,  513,\n",
      "          537,  171,  288,  290,  294,  309,  335,  452,  454,  458,  473,  531,\n",
      "          648,  650,  654,  669,  792,  909,  911,  915,  930, 1012,  111,  127,\n",
      "          175,  190,  331,  362,  436,  455,  469,  620,  651,  725,  744,  758,\n",
      "            5,  122,  124,  128,  143,  167,  284,  286,  290,  305,  344,  123,\n",
      "          225,  239,  286,    9,   31,   49,  107,  128,  138,  154,  164,  175,\n",
      "          185,  210,  313,  337,  375,  153,  321,  387,  396,  560,    3,   62,\n",
      "           96,  180,  256,  269,  292,  304,  357,  381,  390,  414,  428,  448,\n",
      "          460,  502,  516,  538,  579,  597,  182,  188,  194,  206,  215,  234,\n",
      "          249,  176,  185,  194,  203,  212,  221,  434,   35,  102,  116,  145,\n",
      "          195,  203,  219,  290,   95,  431,  725, 1021, 1288, 1561,   12,   75,\n",
      "           92,  105,  117,  127,    3,   10,   29,  242,  248,  262,  274,   69,\n",
      "          124,  222,  277,  255,  391,   67,  224,  226,  230,  244,   92,  121,\n",
      "          219,  248,   24,   38,   45,   14,  170,  271,  393,  494,    9,   31,\n",
      "           49,  107,  127,  137,  153,  163,  174,  184,  617,    6,   22,    7,\n",
      "           30,   52,   88,  111,  133,  239,  252,  247,  256,  279,  301,   26,\n",
      "           78,   83,  124,  325,  337,  127,  186,  338,  620]]))\n",
      "(('IF_LOOP', 'if_false', 'END_LOOP'), tensor([[  58,  105,  198,  228,  241,  255,  277,  303,  115,  445,  542,  535,\n",
      "          576,  719, 1072, 1550,   77,  137,   40,   50,   70,   79,  100,  137,\n",
      "          146,  209,  237,  301,  314,  326,  336,  145,  395,  433,  440,  457,\n",
      "          470,  494,  505,  531,  551,  595,   46,   67,   73,  162,  183,  189,\n",
      "          331,  482,  516,  522,  528,  545,  551,  557,  563,  569,  590,  597,\n",
      "           18,   55,   75,  115,  143,  163,   33,   86,  184,  234,  256,  283,\n",
      "           57,  132,   21,   38,   56,  240,  255,  301,  316,  484,  495,  506,\n",
      "          521,  592,  578,  619,  636,    6,   11,   54,  354,  584,  588,  612,\n",
      "          620,  646,  652,    9,   31,   49,  104,  124,  134,  150,  160,  171,\n",
      "          181,   54,   79,   97,  141,  173,  183,  199,  209,  220,  230,   98,\n",
      "          248,  302,  385,  417,   95,  107,  297,  314,  322,  220,  348,  194,\n",
      "          212,  258,   10,   65,   86,   96,  114,  135,  141,  208,  244,   94,\n",
      "          116,  129,  144,  175,  197,  210,  225,  578,  600,  613,  628,  786,\n",
      "          808,  821,  836,   24,   35,   52,   42,   82,  101,  125,  513,  537,\n",
      "          171,  288,  290,  294,  309,  335,  452,  454,  458,  473,  531,  648,\n",
      "          650,  654,  669,  792,  909,  911,  915,  930, 1012,  111,  127,  175,\n",
      "          190,  331,  362,  436,  455,  469,  620,  651,  725,  744,  758,    5,\n",
      "          122,  124,  128,  143,  167,  284,  286,  290,  305,  344,  123,  225,\n",
      "          239,  286,    9,   31,   49,  107,  128,  138,  154,  164,  175,  185,\n",
      "          210,  227,  254,  313,  337,  375,  153,  321,  387,  396,  560,    3,\n",
      "           62,   96,  180,  256,  269,  292,  304,  357,  381,  390,  414,  428,\n",
      "          448,  460,  502,  516,  538,  579,  597,  182,  188,  194,  206,  215,\n",
      "          234,  249,  176,  185,  194,  203,  212,  221,  434,   35,  102,  116,\n",
      "          145,  195,  203,  219,  290,   95,  431,  725, 1021, 1288, 1561,   12,\n",
      "           75,   92,  105,  117,  127,    3,   10,   29,  242,  248,  262,  274,\n",
      "           69,  124,  222,  277,  255,  391,   67,  224,  226,  230,  244,   92,\n",
      "          121,  219,  248,   24,   38,   45,   14,  170,  271,  393,  494,    9,\n",
      "           31,   49,  107,  127,  137,  153,  163,  174,  184,  617,    6,   22,\n",
      "            7,   30,   52,   88,  111,  133,  239,  252,  247,  256,  279,  301,\n",
      "           26,   78,   83,  124,  325,  337,  127,  186,  338,  620],\n",
      "        [  56,  103,  196,  226,  239,  253,  275,  301,  113,  443,  540,  533,\n",
      "          579,  717, 1070, 1548,   82,  142,   38,   48,   68,   77,   98,  135,\n",
      "          144,  207,  235,  299,  312,  324,  334,  151,  393,  431,  438,  455,\n",
      "          468,  492,  503,  529,  549,  593,   44,   65,   71,  160,  181,  187,\n",
      "          329,  480,  514,  520,  526,  543,  549,  555,  561,  567,  593,  600,\n",
      "           16,   53,   73,  130,  141,  161,   31,   84,  182,  232,  254,  281,\n",
      "           55,  130,   24,   36,   54,  243,  257,  304,  318,  487,  499,  511,\n",
      "          527,  618,  576,  622,  634,    4,    9,   52,  352,  610,  605,  638,\n",
      "          637,  644,  650,    7,   29,   47,  102,  122,  132,  148,  158,  169,\n",
      "          179,   52,   77,   95,  139,  171,  181,  197,  207,  218,  228,   96,\n",
      "          246,  300,  383,  415,   93,  105,  295,  312,  320,  218,  346,  192,\n",
      "          210,  261,    8,   63,   84,   94,  112,  133,  139,  206,  242,   92,\n",
      "          114,  127,  142,  173,  195,  208,  223,  576,  598,  611,  626,  784,\n",
      "          806,  819,  834,   22,   33,   50,   40,   80,   99,  123,  511,  535,\n",
      "          169,  302,  292,  296,  307,  333,  466,  456,  460,  471,  529,  662,\n",
      "          652,  656,  667,  790,  923,  913,  917,  928, 1010,  114,  132,  178,\n",
      "          194,  329,  360,  434,  453,  481,  618,  649,  723,  742,  770,    3,\n",
      "          136,  126,  130,  141,  165,  298,  288,  292,  303,  342,  121,  223,\n",
      "          237,  284,    7,   29,   47,  105,  126,  136,  152,  162,  173,  183,\n",
      "          208,  233,  268,  323,  347,  397,  151,  319,  385,  394,  558,    2,\n",
      "           60,   94,  178,  262,  267,  298,  311,  360,  379,  388,  412,  426,\n",
      "          446,  458,  500,  514,  536,  577,  595,  180,  186,  192,  204,  213,\n",
      "          232,  247,  174,  183,  192,  201,  210,  219,  432,   33,  100,  114,\n",
      "          143,  193,  201,  217,  288,   93,  429,  723, 1019, 1286, 1559,   10,\n",
      "           73,   90,  103,  115,  125,    5,    8,   27,  240,  246,  260,  272,\n",
      "           71,  122,  224,  275,  256,  400,   65,  238,  228,  232,  242,   90,\n",
      "          119,  217,  246,   22,   36,   43,   12,  168,  269,  391,  492,    7,\n",
      "           29,   47,  105,  125,  135,  151,  161,  172,  182,  615,    4,   20,\n",
      "            5,   28,   50,   86,  109,  131,  237,  250,  245,  254,  277,  299,\n",
      "           24,   76,   86,  127,  323,  354,  125,  184,  336,  618]]))\n",
      "(('NEW VARIABLE', 'next', 'BEGIN_LOOP'), tensor([[  57,  104,  197,  227,  240,  254,  276,  302,  114,  534,  718, 1071,\n",
      "         1362, 1549,   75,  135,   39,   69,   78,   99,  136,  145,  208,  236,\n",
      "          300,  313,  325,  143,  394,  432,  439,  493,  504,  594,   45,   66,\n",
      "          161,  182,  481,  515,  544,  588,  595,   17,   54,   74,  113,  142,\n",
      "          162,   32,   85,  183,  233,  255,  282,   56,  131,   37,   55,  238,\n",
      "          299,  482,  493,  504,  590,  577,  635,    5,   10,   53,  353,  582,\n",
      "          645,  651,    8,   30,   48,  103,  123,  133,   53,   78,   96,  140,\n",
      "          172,  182,   97,  247,  301,  384,  416,   94,  106,  296,  313,  347,\n",
      "          193,    9,   64,   85,   95,  113,  140,  207,  243,   93,  143,  174,\n",
      "          224,  577,  627,  785,  835,   23,   34,   51,   41,   81,  100,  124,\n",
      "          512,  536,  170,  286,  308,  334,  450,  472,  530,  646,  668,  791,\n",
      "          907,  929, 1011,  109,  125,  173,  188,  330,  435,  454,  467,  619,\n",
      "          724,  743,  756,    4,  120,  142,  166,  282,  304,  343,  122,  224,\n",
      "          285,    8,   30,   48,  106,  127,  137,  209,  252,  311,  335,  373,\n",
      "          386,  395,   95,  179,  355,  380,  413,  427,  447,  515,  537,  578,\n",
      "          596,  181,  205,  214,  233,  248,  175,  184,  193,  202,  211,  220,\n",
      "          433,   34,  101,  144,  194,  218,  289,   94,  430,  724, 1020, 1287,\n",
      "         1560,   11,   74,   91,  104,  116,    1,    9,   28,  241,  247,  261,\n",
      "          273,  123,  276,  253,   66,  222,  243,   91,  120,  218,  247,   23,\n",
      "           37,   13,  169,  270,  392,  493,    8,   30,   48,  106,  126,  136,\n",
      "          616,    5,   21,    6,   29,   51,   87,  110,  132,  238,  251,  246,\n",
      "          255,  278,  300,   25,   77,   81,  122,  335],\n",
      "        [  55,  102,  195,  225,  238,  252,  274,  300,  112,  532,  716, 1069,\n",
      "         1360, 1547,   76,  136,   37,   67,   76,   97,  134,  143,  206,  234,\n",
      "          298,  311,  323,  144,  392,  430,  437,  491,  502,  592,   43,   64,\n",
      "          159,  180,  479,  513,  542,  589,  596,   15,   52,   72,  114,  140,\n",
      "          160,   30,   83,  181,  231,  253,  280,   54,  129,   35,   53,  239,\n",
      "          300,  483,  494,  505,  591,  575,  633,    3,    8,   51,  351,  583,\n",
      "          643,  649,    6,   28,   46,  101,  121,  131,   51,   76,   94,  138,\n",
      "          170,  180,   95,  245,  299,  382,  414,   92,  104,  294,  311,  345,\n",
      "          191,    7,   62,   83,   93,  111,  138,  205,  241,   91,  141,  172,\n",
      "          222,  575,  625,  783,  833,   21,   32,   49,   39,   79,   98,  122,\n",
      "          510,  534,  168,  287,  306,  332,  451,  470,  528,  647,  666,  789,\n",
      "          908,  927, 1009,  110,  126,  174,  189,  328,  433,  452,  468,  617,\n",
      "          722,  741,  757,    2,  121,  140,  164,  283,  302,  341,  120,  222,\n",
      "          283,    6,   28,   46,  104,  125,  135,  207,  253,  312,  336,  374,\n",
      "          384,  393,   93,  177,  356,  378,  411,  425,  445,  513,  535,  576,\n",
      "          594,  179,  203,  212,  231,  246,  173,  182,  191,  200,  209,  218,\n",
      "          431,   32,   99,  142,  192,  216,  287,   92,  428,  722, 1018, 1285,\n",
      "         1558,    9,   72,   89,  102,  114,    2,    7,   26,  239,  245,  259,\n",
      "          271,  121,  274,  254,   64,  223,  241,   89,  118,  216,  245,   21,\n",
      "           35,   11,  167,  268,  390,  491,    6,   28,   46,  104,  124,  134,\n",
      "          614,    3,   19,    4,   27,   49,   85,  108,  130,  236,  249,  244,\n",
      "          253,  276,  298,   23,   75,   82,  123,  336]]))\n",
      "(('IF_LOOP', 'if_true', 'NEW VARIABLE'), tensor([[ 115,  719, 1072, 1550,  145,  440,   46,  162,   57,  132,    6,   54,\n",
      "          348,  194,  212,  141,  208,   94,  144,  175,  225,  578,  628,  786,\n",
      "          836,   35,   52,   62,   96,  269,  304,  428,  502,  516,  234,  249,\n",
      "          242,   24,   45,  170,  271,  393,  494,  617,   22,  247,  256,  337],\n",
      "        [ 116,  720, 1073, 1551,  146,  441,   47,  163,   58,  133,    7,   55,\n",
      "          349,  195,  213,  142,  209,   95,  145,  176,  226,  579,  629,  787,\n",
      "          837,   36,   53,   63,   97,  270,  305,  429,  503,  517,  235,  250,\n",
      "          243,   25,   46,  171,  272,  394,  495,  618,   23,  248,  257,  338]]))\n",
      "(('IF', 'if_false', 'IF'), tensor([[ 580,  582,  584,   13,   59,  204,  219,  254,  259,  339,  343,  347,\n",
      "          349,  385,  694,  698,  275,  483,   27,  102,   30,  109,  174,  311,\n",
      "          326,  341,  379,  384,  439,  444,  278,  606,   19,  107,  130,  151,\n",
      "           49,   98,  244,  259,  291,  296,  628,  162,  330,  332,  334,  336,\n",
      "          338,  340,  342,   52,   76,   98,  122,  141,  165,  186,  210,  228,\n",
      "          252,  270,  294,  312,  332,  403,  457,  481,   77,  286,  288,  290,\n",
      "          292,  294,  296,  298,  300,  684,  686,  136,  281,  162,   63,   65,\n",
      "           67,   69,   71,   73,   75,  148,  150,  229,  231,  243,  245,  247,\n",
      "          249,  251,  253,  255,  547,  549,  551,  553,  555,  557,  559,  632,\n",
      "          634,  840,  842,  854,  856,  858,  860,  862,  864,  866,   22,  101,\n",
      "          103,  144,  291,  373,  382,  387,  586,  662,  671,  676, 1002,  140,\n",
      "          422,  458,   89,   91,   93,   95,    4,   44,  100,  165,   22,   24,\n",
      "          191,  193,  425,  427,   65,   67,   69,   71,  127,  129,  160,  163,\n",
      "          542,  548,  164,  166,  168,  170,  172,  174,  176,  178,   45,   96,\n",
      "          432,  726, 1022, 1500,   45,   47,   49,  488,  543,    3,   35,   92,\n",
      "          453,  159,  161,  163,  165,  167,   64,  139,  198,  201,  204,  362,\n",
      "          421,  424,  427,  554,  557,  560,  172,    8,   89,  224,  226,  228,\n",
      "           15,   17,   49,   51,  255,  257,  537,  539],\n",
      "        [ 582,  584,  586,   15,   61,  206,  222,  259,  264,  343,  347,  349,\n",
      "          351,  388,  696,  700,  286,  492,   29,  104,   32,  111,  176,  313,\n",
      "          328,  344,  384,  389,  444,  449,  290,  611,   21,  109,  132,  153,\n",
      "           51,  100,  246,  262,  296,  301,  630,  166,  332,  334,  336,  338,\n",
      "          340,  342,  344,   55,   84,  101,  128,  144,  173,  189,  215,  231,\n",
      "          257,  273,  299,  315,  337,  407,  460,  491,   82,  288,  290,  292,\n",
      "          294,  296,  298,  300,  302,  686,  688,  138,  286,  169,   65,   67,\n",
      "           69,   71,   73,   75,   77,  150,  152,  231,  233,  245,  247,  249,\n",
      "          251,  253,  255,  257,  549,  551,  553,  555,  557,  559,  561,  634,\n",
      "          636,  842,  844,  856,  858,  860,  862,  864,  866,  868,   29,  103,\n",
      "          105,  151,  293,  375,  387,  389,  588,  664,  676,  678, 1004,  142,\n",
      "          424,  460,   91,   93,   95,   97,    7,   47,  103,  168,   24,   26,\n",
      "          193,  195,  427,  429,   67,   69,   71,   73,  129,  131,  163,  166,\n",
      "          544,  550,  166,  168,  170,  172,  174,  176,  178,  180,   47,  105,\n",
      "          441,  735, 1031, 1502,   47,   49,   51,  490,  545,    6,   38,   95,\n",
      "          456,  161,  163,  165,  167,  169,   66,  141,  201,  204,  207,  364,\n",
      "          424,  427,  430,  557,  560,  563,  184,   12,   91,  226,  228,  230,\n",
      "           17,   19,   51,   53,  257,  259,  539,  541]]))\n",
      "(('IF_LOOP', 'if_false', 'IF'), tensor([[1363],\n",
      "        [1367]]))\n",
      "(('IF_LOOP', 'if_true', 'END_LOOP'), tensor([[1363],\n",
      "        [1361]]))\n",
      "(('INLINE ASM', 'next', 'RETURN'), tensor([[ 117,  101,  552,  292,  357,  581,  899, 1240,  112,  168,  322,   73,\n",
      "           79,  595,  229,  115,  558,  285,   13,  201,  227,  113,  181,  313,\n",
      "         1165,   14,  286,   27,   69,  182,  713],\n",
      "        [ 118,  102,  553,  293,  358,  582,  900, 1241,  113,  169,  323,   74,\n",
      "           80,  596,  230,  116,  559,  286,   14,  202,  228,  114,  182,  314,\n",
      "         1166,   15,  287,   28,   70,  183,  714]]))\n",
      "(('NEW VARIABLE', 'next', 'INLINE ASM'), tensor([[ 116,  100,  500,  551,  291,  356,  580,  898, 1239,  111,    2,   10,\n",
      "           20,   24,   29,   33,  321,   72,  725,   78,  543,  594,  400,  445,\n",
      "          666,  378,  390,  228,  114,  557,  284,   81,    2,  216,  644,    8,\n",
      "           12,   51,   63,   98,  125,  157,  200,  226,  250,  253,  264,  270,\n",
      "          286,  289,  300,  305,  367,  385,  112,  180,  312,  132, 1164,   13,\n",
      "           34,   43,   53,   62,  106,  110,  155,  159,  171,  180,  285,   26,\n",
      "           53,   60,   68,   77,  162,  181,  208,  222,  243,  253,  266,   29,\n",
      "           73,  426,  757],\n",
      "        [ 117,  101,  501,  552,  292,  357,  581,  899, 1240,  112,    3,   11,\n",
      "           21,   25,   30,   34,  322,   73,  726,   79,  544,  595,  401,  446,\n",
      "          667,  379,  391,  229,  115,  558,  285,   82,    3,  217,  645,    9,\n",
      "           13,   52,   64,   99,  126,  158,  201,  227,  251,  254,  265,  271,\n",
      "          287,  290,  301,  306,  368,  386,  113,  181,  313,  133, 1165,   14,\n",
      "           35,   44,   54,   63,  107,  111,  156,  160,  172,  181,  286,   27,\n",
      "           54,   61,   69,   78,  163,  182,  209,  223,  244,  254,  267,   30,\n",
      "           74,  427,  758]]))\n",
      "(('END_IF', 'next', '_'), tensor([[  12,  148,  195,  793,   20,   69,  133,  402,  408,    7,   21,   43,\n",
      "           49,  177,  183,  189,  236,  242,  312,  318,   27,   34,   42,   48,\n",
      "          193,  200,  208,  214,  220,  226,  688,  694,  700,  707,  715,  721,\n",
      "          727,  733,  739,  745,  751,  255,  265,  271,   92,   98,  104,  366,\n",
      "          372,  378,  388,  668,  674,  680,    6,   50,   10,   65,   15,   43,\n",
      "          118,   11,   87,   14,  146,  152,  158,  241,  247,  253,  259,  265,\n",
      "          271,  277,  283,  298,  791,  797,  803,  809,   13,   19,   97,  103,\n",
      "           12,   18,   33,  134,  140,  155,  161,  726,  732,  738, 1024, 1030,\n",
      "         1036,   20,  104,  232,  257,  613,   85,  112,  344,  371,  247,  474,\n",
      "          142,  523,  842, 1102,  142,  148,  154,  160,  166,  172,  178,  184,\n",
      "          512,  518,  524,  531,   77,   83,   63,   69,   75,   81,   10,   27,\n",
      "           60,   99,  141,  202,  392,  398,  404,  410,  416,  474,  480,  486,\n",
      "          492,  498,  441,  744],\n",
      "        [  13,  149,  196,  794,   21,   70,  134,  403,  409,    8,   22,   44,\n",
      "           50,  178,  184,  190,  237,  243,  313,  319,   28,   35,   43,   49,\n",
      "          194,  201,  209,  215,  221,  227,  689,  695,  701,  708,  716,  722,\n",
      "          728,  734,  740,  746,  752,  256,  266,  272,   93,   99,  105,  367,\n",
      "          373,  379,  389,  669,  675,  681,    7,   51,   11,   66,   16,   44,\n",
      "          119,   12,   88,   15,  147,  153,  159,  242,  248,  254,  260,  266,\n",
      "          272,  278,  284,  299,  792,  798,  804,  810,   14,   20,   98,  104,\n",
      "           13,   19,   34,  135,  141,  156,  162,  727,  733,  739, 1025, 1031,\n",
      "         1037,   21,  105,  233,  258,  614,   86,  113,  345,  372,  248,  475,\n",
      "          143,  524,  843, 1103,  143,  149,  155,  161,  167,  173,  179,  185,\n",
      "          513,  519,  525,  532,   78,   84,   64,   70,   76,   82,   11,   28,\n",
      "           61,  100,  142,  203,  393,  399,  405,  411,  417,  475,  481,  487,\n",
      "          493,  499,  442,  745]]))\n",
      "(('END_LOOP', 'next', 'RETURN'), tensor([[ 226,  239,  113,  443,  540,  717, 1070,  151,  593,   71,  187,  526,\n",
      "          567,  600,   16,   73,  161,   36,  243,  257,  304,  318,  487,  499,\n",
      "          511,  527,  634,  346,   84,   94,  242,   92,  127,  142,  173,  208,\n",
      "          223,  576,  611,  626,  784,  819,  834,   99,  511,  114,  132,  178,\n",
      "          194,  284,   94,  178,  262,  298,  388,  514,  536,  192,  174,  183,\n",
      "          192,  201,  210,  219,  288,  240,  260,  245,   86],\n",
      "        [ 233,  246,  141,  450,  547,  741, 1094,  152,  607,   76,  192,  531,\n",
      "          572,  601,   22,   84,  172,   41,  244,  258,  305,  319,  488,  500,\n",
      "          512,  528,  639,  358,   89,   99,  250,  105,  132,  159,  186,  213,\n",
      "          240,  589,  616,  643,  797,  824,  851,  106,  518,  115,  133,  179,\n",
      "          195,  289,  113,  188,  263,  299,  398,  523,  556,  197,  179,  188,\n",
      "          197,  206,  215,  224,  293,  255,  267,  266,   87]]))\n",
      "(('IF', 'if_true', 'CONTINUE'), tensor([[ 721, 1074,  216,  100,  181,  584,  792,  332,  621,  315,  339],\n",
      "        [ 722, 1075,  217,  101,  182,  585,  793,  333,  622,  316,  340]]))\n",
      "(('CONTINUE', 'next', 'BEGIN_LOOP'), tensor([[ 722, 1075,  217,   98,  101,  179,  182,  582,  585,  790,  793,  333,\n",
      "          622,  316,  340],\n",
      "        [ 716, 1069,  209,   91,   91,  172,  172,  575,  575,  783,  783,  328,\n",
      "          617,  312,  336]]))\n",
      "(('_', 'next', 'END_IF'), tensor([[  13,   33,   80,   20,   25,  119,  124,  129,  137,  404,  409,  414,\n",
      "          419,   11,   42,  301,  303,  320,  325,  511,  516,  521,  715,  720,\n",
      "         1052, 1057, 1062,  154,  159,  353,  358,    9,   27,  165,  196,  201,\n",
      "          211,  217,  246,  251,  262,  618,  623,  628,  633,  639,   33,   32,\n",
      "           90,   95,  100,  349,  354,  359,  376,  381,  121,  122,  203,  257,\n",
      "           86,   91],\n",
      "        [  14,   34,   81,   21,   26,  120,  125,  130,  138,  405,  410,  415,\n",
      "          420,   12,   43,  304,  304,  321,  326,  512,  517,  522,  716,  721,\n",
      "         1053, 1058, 1063,  155,  160,  354,  359,   10,   28,  166,  197,  202,\n",
      "          212,  218,  247,  252,  263,  619,  624,  629,  634,  640,   34,   33,\n",
      "           91,   96,  101,  350,  355,  360,  377,  382,  122,  124,  205,  258,\n",
      "           87,   92]]))\n",
      "(('IF', 'if_true', '_'), tensor([[  12,   32,   79,   19,   24,  118,  123,  128,  136,  403,  408,  413,\n",
      "          418,   10,   41,  319,  324,  510,  515,  520,  714,  719, 1051, 1056,\n",
      "         1061,  153,  158,  352,  357,    8,   26,  164,  195,  200,  210,  245,\n",
      "          250,  261,  617,  622,  627,  632,   31,   89,   94,   99,  348,  353,\n",
      "          358,  375,  380,  120,  121,  202,  256,   85,   90],\n",
      "        [  13,   33,   80,   20,   25,  119,  124,  129,  137,  404,  409,  414,\n",
      "          419,   11,   42,  320,  325,  511,  516,  521,  715,  720, 1052, 1057,\n",
      "         1062,  154,  159,  353,  358,    9,   27,  165,  196,  201,  211,  246,\n",
      "          251,  262,  618,  623,  628,  633,   32,   90,   95,  100,  349,  354,\n",
      "          359,  376,  381,  121,  122,  203,  257,   86,   91]]))\n",
      "(('_', 'next', 'IF'), tensor([[ 745, 1043],\n",
      "        [ 746, 1044]]))\n",
      "(('IF', 'if_false', '_'), tensor([[ 742, 1040,   29],\n",
      "        [ 745, 1043,   33]]))\n",
      "(('IF', 'if_true', 'THROW'), tensor([[ 10,  82,  85,  ..., 702, 718, 742],\n",
      "        [ 11,  83,  86,  ..., 703, 719, 743]]))\n",
      "(('IF_LOOP', 'if_true', 'IF'), tensor([[ 198,  255,  277,  303,  445,  542,  535,   77,  137,   40,   50,   79,\n",
      "          100,  209,  237,  301,  314,  326,  336,  433,  494,  505,  531,  551,\n",
      "          595,  482,   55,  115,  143,  163,   56,  506,  521,  578,   31,   49,\n",
      "          104,  124,  134,  150,  171,   54,   79,   97,  141,  173,  183,  199,\n",
      "          220,  220,   10,   65,  135,  116,  197,  600,  808,  101,  125,  513,\n",
      "          537,  309,  473,  669,  930,  331,  620,  143,  305,   31,   49,  107,\n",
      "          128,  138,  154,  175,  256,  292,  448,  579,  597,  206,  434,  219,\n",
      "           95,  431,  725, 1021,   12,   92,  105,  117,  127,   29,  262,   31,\n",
      "           49,  107,  127,  137,  153,  174,   30,   52,  111,  133,  239,  252,\n",
      "          325],\n",
      "        [ 199,  256,  278,  304,  446,  543,  536,   78,  138,   41,   51,   80,\n",
      "          101,  210,  238,  302,  315,  327,  337,  434,  495,  506,  532,  552,\n",
      "          596,  483,   56,  116,  144,  164,   57,  507,  522,  579,   32,   50,\n",
      "          105,  125,  135,  151,  172,   55,   80,   98,  142,  174,  184,  200,\n",
      "          221,  221,   11,   66,  136,  117,  198,  601,  809,  102,  126,  514,\n",
      "          538,  310,  474,  670,  931,  332,  621,  144,  306,   32,   50,  108,\n",
      "          129,  139,  155,  176,  257,  293,  449,  580,  598,  207,  435,  220,\n",
      "           96,  432,  726, 1022,   13,   93,  106,  118,  128,   30,  263,   32,\n",
      "           50,  108,  128,  138,  154,  175,   31,   53,  112,  134,  240,  253,\n",
      "          326]]))\n",
      "(('END_LOOP', 'next', 'EXPRESSION'), tensor([[ 196,  253,  533,   38,   77,  207,  235,  324,  393,  431,  468,  492,\n",
      "          503,  529,  549,   44,   65,  160,  181,  514,  520,  543,  549,  555,\n",
      "          561,  130,  141,  232,  254,  281,   55,  130,   54,  576,    9,   52,\n",
      "          352,  644,  650,    7,   29,   47,  148,  169,   52,   77,   95,  197,\n",
      "          218,  295,  312,  320,  210,  139,  169,  307,  333,  471,  529,  667,\n",
      "          790,  928, 1010,    3,  141,  165,  303,  342,  223,  237,    7,   29,\n",
      "           47,  152,  173,  412,  426,  458,  577,  595,  180,  186,  232,  247,\n",
      "           33,  100,  114,   10,   73,  115,    5,    8,   27,  246,  272,  400,\n",
      "           65,  242,  119,  246,   43,  168,  269,  391,  492,    7,   29,   47,\n",
      "          151,  172,  615,    4,   20,   28,  109,  254,  354],\n",
      "        [ 203,  261,  550,   46,   92,  215,  243,  332,  398,  476,  475,  567,\n",
      "          520,  544,  561,   53,   72,  169,  188,  521,  527,  550,  556,  562,\n",
      "          568,  131,  154,  237,  263,  290,   66,  141,   71,  593,   15,   63,\n",
      "          359,  660,  655,   13,   37,   55,  156,  177,   60,   85,  103,  205,\n",
      "          226,  302,  318,  326,  225,  145,  175,  314,  339,  478,  535,  674,\n",
      "          796,  935, 1015,    9,  148,  171,  310,  347,  228,  242,   13,   37,\n",
      "           55,  160,  181,  417,  432,  463,  585,  603,  187,  193,  240,  263,\n",
      "           38,  105,  119,   18,   78,  123,    6,   13,   34,  254,  277,  401,\n",
      "           71,  247,  124,  251,   51,  177,  291,  400,  514,   13,   37,   55,\n",
      "          159,  180,  625,   11,   27,   36,  117,  263,  355]]))\n",
      "(('ENTRY_POINT', 'next', 'INLINE ASM'), tensor([[  69,   72,  149,  555,  558,  561,  564,  662,  669,  672,   42,  190,\n",
      "           82,  418,  712, 1008,    3,   20,   68,  186,  181,  155,  282,    3,\n",
      "            6,  260],\n",
      "        [  70,   73,  150,  556,  559,  562,  565,  663,  670,  673,   43,  191,\n",
      "           83,  419,  713, 1009,    4,   21,   69,  187,  182,  156,  283,    4,\n",
      "            7,  261]]))\n",
      "(('END_IF', 'next', 'IF_LOOP'), tensor([[150, 604, 609, 636, 301, 465, 661, 922, 135, 297, 399, 237],\n",
      "        [145, 588, 584, 620, 288, 452, 648, 909, 122, 284, 391, 224]]))\n",
      "(('END_LOOP', 'next', 'BEGIN_LOOP'), tensor([[610, 292, 456, 652, 913, 126, 288, 228],\n",
      "        [611, 293, 457, 653, 914, 127, 289, 229]]))\n",
      "(('IF_LOOP', 'if_true', 'BEGIN_LOOP'), tensor([[288, 452, 648, 909, 122, 284, 224],\n",
      "        [289, 453, 649, 910, 123, 285, 225]]))\n",
      "(('IF', 'if_false', 'NEW VARIABLE'), tensor([[265, 291, 155, 450, 523, 683,  32,  13, 259, 630, 515, 351, 307, 165,\n",
      "         174,  24,  56,  60, 335, 374, 508, 248, 284, 795, 888, 147, 250, 250],\n",
      "        [267, 293, 159, 453, 527, 685,  34,  16, 261, 632, 518, 353, 309, 167,\n",
      "         176,  26,  58,  64, 337, 376, 512, 264, 300, 798, 891, 149, 252, 253]]))\n",
      "(('EXPRESSION', 'next', 'BEGIN_LOOP'), tensor([[444, 541, 574,  49, 335, 456, 469, 530, 550,  72, 188, 330, 521, 527,\n",
      "         550, 556, 562, 568,  19, 253, 314, 519, 617, 586, 618, 149, 159, 170,\n",
      "         180, 198, 208, 219, 229, 321, 219, 211, 256, 134, 115, 128, 196, 209,\n",
      "         599, 612, 807, 820, 361, 650, 238, 153, 163, 174, 184, 152, 320, 559,\n",
      "          61, 268, 302, 389, 459, 501, 187, 193, 115, 202, 126,  44, 152, 162,\n",
      "         173, 183, 324, 126, 185, 337, 619],\n",
      "        [442, 539, 575,  47, 333, 454, 467, 528, 548,  70, 186, 328, 519, 525,\n",
      "         548, 554, 560, 566,  20, 254, 315, 520, 618, 587, 619, 147, 157, 168,\n",
      "         178, 196, 206, 217, 227, 319, 217, 209, 257, 132, 113, 126, 194, 207,\n",
      "         597, 610, 805, 818, 359, 648, 236, 151, 161, 172, 182, 150, 318, 557,\n",
      "          59, 266, 303, 387, 457, 499, 185, 191, 113, 200, 124,  42, 150, 160,\n",
      "         171, 181, 322, 124, 183, 335, 617]]))\n",
      "(('END_LOOP', 'next', 'NEW VARIABLE'), tensor([[593,  53, 192, 114, 195, 598, 806, 329, 618,   2, 379, 204, 213,  36,\n",
      "         323],\n",
      "        [594,  60, 204, 121, 202, 605, 813, 337, 626,   8, 384, 211, 218,  41,\n",
      "         330]]))\n",
      "(('EXPRESSION', 'next', 'CONTINUE'), tensor([[ 97, 178, 581, 789],\n",
      "        [ 98, 179, 582, 790]]))\n",
      "(('INLINE ASM', 'next', 'EXPRESSION'), tensor([[501,   3, 726, 544, 401, 405, 409, 446, 379, 391,  82,   3, 217, 645,\n",
      "           4,  43,  52, 265, 287, 301, 368, 386, 133, 183, 406, 254,  30,  74,\n",
      "         427, 758],\n",
      "        [502,   4, 727, 545, 402, 406, 410, 447, 380, 392,  83,   4, 218, 646,\n",
      "           5,  44,  53, 268, 288, 302, 369, 389, 134, 184, 407, 255,  31,  75,\n",
      "         428, 759]]))\n",
      "(('IF', 'if_false', 'THROW'), tensor([[234, 235,  78,  82,  71,  45,   1, 717],\n",
      "        [243, 241,  80,  84,  77,  47,   7, 721]]))\n",
      "(('END_IF', 'next', 'INLINE ASM'), tensor([[167,  33, 149, 136,   6, 149, 200, 712],\n",
      "        [168,  34, 150, 137,   7, 150, 201, 713]]))\n",
      "(('_', 'next', 'EXPRESSION'), tensor([[ 35, 201, 708, 324, 178, 645,  31, 365, 422],\n",
      "        [ 36, 202, 709, 325, 179, 646,  32, 366, 423]]))\n",
      "(('ENTRY_POINT', 'next', 'THROW'), tensor([[ 65, 178, 158, 662, 461, 674, 342, 129],\n",
      "        [ 66, 179, 159, 663, 462, 675, 343, 130]]))\n",
      "(('END_LOOP', 'next', 'IF_LOOP'), tensor([[637],\n",
      "        [612]]))\n",
      "(('EXPRESSION', 'next', 'BREAK'), tensor([[239,  33,  51,  81,  99, 222,  33,  51, 260, 581, 599,  14,  33,  51,\n",
      "          32, 113, 259],\n",
      "        [240,  34,  52,  82, 100, 223,  34,  52, 261, 582, 600,  15,  34,  52,\n",
      "          33, 114, 260]]))\n",
      "(('END_LOOP', 'next', 'END_IF'), tensor([[275, 301, 455,  63, 112, 206, 267, 311, 193, 201, 277],\n",
      "        [282, 308, 465,  70, 121, 236, 277, 312, 207, 207, 282]]))\n",
      "(('INLINE ASM', 'next', 'IF'), tensor([[  7,  64,  99, 126, 271, 306, 225, 448, 163, 209, 223, 244, 267],\n",
      "        [  8,  65, 100, 127, 272, 307, 226, 449, 164, 210, 224, 245, 268]]))\n",
      "(('IF', 'if_true', 'INLINE ASM'), tensor([[164, 209, 236, 224, 447, 228],\n",
      "        [165, 210, 237, 225, 448, 229]]))\n",
      "(('IF', 'if_true', 'END_IF'), tensor([[426],\n",
      "        [427]]))\n",
      "(('EXPRESSION', 'next', 'INLINE ASM'), tensor([[ 71, 131, 404, 408, 260, 296, 152, 279, 182, 405],\n",
      "        [ 72, 132, 405, 409, 261, 297, 153, 280, 183, 406]]))\n",
      "(('END_IF', 'next', 'THROW'), tensor([[393],\n",
      "        [394]]))\n",
      "(('END_IF', 'next', 'BEGIN_LOOP'), tensor([[225,  67, 220, 389],\n",
      "        [226,  68, 221, 390]]))\n",
      "(('EXPRESSION', 'next', 'THROW'), tensor([[  3, 349,  14],\n",
      "        [  4, 350,  15]]))\n",
      "(('INLINE ASM', 'next', 'IF_LOOP'), tensor([[261, 297],\n",
      "        [256, 292]]))\n",
      "(('INLINE ASM', 'next', 'BEGIN_LOOP'), tensor([[254, 290],\n",
      "        [255, 291]]))\n",
      "(('BEGIN_LOOP', 'next', 'EXPRESSION'), tensor([[226, 253],\n",
      "        [228, 255]]))\n",
      "(('IF_LOOP', 'if_true', 'IF_LOOP'), tensor([[255],\n",
      "        [255]]))\n",
      "(('INLINE ASM', 'next', 'NEW VARIABLE'), tensor([[158, 251,  78],\n",
      "        [159, 252,  79]]))\n",
      "(('INLINE ASM', 'next', 'END_IF'), tensor([[165, 210, 237, 229, 232],\n",
      "        [166, 211, 238, 234, 233]]))\n",
      "(('IF', 'if_false', 'INLINE ASM'), tensor([[230],\n",
      "        [232]]))\n",
      "(('END_LOOP', 'next', 'INLINE ASM'), tensor([[ 82, 142],\n",
      "        [ 83, 143]]))\n",
      "(('IF_LOOP', 'if_true', 'INLINE ASM'), tensor([[3],\n",
      "        [4]]))\n",
      "(('ENTRY_POINT', 'next', 'BEGIN_LOOP'), tensor([[0],\n",
      "        [1]]))\n"
     ]
    }
   ],
   "source": [
    "for i in geo_graph_data.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435690f-7fc6-4807-8e85-5114e3480f21",
   "metadata": {},
   "source": [
    "# Load global graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a4dca84-3ce9-4206-80b8-b77ceb250379",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_graph_path = './ge-sc/outputs/compress_graphs.gpickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6812d2ba-6bb8-4c22-b028-034985ea7786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx_graph = nx.read_gpickle(global_graph_path)\n",
    "nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
    "nx_g_data = generate_hetero_graph_data(nx_graph)\n",
    "explicated_dgl_graph_data = {}\n",
    "for k, v in nx_g_data.items():\n",
    "    explicated_dgl_graph_data[(k[0], '_'.join(k), k[-1])] = v\n",
    "\n",
    "global_graph = dgl.heterograph(explicated_dgl_graph_data)\n",
    "    \n",
    "# dgl_hete_graph = dgl.heterograph(nx_g_data)\n",
    "# print(dgl_hete_graph.ntypes, dgl_hete_graph.num_nodes())\n",
    "# print(dgl_hete_graph.etypes, dgl_hete_graph.num_edges())\n",
    "# global_graph = dgl_hete_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c10c3b8f-d605-423c-914a-71fd61cc86db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BEGIN_LOOP', 'BEGIN_LOOP_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('BEGIN_LOOP', 'BEGIN_LOOP_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('BREAK', 'BREAK_next_END_LOOP', 'END_LOOP'),\n",
       " ('CONTINUE', 'CONTINUE_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('END_IF', 'END_IF_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('END_IF', 'END_IF_next_END_IF', 'END_IF'),\n",
       " ('END_IF', 'END_IF_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('END_IF', 'END_IF_next_IF', 'IF'),\n",
       " ('END_IF', 'END_IF_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('END_IF', 'END_IF_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('END_IF', 'END_IF_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('END_IF', 'END_IF_next_RETURN', 'RETURN'),\n",
       " ('END_IF', 'END_IF_next_THROW', 'THROW'),\n",
       " ('END_IF', 'END_IF_next__', '_'),\n",
       " ('END_LOOP', 'END_LOOP_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('END_LOOP', 'END_LOOP_next_END_IF', 'END_IF'),\n",
       " ('END_LOOP', 'END_LOOP_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('END_LOOP', 'END_LOOP_next_IF', 'IF'),\n",
       " ('END_LOOP', 'END_LOOP_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('END_LOOP', 'END_LOOP_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('END_LOOP', 'END_LOOP_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('END_LOOP', 'END_LOOP_next_RETURN', 'RETURN'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_IF', 'IF'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_RETURN', 'RETURN'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_THROW', 'THROW'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_BREAK', 'BREAK'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_CONTINUE', 'CONTINUE'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_END_IF', 'END_IF'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_IF', 'IF'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_RETURN', 'RETURN'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_THROW', 'THROW'),\n",
       " ('EXPRESSION', 'EXPRESSION_next__', '_'),\n",
       " ('FUNCTION_NAME', 'FUNCTION_NAME_next_ENTRY_POINT', 'ENTRY_POINT'),\n",
       " ('FUNCTION_NAME', 'FUNCTION_NAME_next_OTHER_ENTRYPOINT', 'OTHER_ENTRYPOINT'),\n",
       " ('IF', 'IF_if_false_END_IF', 'END_IF'),\n",
       " ('IF', 'IF_if_false_EXPRESSION', 'EXPRESSION'),\n",
       " ('IF', 'IF_if_false_IF', 'IF'),\n",
       " ('IF', 'IF_if_false_INLINE ASM', 'INLINE ASM'),\n",
       " ('IF', 'IF_if_false_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('IF', 'IF_if_false_RETURN', 'RETURN'),\n",
       " ('IF', 'IF_if_false_THROW', 'THROW'),\n",
       " ('IF', 'IF_if_false__', '_'),\n",
       " ('IF', 'IF_if_true_BREAK', 'BREAK'),\n",
       " ('IF', 'IF_if_true_CONTINUE', 'CONTINUE'),\n",
       " ('IF', 'IF_if_true_END_IF', 'END_IF'),\n",
       " ('IF', 'IF_if_true_EXPRESSION', 'EXPRESSION'),\n",
       " ('IF', 'IF_if_true_IF', 'IF'),\n",
       " ('IF', 'IF_if_true_INLINE ASM', 'INLINE ASM'),\n",
       " ('IF', 'IF_if_true_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('IF', 'IF_if_true_RETURN', 'RETURN'),\n",
       " ('IF', 'IF_if_true_THROW', 'THROW'),\n",
       " ('IF', 'IF_if_true__', '_'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_false_END_LOOP', 'END_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_false_IF', 'IF'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_END_LOOP', 'END_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_EXPRESSION', 'EXPRESSION'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_IF', 'IF'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_IF_LOOP', 'IF_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_INLINE ASM', 'INLINE ASM'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_END_IF', 'END_IF'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_IF', 'IF'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_RETURN', 'RETURN'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_IF', 'IF'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_RETURN', 'RETURN'),\n",
       " ('OTHER_ENTRYPOINT',\n",
       "  'OTHER_ENTRYPOINT_next_OTHER_ENTRYPOINT',\n",
       "  'OTHER_ENTRYPOINT'),\n",
       " ('_', '__next_END_IF', 'END_IF'),\n",
       " ('_', '__next_EXPRESSION', 'EXPRESSION'),\n",
       " ('_', '__next_IF', 'IF')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_graph.canonical_etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a371827a-a690-487c-bd87-bac1ca95e517",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ENTRY_POINT', 'next', 'IF')\n",
      "('IF', 'if_true', 'RETURN')\n",
      "('IF', 'if_false', 'END_IF')\n",
      "('END_IF', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'RETURN')\n",
      "('FUNCTION_NAME', 'next', 'ENTRY_POINT')\n",
      "('ENTRY_POINT', 'next', 'EXPRESSION')\n",
      "('ENTRY_POINT', 'next', 'NEW VARIABLE')\n",
      "('NEW VARIABLE', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'BEGIN_LOOP')\n",
      "('BEGIN_LOOP', 'next', 'IF_LOOP')\n",
      "('IF_LOOP', 'if_true', 'EXPRESSION')\n",
      "('IF_LOOP', 'if_false', 'END_LOOP')\n",
      "('EXPRESSION', 'next', 'IF_LOOP')\n",
      "('ENTRY_POINT', 'next', 'RETURN')\n",
      "('IF', 'if_false', 'IF')\n",
      "('IF', 'if_false', 'NEW VARIABLE')\n",
      "('NEW VARIABLE', 'next', 'NEW VARIABLE')\n",
      "('END_LOOP', 'next', 'RETURN')\n",
      "('NEW VARIABLE', 'next', 'BEGIN_LOOP')\n",
      "('EXPRESSION', 'next', 'IF')\n",
      "('IF', 'if_true', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'END_IF')\n",
      "('END_IF', 'next', 'NEW VARIABLE')\n",
      "('END_LOOP', 'next', 'EXPRESSION')\n",
      "('IF_LOOP', 'if_true', 'IF')\n",
      "('IF', 'if_false', 'EXPRESSION')\n",
      "('END_IF', 'next', 'END_IF')\n",
      "('END_IF', 'next', 'IF')\n",
      "('EXPRESSION', 'next', 'NEW VARIABLE')\n",
      "('NEW VARIABLE', 'next', 'INLINE ASM')\n",
      "('INLINE ASM', 'next', 'RETURN')\n",
      "('NEW VARIABLE', 'next', 'IF')\n",
      "('IF', 'if_true', 'NEW VARIABLE')\n",
      "('IF', 'if_false', 'RETURN')\n",
      "('IF', 'if_true', 'IF')\n",
      "('NEW VARIABLE', 'next', 'RETURN')\n",
      "('END_IF', 'next', 'RETURN')\n",
      "('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT')\n",
      "('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT')\n",
      "('EXPRESSION', 'next', '_')\n",
      "('INLINE ASM', 'next', 'EXPRESSION')\n",
      "('IF', 'if_true', 'THROW')\n",
      "('IF', 'if_false', 'THROW')\n",
      "('END_IF', 'next', '_')\n",
      "('ENTRY_POINT', 'next', 'INLINE ASM')\n",
      "('EXPRESSION', 'next', 'BREAK')\n",
      "('BREAK', 'next', 'END_LOOP')\n",
      "('IF_LOOP', 'if_true', 'NEW VARIABLE')\n",
      "('END_IF', 'next', 'INLINE ASM')\n",
      "('END_LOOP', 'next', 'IF')\n",
      "('IF', 'if_true', 'BREAK')\n",
      "('END_LOOP', 'next', 'NEW VARIABLE')\n",
      "('IF', 'if_true', 'END_IF')\n",
      "('_', 'next', 'END_IF')\n",
      "('EXPRESSION', 'next', 'CONTINUE')\n",
      "('CONTINUE', 'next', 'BEGIN_LOOP')\n",
      "('IF', 'if_true', 'CONTINUE')\n",
      "('ENTRY_POINT', 'next', 'THROW')\n",
      "('IF_LOOP', 'if_true', 'BEGIN_LOOP')\n",
      "('END_LOOP', 'next', 'BEGIN_LOOP')\n",
      "('END_IF', 'next', 'IF_LOOP')\n",
      "('IF', 'if_true', '_')\n",
      "('_', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'THROW')\n",
      "('END_IF', 'next', 'BEGIN_LOOP')\n",
      "('BEGIN_LOOP', 'next', 'EXPRESSION')\n",
      "('EXPRESSION', 'next', 'INLINE ASM')\n",
      "('END_LOOP', 'next', 'IF_LOOP')\n",
      "('IF_LOOP', 'if_true', 'IF_LOOP')\n",
      "('END_LOOP', 'next', 'END_IF')\n",
      "('INLINE ASM', 'next', 'NEW VARIABLE')\n",
      "('INLINE ASM', 'next', 'IF')\n",
      "('IF', 'if_true', 'INLINE ASM')\n",
      "('INLINE ASM', 'next', 'END_IF')\n",
      "('IF', 'if_false', 'INLINE ASM')\n",
      "('IF', 'if_false', '_')\n",
      "('END_LOOP', 'next', 'INLINE ASM')\n",
      "('ENTRY_POINT', 'next', 'BEGIN_LOOP')\n",
      "('IF_LOOP', 'if_true', 'INLINE ASM')\n",
      "('INLINE ASM', 'next', 'BEGIN_LOOP')\n",
      "('INLINE ASM', 'next', 'IF_LOOP')\n",
      "('_', 'next', 'IF')\n",
      "('END_IF', 'next', 'THROW')\n",
      "('IF_LOOP', 'if_true', 'END_LOOP')\n",
      "('IF_LOOP', 'if_false', 'IF')\n"
     ]
    }
   ],
   "source": [
    "for k in nx_g_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fef00520-ef99-468a-abd4-280161f0e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = {}\n",
    "for ntype in global_graph.ntypes:\n",
    "    feature_data[ntype] = nodetype2onehot(ntype, ntypes_dict).repeat(dgl_hete_graph.num_nodes(ntype), 1)\n",
    "global_graph.ndata['feat'] = feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16f6fd59-8b17-43fc-86cd-0afd595d32d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BEGIN_LOOP': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'BREAK': tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.]]),\n",
       " 'CONTINUE': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'END_IF': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'END_LOOP': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'ENTRY_POINT': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'EXPRESSION': tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.]]),\n",
       " 'FUNCTION_NAME': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'IF': tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.]]),\n",
       " 'IF_LOOP': tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'INLINE ASM': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'NEW VARIABLE': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'OTHER_ENTRYPOINT': tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]),\n",
       " 'RETURN': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'THROW': tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]]),\n",
       " '_': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_graph.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b0195-18c5-4ab0-8ff8-57a6417860ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dccecc-cd2b-4ace-ab9f-9a8f9c3af9bd",
   "metadata": {},
   "source": [
    "# Load global graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5554697-6408-4734-93cc-a8a6701147b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl_graph_generator import generate_hetero_graph_data, add_hetero_ids, get_number_of_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8235dac0-af96-4d9f-a101-469d2cf37907",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_graph = './datasets/Etherscan_Contract/extracted_source_code'\n",
    "filename_mapping = {file: idx for idx, file in enumerate(os.listdir(extracted_graph))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b71f8ac1-37d6-4f54-9f4c-b662b331ed47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx_graph = nx.read_gpickle('./datasets/Etherscan_Contract/compressed_graphs/compress_graphs.gpickle')\n",
    "nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
    "nx_graph = add_hetero_ids(nx_graph)\n",
    "nx_g_data, node_tracker = generate_hetero_graph_data(nx_graph, filename_mapping)\n",
    "number_of_nodes = get_number_of_nodes(nx_graph)\n",
    "global_graph = dgl.heterograph(nx_g_data, num_nodes_dict=number_of_nodes)\n",
    "global_graph.ndata['filename'] = node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "308c40d6-1125-4a51-8005-2ed36d3069fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49088, 42144)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_graph.number_of_nodes(), global_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "243dd07f-7b06-44cd-af6f-e0869859a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_graph(nx_g_data):\n",
    "    reflected_data = {}\n",
    "    for metapath, value in nx_g_data.items():\n",
    "        if metapath[0] == metapath[-1]:\n",
    "            reflected_data[metapath] = (torch.cat((value[0], value[1])), torch.cat((value[1], value[0])))\n",
    "        else:\n",
    "            if metapath not in reflected_data.keys():\n",
    "                reflected_data[metapath] = value\n",
    "            else:\n",
    "                reflected_data[metapath] = (torch.cat((reflected_data[metapath][0], value[0])), torch.cat((reflected_data[metapath][1], value[1])))\n",
    "            if metapath[::-1] not in reflected_data.keys():\n",
    "                reflected_data[metapath[::-1]] = (value[1], value[0])\n",
    "            else:\n",
    "                reflected_data[metapath[::-1]] = (torch.cat((reflected_data[metapath[::-1]][0], value[1])), torch.cat((reflected_data[metapath[::-1]][1], value[0])))\n",
    "    return reflected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17595d69-bced-472c-a446-afab1dd1ffd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49088, 84288)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflected_global_graph_data = reflect_graph(nx_g_data)\n",
    "reflected_global_graph = dgl.heterograph(reflected_global_graph_data)\n",
    "reflected_global_graph.ndata['filename'] = global_graph.ndata['filename']\n",
    "reflected_global_graph.number_of_nodes(), reflected_global_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c6e3910-0e32-42e5-befe-f8eef3f738fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "for ntype in reflected_global_graph.ntypes:\n",
    "    features[ntype] = nodetype2onehot(ntype, ntypes_dict).repeat(global_graph.num_nodes(ntype), 1)\n",
    "reflected_global_graph.ndata['feat'] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4af21e-b450-420b-bc58-24968385c395",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true"
   },
   "source": [
    "# HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e0fd471-6ec7-453c-a1ca-f5d269f7ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../dgl')\n",
    "from examples.pytorch.han.model_hetero import SemanticAttention, HANLayer\n",
    "from examples.pytorch.han.utils import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfeb1d1c-1674-416d-a9f2-e867b668082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"QM7b dataset for graph property prediction (regression).\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "class HANDataset(DGLDataset):\n",
    "    _url = 'http://deepchem.io.s3-website-us-west-1.amazonaws.com/' \\\n",
    "           'datasets/qm7b.mat'\n",
    "    _sha1_str = '4102c744bb9d6fd7b40ac67a300e49cd87e28392'\n",
    "    _label = './datasets/Etherscan_Contract/Reentrancy_AutoExtract_corenodes.json'\n",
    "    _data_path = './datasets/Etherscan_Contract/extracted_graph'\n",
    "\n",
    "    def __init__(self, raw_dir=None, force_reload=False, verbose=False):\n",
    "        super(HANDataset, self).__init__(name='ethsc',\n",
    "                                          url=self._url,\n",
    "                                          raw_dir=raw_dir,\n",
    "                                          force_reload=force_reload,\n",
    "                                          verbose=verbose)\n",
    "\n",
    "    def process(self):\n",
    "        self.graphs, self.label = self._load_graph()\n",
    "\n",
    "    def _load_graph(self):\n",
    "        extracted_graph = [f for f in os.listdir(self._data_path) if f.endswith('.gpickle')]\n",
    "        num_graphs = len(extracted_graph)\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        for i in range(num_graphs):\n",
    "            nx_graph = nx.read_gpickle(join(self._data_path, extracted_graph[i]))\n",
    "            nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
    "            nx_g_data = generate_hetero_graph_data(nx_graph)\n",
    "            dgl_hete_graph = dgl.heterograph(nx_g_data)\n",
    "            feature_data = {}\n",
    "            h_data = {}\n",
    "            for ntype in dgl_hete_graph.ntypes:\n",
    "                feature_data[ntype] = nodetype2onehot(ntype, ntypes_dict).repeat(dgl_hete_graph.num_nodes(ntype), 1)\n",
    "#                 h_data[ntype] = torch.tensor([], dtype=torch.int64).repeat(dgl_hete_graph.num_nodes(ntype), 1)\n",
    "                \n",
    "            dgl_hete_graph.ndata['feat'] = feature_data\n",
    "#             dgl_hete_graph.ndata['h'] = h_data\n",
    "            graphs.append(dgl_hete_graph)\n",
    "            labels.append(int(label_dict[extracted_graph[i].replace('.gpickle', '.sol')]))\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "#         print(graphs[0].ndata)\n",
    "        return graphs, labels\n",
    "\n",
    "\n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "Ethdataset = HANDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "6dfac784-0f7d-40e0-901a-9d8362aeac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETHidsDataset(DGLDataset):\n",
    "    _label = './datasets/Etherscan_Contract/Reentrancy_AutoExtract_corenodes.json'\n",
    "    _data_path = './datasets/Etherscan_Contract/extracted_source_code'\n",
    "\n",
    "    def __init__(self, raw_dir=None, force_reload=False, verbose=False):\n",
    "        super(ETHidsDataset, self).__init__(name='ethscids',\n",
    "                                          raw_dir=raw_dir,\n",
    "                                          force_reload=force_reload,\n",
    "                                          verbose=verbose)\n",
    "\n",
    "    def process(self):\n",
    "        self.graphs, self.label = self._load_graph()\n",
    "\n",
    "    def _load_graph(self):\n",
    "        extracted_graph = [f for f in os.listdir(self._data_path) if f.endswith('.sol')]\n",
    "        num_graphs = len(extracted_graph)\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        with open(self._label, 'r') as f:\n",
    "            content = f.readlines()\n",
    "        label_dict = {}\n",
    "        for l in content:\n",
    "            sc = json.loads(l.strip('\\n').strip(','))\n",
    "            label_dict[sc['contract_name']] = sc['targets']\n",
    "        label_dict['No_Reentrance.sol'] = '0'\n",
    "        for i in range(num_graphs):\n",
    "            graphs.append(extracted_graph[i])\n",
    "            labels.append(int(label_dict[extracted_graph[i].replace('.gpickle', '.sol')]))\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "#         onehot_label = None\n",
    "#         for label in labels:\n",
    "#             one_hot = torch.zeros(2)\n",
    "#             one_hot[label] = 1\n",
    "#             if onehot_label is None:\n",
    "#                 one_hot_label = one_hot\n",
    "#             else:\n",
    "#                 onehot_label = torch.cat((onehot_label, one_hot), dim=0)\n",
    "#         labels = onehot_label\n",
    "#         print(graphs[0].ndata)\n",
    "        return graphs, labels\n",
    "\n",
    "\n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "EthIdsdataset = ETHidsDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "48dada0e-0a4e-46e9-8fdb-cf8b26693d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = GraphDataLoader(\n",
    "    EthIdsdataset,\n",
    "    batch_size=8,\n",
    "    drop_last=False,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75180bcf-2ed8-4288-89b1-f49fdf71c057",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('BEGIN_LOOP', 'if_true', 'IF_LOOP'), ('IF_LOOP', 'if_true', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'CONTINUE'), ('CONTINUE', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'END_IF'), ('END_IF', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'ENTRY_POINT'),\n",
       "  ('ENTRY_POINT', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'IF_LOOP'), ('IF_LOOP', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'BEGIN_LOOP')],\n",
       " [('BEGIN_LOOP', 'next', 'NEW VARIABLE'),\n",
       "  ('NEW VARIABLE', 'next', 'BEGIN_LOOP')],\n",
       " [('BREAK', 'if_true', 'IF'), ('IF', 'if_true', 'BREAK')],\n",
       " [('BREAK', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'BREAK')],\n",
       " [('BREAK', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'BREAK')],\n",
       " [('CONTINUE', 'if_true', 'IF'), ('IF', 'if_true', 'CONTINUE')],\n",
       " [('CONTINUE', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'CONTINUE')],\n",
       " [('CONTINUE', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'CONTINUE')],\n",
       " [('END_IF', 'if_false', 'IF'), ('IF', 'if_false', 'END_IF')],\n",
       " [('END_IF', 'if_true', 'IF'), ('IF', 'if_true', 'END_IF')],\n",
       " [('END_IF', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'END_IF'), ('END_IF', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'IF'), ('IF', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'IF_LOOP'), ('IF_LOOP', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'RETURN'), ('RETURN', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', 'THROW'), ('THROW', 'next', 'END_IF')],\n",
       " [('END_IF', 'next', '_'), ('_', 'next', 'END_IF')],\n",
       " [('END_LOOP', 'if_false', 'IF_LOOP'), ('IF_LOOP', 'if_false', 'END_LOOP')],\n",
       " [('END_LOOP', 'if_true', 'IF_LOOP'), ('IF_LOOP', 'if_true', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'BREAK'), ('BREAK', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'END_IF'), ('END_IF', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'IF'), ('IF', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'IF_LOOP'), ('IF_LOOP', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'END_LOOP')],\n",
       " [('END_LOOP', 'next', 'RETURN'), ('RETURN', 'next', 'END_LOOP')],\n",
       " [('ENTRY_POINT', 'next', 'BEGIN_LOOP'),\n",
       "  ('BEGIN_LOOP', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'EXPRESSION'),\n",
       "  ('EXPRESSION', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'FUNCTION_NAME'),\n",
       "  ('FUNCTION_NAME', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'IF'), ('IF', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'INLINE ASM'),\n",
       "  ('INLINE ASM', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'NEW VARIABLE'),\n",
       "  ('NEW VARIABLE', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'RETURN'), ('RETURN', 'next', 'ENTRY_POINT')],\n",
       " [('ENTRY_POINT', 'next', 'THROW'), ('THROW', 'next', 'ENTRY_POINT')],\n",
       " [('EXPRESSION', 'if_false', 'IF'), ('IF', 'if_false', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'if_true', 'IF'), ('IF', 'if_true', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'if_true', 'IF_LOOP'), ('IF_LOOP', 'if_true', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'BREAK'), ('BREAK', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'CONTINUE'), ('CONTINUE', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'END_IF'), ('END_IF', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'ENTRY_POINT'),\n",
       "  ('ENTRY_POINT', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'IF'), ('IF', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'IF_LOOP'), ('IF_LOOP', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'NEW VARIABLE'),\n",
       "  ('NEW VARIABLE', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'RETURN'), ('RETURN', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', 'THROW'), ('THROW', 'next', 'EXPRESSION')],\n",
       " [('EXPRESSION', 'next', '_'), ('_', 'next', 'EXPRESSION')],\n",
       " [('FUNCTION_NAME', 'next', 'ENTRY_POINT'),\n",
       "  ('ENTRY_POINT', 'next', 'FUNCTION_NAME')],\n",
       " [('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT'),\n",
       "  ('OTHER_ENTRYPOINT', 'next', 'FUNCTION_NAME')],\n",
       " [('IF', 'if_false', 'END_IF'), ('END_IF', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'EXPRESSION'), ('EXPRESSION', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'IF'), ('IF', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'IF_LOOP'), ('IF_LOOP', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'INLINE ASM'), ('INLINE ASM', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'NEW VARIABLE'), ('NEW VARIABLE', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'RETURN'), ('RETURN', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', 'THROW'), ('THROW', 'if_false', 'IF')],\n",
       " [('IF', 'if_false', '_'), ('_', 'if_false', 'IF')],\n",
       " [('IF', 'if_true', 'BREAK'), ('BREAK', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'CONTINUE'), ('CONTINUE', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'END_IF'), ('END_IF', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'EXPRESSION'), ('EXPRESSION', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'IF'), ('IF', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'IF_LOOP'), ('IF_LOOP', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'INLINE ASM'), ('INLINE ASM', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'NEW VARIABLE'), ('NEW VARIABLE', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'RETURN'), ('RETURN', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', 'THROW'), ('THROW', 'if_true', 'IF')],\n",
       " [('IF', 'if_true', '_'), ('_', 'if_true', 'IF')],\n",
       " [('IF', 'next', 'END_IF'), ('END_IF', 'next', 'IF')],\n",
       " [('IF', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'IF')],\n",
       " [('IF', 'next', 'ENTRY_POINT'), ('ENTRY_POINT', 'next', 'IF')],\n",
       " [('IF', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'IF')],\n",
       " [('IF', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'IF')],\n",
       " [('IF', 'next', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'IF')],\n",
       " [('IF', 'next', '_'), ('_', 'next', 'IF')],\n",
       " [('IF_LOOP', 'if_false', 'END_LOOP'), ('END_LOOP', 'if_false', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_false', 'IF'), ('IF', 'if_false', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'END_LOOP'), ('END_LOOP', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'EXPRESSION'), ('EXPRESSION', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'IF'), ('IF', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'IF_LOOP'), ('IF_LOOP', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'INLINE ASM'), ('INLINE ASM', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'if_true', 'NEW VARIABLE'),\n",
       "  ('NEW VARIABLE', 'if_true', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'next', 'END_IF'), ('END_IF', 'next', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'IF_LOOP')],\n",
       " [('IF_LOOP', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'IF_LOOP')],\n",
       " [('INLINE ASM', 'if_false', 'IF'), ('IF', 'if_false', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'if_true', 'IF'), ('IF', 'if_true', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'if_true', 'IF_LOOP'), ('IF_LOOP', 'if_true', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'BEGIN_LOOP'), ('BEGIN_LOOP', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'END_IF'), ('END_IF', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'ENTRY_POINT'),\n",
       "  ('ENTRY_POINT', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'IF'), ('IF', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'IF_LOOP'), ('IF_LOOP', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'NEW VARIABLE'),\n",
       "  ('NEW VARIABLE', 'next', 'INLINE ASM')],\n",
       " [('INLINE ASM', 'next', 'RETURN'), ('RETURN', 'next', 'INLINE ASM')],\n",
       " [('NEW VARIABLE', 'if_false', 'IF'), ('IF', 'if_false', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'if_true', 'IF'), ('IF', 'if_true', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'if_true', 'IF_LOOP'),\n",
       "  ('IF_LOOP', 'if_true', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'BEGIN_LOOP'),\n",
       "  ('BEGIN_LOOP', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'END_IF'), ('END_IF', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'ENTRY_POINT'),\n",
       "  ('ENTRY_POINT', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'EXPRESSION'),\n",
       "  ('EXPRESSION', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'IF'), ('IF', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'INLINE ASM'),\n",
       "  ('INLINE ASM', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'NEW VARIABLE'),\n",
       "  ('NEW VARIABLE', 'next', 'NEW VARIABLE')],\n",
       " [('NEW VARIABLE', 'next', 'RETURN'), ('RETURN', 'next', 'NEW VARIABLE')],\n",
       " [('OTHER_ENTRYPOINT', 'next', 'FUNCTION_NAME'),\n",
       "  ('FUNCTION_NAME', 'next', 'OTHER_ENTRYPOINT')],\n",
       " [('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT'),\n",
       "  ('OTHER_ENTRYPOINT', 'next', 'OTHER_ENTRYPOINT')],\n",
       " [('RETURN', 'if_false', 'IF'), ('IF', 'if_false', 'RETURN')],\n",
       " [('RETURN', 'if_true', 'IF'), ('IF', 'if_true', 'RETURN')],\n",
       " [('RETURN', 'next', 'END_IF'), ('END_IF', 'next', 'RETURN')],\n",
       " [('RETURN', 'next', 'END_LOOP'), ('END_LOOP', 'next', 'RETURN')],\n",
       " [('RETURN', 'next', 'ENTRY_POINT'), ('ENTRY_POINT', 'next', 'RETURN')],\n",
       " [('RETURN', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'RETURN')],\n",
       " [('RETURN', 'next', 'INLINE ASM'), ('INLINE ASM', 'next', 'RETURN')],\n",
       " [('RETURN', 'next', 'NEW VARIABLE'), ('NEW VARIABLE', 'next', 'RETURN')],\n",
       " [('THROW', 'if_false', 'IF'), ('IF', 'if_false', 'THROW')],\n",
       " [('THROW', 'if_true', 'IF'), ('IF', 'if_true', 'THROW')],\n",
       " [('THROW', 'next', 'END_IF'), ('END_IF', 'next', 'THROW')],\n",
       " [('THROW', 'next', 'ENTRY_POINT'), ('ENTRY_POINT', 'next', 'THROW')],\n",
       " [('THROW', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'THROW')],\n",
       " [('_', 'if_false', 'IF'), ('IF', 'if_false', '_')],\n",
       " [('_', 'if_true', 'IF'), ('IF', 'if_true', '_')],\n",
       " [('_', 'next', 'END_IF'), ('END_IF', 'next', '_')],\n",
       " [('_', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', '_')],\n",
       " [('_', 'next', 'IF'), ('IF', 'next', '_')]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_paths = []\n",
    "for mt in reflected_global_graph.canonical_etypes:\n",
    "    if mt[0] == mt[1]:\n",
    "        ref_mt = [mt]\n",
    "    else:\n",
    "        ref_mt = [mt, mt[::-1]]\n",
    "    if ref_mt not in meta_paths:\n",
    "        meta_paths.append(ref_mt)\n",
    "print(len(meta_paths))\n",
    "meta_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "515bb07e-bbac-4cd9-89e5-43144426208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print(len(reflected_global_graph.canonical_etypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9b96b7b0-0cbb-4417-ac3e-1c9917daad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_paths = [[('BEGIN_LOOP', 'BEGIN_LOOP_next_EXPRESSION', 'EXPRESSION'), ('EXPRESSION', 'EXPRESSION_next_BEGIN_LOOP', 'BEGIN_LOOP')],\n",
    "#               [('EXPRESSION', 'EXPRESSION_next_IF', 'IF'), ('IF', 'IF_if_false_EXPRESSION', 'EXPRESSION')]]\n",
    "meta_paths = [[('BEGIN_LOOP', 'next', 'EXPRESSION'), ('EXPRESSION', 'next', 'BEGIN_LOOP')],\n",
    "              [('EXPRESSION', 'next', 'EXPRESSION'), ('IF', 'if_false', 'EXPRESSION')]]\n",
    "# meta_paths = [['BEGIN_LOOP_next_EXPRESSION', 'EXPRESSION_next_BEGIN_LOOP'],\n",
    "#               ['EXPRESSION_next_IF', 'IF_if_false_EXPRESSION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71a96967-600a-407a-a2a6-af531500d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "for ntype in reflected_global_graph.ntypes:\n",
    "    features[ntype] = nodetype2onehot(ntype, ntypes_dict).repeat(reflected_global_graph.num_nodes(ntype), 1)\n",
    "reflected_global_graph.ndata['feat'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "53f245db-17d7-41e3-a2c4-9fccd318a325",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN_LOOP\n",
      "tensor([0, 0, 0])\n",
      "BREAK\n",
      "tensor([], dtype=torch.int64)\n",
      "CONTINUE\n",
      "tensor([], dtype=torch.int64)\n",
      "END_IF\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "END_LOOP\n",
      "tensor([0, 0, 0])\n",
      "ENTRY_POINT\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "EXPRESSION\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "FUNCTION_NAME\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "IF\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "IF_LOOP\n",
      "tensor([0, 0, 0])\n",
      "INLINE ASM\n",
      "tensor([0, 0])\n",
      "NEW VARIABLE\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0])\n",
      "OTHER_ENTRYPOINT\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "RETURN\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "THROW\n",
      "tensor([], dtype=torch.int64)\n",
      "_\n",
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for k, v in reflected_global_graph.ndata['filename'].items():\n",
    "    print(k)\n",
    "    file_mapping = v == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "86db01aa-35c6-4a21-a098-db73ca66246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HANVulClassifier(nn.Module):\n",
    "    def __init__(self, reflected_global_graph, meta_paths, in_size, hidden_size, out_size, num_heads, dropout):\n",
    "        super(HANVulClassifier, self).__init__()\n",
    "        self.reflected_global_graph = reflected_global_graph\n",
    "        self.meta_paths = meta_paths\n",
    "        self.node_types = set([meta_path[0][0] for meta_path in meta_paths])\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(HANLayer([meta_paths[0]], in_size, hidden_size, num_heads, dropout))\n",
    "        for meta_path in meta_paths[1:]:\n",
    "            self.layers.append(HANLayer([meta_path], in_size, hidden_size, num_heads, dropout))\n",
    "        self.features = {}\n",
    "        for han in self.layers:\n",
    "            ntype = han.meta_paths[0][0][0]\n",
    "            self.features[ntype] = han(self.reflected_global_graph, self.reflected_global_graph.ndata['feat'][ntype])\n",
    "        self.classify = nn.Linear(hidden_size * num_heads , out_size)\n",
    "        \n",
    "\n",
    "    def forward(self, batched_g_name):\n",
    "        batched_graph_embedded = []\n",
    "        for g_name in batched_g_name:\n",
    "            file_ids = filename_mapping[g_name]\n",
    "            graph_embedded = 0\n",
    "            for node_type in self.node_types:\n",
    "                file_mask = self.reflected_global_graph.ndata['filename'][node_type] == file_ids\n",
    "                if file_mask.sum().item() != 0:\n",
    "                    graph_embedded += self.features[node_type][file_mask].mean(0)\n",
    "            batched_graph_embedded.append(graph_embedded.tolist())\n",
    "        batched_graph_embedded = torch.tensor(batched_graph_embedded).to(device)\n",
    "        output = self.classify(batched_graph_embedded)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "604a94bc-6189-4b0e-a7ff-08269a9900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_graph_path = './datasets/Etherscan_Contract/extracted_source_code'\n",
    "extracted_graph = [f for f in os.listdir(extracted_graph_path) if f.endswith('.sol')]\n",
    "num_graphs = len(extracted_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "ff1c90fc-5a27-4159-b49c-cd784c61b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 2]) torch.Size([3]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "type(one_hot(torch.tensor([1]), 2))\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target, target.shape, target.dtype)\n",
    "# output = loss(input, target)output.backward()\n",
    "a = torch.tensor([float('nan'), float(1)])\n",
    "torch.isnan(a).any()\n",
    "a = torch.tensor([list(torch.tensor([1,2])), list(torch.tensor([3,4]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "83762140-14e5-49ec-91a3-497817ab16a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "c467fa82-298b-4b7f-86ac-1c066c38d1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.645506 - train_acc: 0.300725\n",
      "train_loss: 0.622181 - train_acc: 0.300725\n",
      "train_loss: 0.606615 - train_acc: 0.291667\n",
      "train_loss: 0.595169 - train_acc: 0.291667\n",
      "train_loss: 0.591035 - train_acc: 0.300725\n",
      "train_loss: 0.577336 - train_acc: 0.282609\n",
      "train_loss: 0.572611 - train_acc: 0.282609\n",
      "train_loss: 0.579597 - train_acc: 0.291667\n",
      "train_loss: 0.561972 - train_acc: 0.282609\n",
      "train_loss: 0.574273 - train_acc: 0.300725\n"
     ]
    }
   ],
   "source": [
    "model = HANVulClassifier(reflected_global_graph, meta_paths, in_size=16, hidden_size=16, out_size=2, num_heads=8, dropout=0.6)\n",
    "# opt = torch.optim.Adam(model.parameters(),  lr=0.0005)\n",
    "model.to(device)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    train_acc = 0\n",
    "    steps = 0\n",
    "    logists = []\n",
    "    target = []\n",
    "    for idx, (batched_graph_name, labels) in enumerate(dataloader):\n",
    "#         print(labels)\n",
    "        torch.set_grad_enabled(True)\n",
    "        logist = model(batched_graph_name)\n",
    "        preds = logits.argmax(dim=1)\n",
    "#         label = int(label_dict[graph_name])\n",
    "#         logists.append(logist.tolist())\n",
    "#         target.append(label)\n",
    "        loss = cross_entropy(logist.to(device), labels.to(device))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "        train_acc += accuracy(preds, labels)\n",
    "        \n",
    "#     preds = torch.tensor(logists, requires_grad=True)\n",
    "#     target = torch.tensor(target, dtype=torch.int64)\n",
    "#     loss = cross_entropy(preds, target)\n",
    "#     opt.zero_grad()\n",
    "#     loss.backward()\n",
    "#     opt.step()\n",
    "    print('train_loss: {:4f} - train_acc: {:4f}'.format(total_loss/(idx+1), train_acc/(idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "91c882e9-fdd5-4f99-9832-1395ca025bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "4bde1a12-d8ed-4cbf-904f-b8bfcb94d630",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training fold 0 with 1/1 train/test smart contracts\n",
      "Fold 0 - Epochs 0\n",
      "train_loss: 0.692884 - train_acc: 0.494382\n",
      "valid_loss: 0.685920 - valid_acc: 0.511111\n",
      "Fold 0 - Epochs 1\n",
      "train_loss: 0.690513 - train_acc: 0.505618\n",
      "valid_loss: 0.684245 - valid_acc: 0.511111\n",
      "Fold 0 - Epochs 2\n",
      "train_loss: 0.688009 - train_acc: 0.516854\n",
      "valid_loss: 0.682304 - valid_acc: 0.522222\n",
      "Fold 0 - Epochs 3\n",
      "train_loss: 0.685087 - train_acc: 0.528090\n",
      "valid_loss: 0.679917 - valid_acc: 0.522222\n",
      "Fold 0 - Epochs 4\n",
      "train_loss: 0.681473 - train_acc: 0.573034\n",
      "valid_loss: 0.676968 - valid_acc: 0.500000\n",
      "Fold 0 - Epochs 5\n",
      "train_loss: 0.676984 - train_acc: 0.617978\n",
      "valid_loss: 0.673385 - valid_acc: 0.511111\n",
      "Fold 0 - Epochs 6\n",
      "train_loss: 0.671480 - train_acc: 0.629213\n",
      "valid_loss: 0.669156 - valid_acc: 0.566667\n",
      "Fold 0 - Epochs 7\n",
      "train_loss: 0.664880 - train_acc: 0.662921\n",
      "valid_loss: 0.664366 - valid_acc: 0.577778\n",
      "Fold 0 - Epochs 8\n",
      "train_loss: 0.657216 - train_acc: 0.685393\n",
      "valid_loss: 0.659110 - valid_acc: 0.588889\n",
      "Fold 0 - Epochs 9\n",
      "train_loss: 0.648531 - train_acc: 0.696629\n",
      "valid_loss: 0.653599 - valid_acc: 0.611111\n",
      "Fold 0 - Epochs 10\n",
      "train_loss: 0.639007 - train_acc: 0.719101\n",
      "valid_loss: 0.648064 - valid_acc: 0.633333\n",
      "Fold 0 - Epochs 11\n",
      "train_loss: 0.628828 - train_acc: 0.707865\n",
      "valid_loss: 0.642770 - valid_acc: 0.644444\n",
      "Fold 0 - Epochs 12\n",
      "train_loss: 0.618236 - train_acc: 0.707865\n",
      "valid_loss: 0.638048 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 13\n",
      "train_loss: 0.607546 - train_acc: 0.707865\n",
      "valid_loss: 0.634163 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 14\n",
      "train_loss: 0.597031 - train_acc: 0.707865\n",
      "valid_loss: 0.631391 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 15\n",
      "train_loss: 0.586976 - train_acc: 0.696629\n",
      "valid_loss: 0.629910 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 16\n",
      "train_loss: 0.577587 - train_acc: 0.707865\n",
      "valid_loss: 0.629804 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 17\n",
      "train_loss: 0.569030 - train_acc: 0.707865\n",
      "valid_loss: 0.631057 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 18\n",
      "train_loss: 0.561367 - train_acc: 0.707865\n",
      "valid_loss: 0.633535 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 19\n",
      "train_loss: 0.554578 - train_acc: 0.707865\n",
      "valid_loss: 0.637024 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 20\n",
      "train_loss: 0.548581 - train_acc: 0.707865\n",
      "valid_loss: 0.641228 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 21\n",
      "train_loss: 0.543234 - train_acc: 0.707865\n",
      "valid_loss: 0.645861 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 22\n",
      "train_loss: 0.538381 - train_acc: 0.707865\n",
      "valid_loss: 0.650592 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 23\n",
      "train_loss: 0.533877 - train_acc: 0.707865\n",
      "valid_loss: 0.655153 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 24\n",
      "train_loss: 0.529588 - train_acc: 0.719101\n",
      "valid_loss: 0.659352 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 25\n",
      "train_loss: 0.525428 - train_acc: 0.719101\n",
      "valid_loss: 0.663024 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 26\n",
      "train_loss: 0.521343 - train_acc: 0.719101\n",
      "valid_loss: 0.666101 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 27\n",
      "train_loss: 0.517328 - train_acc: 0.719101\n",
      "valid_loss: 0.668542 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 28\n",
      "train_loss: 0.513390 - train_acc: 0.719101\n",
      "valid_loss: 0.670395 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 29\n",
      "train_loss: 0.509559 - train_acc: 0.719101\n",
      "valid_loss: 0.671714 - valid_acc: 0.688889\n",
      "Fold 0 - Epochs 30\n",
      "train_loss: 0.505867 - train_acc: 0.730337\n",
      "valid_loss: 0.672613 - valid_acc: 0.688889\n",
      "Fold 0 - Epochs 31\n",
      "train_loss: 0.502345 - train_acc: 0.730337\n",
      "valid_loss: 0.673157 - valid_acc: 0.688889\n",
      "Fold 0 - Epochs 32\n",
      "train_loss: 0.499008 - train_acc: 0.730337\n",
      "valid_loss: 0.673463 - valid_acc: 0.688889\n",
      "Fold 0 - Epochs 33\n",
      "train_loss: 0.495868 - train_acc: 0.730337\n",
      "valid_loss: 0.673604 - valid_acc: 0.688889\n",
      "Fold 0 - Epochs 34\n",
      "train_loss: 0.492922 - train_acc: 0.730337\n",
      "valid_loss: 0.673663 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 35\n",
      "train_loss: 0.490164 - train_acc: 0.741573\n",
      "valid_loss: 0.673693 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 36\n",
      "train_loss: 0.487582 - train_acc: 0.741573\n",
      "valid_loss: 0.673744 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 37\n",
      "train_loss: 0.485156 - train_acc: 0.741573\n",
      "valid_loss: 0.673865 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 38\n",
      "train_loss: 0.482863 - train_acc: 0.741573\n",
      "valid_loss: 0.674073 - valid_acc: 0.677778\n",
      "Fold 0 - Epochs 39\n",
      "train_loss: 0.480677 - train_acc: 0.741573\n",
      "valid_loss: 0.674383 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 40\n",
      "train_loss: 0.478583 - train_acc: 0.741573\n",
      "valid_loss: 0.674807 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 41\n",
      "train_loss: 0.476559 - train_acc: 0.741573\n",
      "valid_loss: 0.675351 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 42\n",
      "train_loss: 0.474596 - train_acc: 0.741573\n",
      "valid_loss: 0.676036 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 43\n",
      "train_loss: 0.472681 - train_acc: 0.741573\n",
      "valid_loss: 0.676827 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 44\n",
      "train_loss: 0.470804 - train_acc: 0.741573\n",
      "valid_loss: 0.677708 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 45\n",
      "train_loss: 0.468976 - train_acc: 0.741573\n",
      "valid_loss: 0.678689 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 46\n",
      "train_loss: 0.467189 - train_acc: 0.741573\n",
      "valid_loss: 0.679752 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 47\n",
      "train_loss: 0.465448 - train_acc: 0.741573\n",
      "valid_loss: 0.680879 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 48\n",
      "train_loss: 0.463755 - train_acc: 0.741573\n",
      "valid_loss: 0.682058 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 49\n",
      "train_loss: 0.462112 - train_acc: 0.741573\n",
      "valid_loss: 0.683275 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 50\n",
      "train_loss: 0.460523 - train_acc: 0.741573\n",
      "valid_loss: 0.684506 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 51\n",
      "train_loss: 0.458987 - train_acc: 0.741573\n",
      "valid_loss: 0.685756 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 52\n",
      "train_loss: 0.457507 - train_acc: 0.741573\n",
      "valid_loss: 0.686996 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 53\n",
      "train_loss: 0.456086 - train_acc: 0.741573\n",
      "valid_loss: 0.688224 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 54\n",
      "train_loss: 0.454717 - train_acc: 0.741573\n",
      "valid_loss: 0.689440 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 55\n",
      "train_loss: 0.453406 - train_acc: 0.741573\n",
      "valid_loss: 0.690614 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 56\n",
      "train_loss: 0.452148 - train_acc: 0.741573\n",
      "valid_loss: 0.691761 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 57\n",
      "train_loss: 0.450944 - train_acc: 0.741573\n",
      "valid_loss: 0.692866 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 58\n",
      "train_loss: 0.449786 - train_acc: 0.741573\n",
      "valid_loss: 0.693927 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 59\n",
      "train_loss: 0.448678 - train_acc: 0.741573\n",
      "valid_loss: 0.694938 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 60\n",
      "train_loss: 0.447624 - train_acc: 0.741573\n",
      "valid_loss: 0.695906 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 61\n",
      "train_loss: 0.446611 - train_acc: 0.741573\n",
      "valid_loss: 0.696838 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 62\n",
      "train_loss: 0.445647 - train_acc: 0.741573\n",
      "valid_loss: 0.697713 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 63\n",
      "train_loss: 0.444730 - train_acc: 0.741573\n",
      "valid_loss: 0.698567 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 64\n",
      "train_loss: 0.443854 - train_acc: 0.741573\n",
      "valid_loss: 0.699362 - valid_acc: 0.655556\n",
      "Fold 0 - Epochs 65\n",
      "train_loss: 0.443022 - train_acc: 0.741573\n",
      "valid_loss: 0.700117 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 66\n",
      "train_loss: 0.442230 - train_acc: 0.741573\n",
      "valid_loss: 0.700845 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 67\n",
      "train_loss: 0.441480 - train_acc: 0.741573\n",
      "valid_loss: 0.701521 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 68\n",
      "train_loss: 0.440772 - train_acc: 0.741573\n",
      "valid_loss: 0.702147 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 69\n",
      "train_loss: 0.440098 - train_acc: 0.741573\n",
      "valid_loss: 0.702778 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 70\n",
      "train_loss: 0.439473 - train_acc: 0.741573\n",
      "valid_loss: 0.703326 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 71\n",
      "train_loss: 0.438881 - train_acc: 0.741573\n",
      "valid_loss: 0.703881 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 72\n",
      "train_loss: 0.438324 - train_acc: 0.741573\n",
      "valid_loss: 0.704374 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 73\n",
      "train_loss: 0.437804 - train_acc: 0.752809\n",
      "valid_loss: 0.704848 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 74\n",
      "train_loss: 0.437319 - train_acc: 0.752809\n",
      "valid_loss: 0.705290 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 75\n",
      "train_loss: 0.436867 - train_acc: 0.752809\n",
      "valid_loss: 0.705693 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 76\n",
      "train_loss: 0.436447 - train_acc: 0.752809\n",
      "valid_loss: 0.706076 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 77\n",
      "train_loss: 0.436062 - train_acc: 0.752809\n",
      "valid_loss: 0.706435 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 78\n",
      "train_loss: 0.435702 - train_acc: 0.752809\n",
      "valid_loss: 0.706740 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 79\n",
      "train_loss: 0.435379 - train_acc: 0.752809\n",
      "valid_loss: 0.707056 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 80\n",
      "train_loss: 0.435077 - train_acc: 0.752809\n",
      "valid_loss: 0.707329 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 81\n",
      "train_loss: 0.434807 - train_acc: 0.752809\n",
      "valid_loss: 0.707592 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 82\n",
      "train_loss: 0.434559 - train_acc: 0.752809\n",
      "valid_loss: 0.707784 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 83\n",
      "train_loss: 0.434342 - train_acc: 0.752809\n",
      "valid_loss: 0.707985 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 84\n",
      "train_loss: 0.434146 - train_acc: 0.752809\n",
      "valid_loss: 0.708186 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 85\n",
      "train_loss: 0.433974 - train_acc: 0.752809\n",
      "valid_loss: 0.708341 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 86\n",
      "train_loss: 0.433817 - train_acc: 0.752809\n",
      "valid_loss: 0.708452 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 87\n",
      "train_loss: 0.433688 - train_acc: 0.752809\n",
      "valid_loss: 0.708600 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 88\n",
      "train_loss: 0.433574 - train_acc: 0.752809\n",
      "valid_loss: 0.708693 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 89\n",
      "train_loss: 0.433483 - train_acc: 0.752809\n",
      "valid_loss: 0.708766 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 90\n",
      "train_loss: 0.433400 - train_acc: 0.752809\n",
      "valid_loss: 0.708836 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 91\n",
      "train_loss: 0.433337 - train_acc: 0.752809\n",
      "valid_loss: 0.708881 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 92\n",
      "train_loss: 0.433285 - train_acc: 0.752809\n",
      "valid_loss: 0.708922 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 93\n",
      "train_loss: 0.433249 - train_acc: 0.752809\n",
      "valid_loss: 0.708951 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 94\n",
      "train_loss: 0.433215 - train_acc: 0.752809\n",
      "valid_loss: 0.708982 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 95\n",
      "train_loss: 0.433199 - train_acc: 0.752809\n",
      "valid_loss: 0.709002 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 96\n",
      "train_loss: 0.433182 - train_acc: 0.752809\n",
      "valid_loss: 0.709002 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 97\n",
      "train_loss: 0.433174 - train_acc: 0.752809\n",
      "valid_loss: 0.708997 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 98\n",
      "train_loss: 0.433171 - train_acc: 0.752809\n",
      "valid_loss: 0.709001 - valid_acc: 0.666667\n",
      "Fold 0 - Epochs 99\n",
      "train_loss: 0.433170 - train_acc: 0.752809\n",
      "valid_loss: 0.709001 - valid_acc: 0.666667\n",
      "Saving model fold 0\n",
      "Start training fold 1 with 1/1 train/test smart contracts\n",
      "Fold 1 - Epochs 0\n",
      "train_loss: 0.678126 - train_acc: 0.622222\n",
      "valid_loss: 0.673308 - valid_acc: 0.662921\n",
      "Fold 1 - Epochs 1\n",
      "train_loss: 0.676200 - train_acc: 0.633333\n",
      "valid_loss: 0.671706 - valid_acc: 0.662921\n",
      "Fold 1 - Epochs 2\n",
      "train_loss: 0.674170 - train_acc: 0.644444\n",
      "valid_loss: 0.669823 - valid_acc: 0.674157\n",
      "Fold 1 - Epochs 3\n",
      "train_loss: 0.671796 - train_acc: 0.655556\n",
      "valid_loss: 0.667510 - valid_acc: 0.674157\n",
      "Fold 1 - Epochs 4\n",
      "train_loss: 0.668889 - train_acc: 0.666667\n",
      "valid_loss: 0.664619 - valid_acc: 0.674157\n",
      "Fold 1 - Epochs 5\n",
      "train_loss: 0.665277 - train_acc: 0.677778\n",
      "valid_loss: 0.661039 - valid_acc: 0.662921\n",
      "Fold 1 - Epochs 6\n",
      "train_loss: 0.660849 - train_acc: 0.700000\n",
      "valid_loss: 0.656754 - valid_acc: 0.674157\n",
      "Fold 1 - Epochs 7\n",
      "train_loss: 0.655606 - train_acc: 0.711111\n",
      "valid_loss: 0.651702 - valid_acc: 0.674157\n",
      "Fold 1 - Epochs 8\n",
      "train_loss: 0.649528 - train_acc: 0.733333\n",
      "valid_loss: 0.645955 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 9\n",
      "train_loss: 0.642729 - train_acc: 0.733333\n",
      "valid_loss: 0.639553 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 10\n",
      "train_loss: 0.635328 - train_acc: 0.733333\n",
      "valid_loss: 0.632656 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 11\n",
      "train_loss: 0.627541 - train_acc: 0.733333\n",
      "valid_loss: 0.625392 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 12\n",
      "train_loss: 0.619534 - train_acc: 0.733333\n",
      "valid_loss: 0.617988 - valid_acc: 0.674157\n",
      "Fold 1 - Epochs 13\n",
      "train_loss: 0.611561 - train_acc: 0.733333\n",
      "valid_loss: 0.610627 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 14\n",
      "train_loss: 0.603791 - train_acc: 0.733333\n",
      "valid_loss: 0.603535 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 15\n",
      "train_loss: 0.596384 - train_acc: 0.733333\n",
      "valid_loss: 0.596910 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 16\n",
      "train_loss: 0.589423 - train_acc: 0.733333\n",
      "valid_loss: 0.590915 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 17\n",
      "train_loss: 0.582918 - train_acc: 0.755556\n",
      "valid_loss: 0.585639 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 18\n",
      "train_loss: 0.576821 - train_acc: 0.755556\n",
      "valid_loss: 0.581133 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 19\n",
      "train_loss: 0.571048 - train_acc: 0.755556\n",
      "valid_loss: 0.577379 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 20\n",
      "train_loss: 0.565498 - train_acc: 0.755556\n",
      "valid_loss: 0.574333 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 21\n",
      "train_loss: 0.560077 - train_acc: 0.755556\n",
      "valid_loss: 0.571935 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 22\n",
      "train_loss: 0.554731 - train_acc: 0.755556\n",
      "valid_loss: 0.570127 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 23\n",
      "train_loss: 0.549445 - train_acc: 0.755556\n",
      "valid_loss: 0.568841 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 24\n",
      "train_loss: 0.544246 - train_acc: 0.755556\n",
      "valid_loss: 0.568026 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 25\n",
      "train_loss: 0.539172 - train_acc: 0.766667\n",
      "valid_loss: 0.567653 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 26\n",
      "train_loss: 0.534262 - train_acc: 0.777778\n",
      "valid_loss: 0.567687 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 27\n",
      "train_loss: 0.529525 - train_acc: 0.777778\n",
      "valid_loss: 0.568122 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 28\n",
      "train_loss: 0.524968 - train_acc: 0.777778\n",
      "valid_loss: 0.568950 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 29\n",
      "train_loss: 0.520590 - train_acc: 0.777778\n",
      "valid_loss: 0.570121 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 30\n",
      "train_loss: 0.516415 - train_acc: 0.777778\n",
      "valid_loss: 0.571614 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 31\n",
      "train_loss: 0.512461 - train_acc: 0.777778\n",
      "valid_loss: 0.573356 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 32\n",
      "train_loss: 0.508746 - train_acc: 0.777778\n",
      "valid_loss: 0.575279 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 33\n",
      "train_loss: 0.505290 - train_acc: 0.777778\n",
      "valid_loss: 0.577267 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 34\n",
      "train_loss: 0.502093 - train_acc: 0.777778\n",
      "valid_loss: 0.579222 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 35\n",
      "train_loss: 0.499141 - train_acc: 0.777778\n",
      "valid_loss: 0.581028 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 36\n",
      "train_loss: 0.496413 - train_acc: 0.788889\n",
      "valid_loss: 0.582596 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 37\n",
      "train_loss: 0.493867 - train_acc: 0.788889\n",
      "valid_loss: 0.583860 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 38\n",
      "train_loss: 0.491479 - train_acc: 0.788889\n",
      "valid_loss: 0.584790 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 39\n",
      "train_loss: 0.489213 - train_acc: 0.788889\n",
      "valid_loss: 0.585383 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 40\n",
      "train_loss: 0.487046 - train_acc: 0.788889\n",
      "valid_loss: 0.585664 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 41\n",
      "train_loss: 0.484978 - train_acc: 0.788889\n",
      "valid_loss: 0.585682 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 42\n",
      "train_loss: 0.482995 - train_acc: 0.788889\n",
      "valid_loss: 0.585496 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 43\n",
      "train_loss: 0.481101 - train_acc: 0.788889\n",
      "valid_loss: 0.585177 - valid_acc: 0.685393\n",
      "Fold 1 - Epochs 44\n",
      "train_loss: 0.479301 - train_acc: 0.788889\n",
      "valid_loss: 0.584768 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 45\n",
      "train_loss: 0.477595 - train_acc: 0.788889\n",
      "valid_loss: 0.584333 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 46\n",
      "train_loss: 0.475982 - train_acc: 0.788889\n",
      "valid_loss: 0.583921 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 47\n",
      "train_loss: 0.474466 - train_acc: 0.788889\n",
      "valid_loss: 0.583556 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 48\n",
      "train_loss: 0.473037 - train_acc: 0.788889\n",
      "valid_loss: 0.583252 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 49\n",
      "train_loss: 0.471686 - train_acc: 0.788889\n",
      "valid_loss: 0.583047 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 50\n",
      "train_loss: 0.470414 - train_acc: 0.788889\n",
      "valid_loss: 0.582941 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 51\n",
      "train_loss: 0.469207 - train_acc: 0.788889\n",
      "valid_loss: 0.582910 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 52\n",
      "train_loss: 0.468065 - train_acc: 0.800000\n",
      "valid_loss: 0.582981 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 53\n",
      "train_loss: 0.466982 - train_acc: 0.800000\n",
      "valid_loss: 0.583129 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 54\n",
      "train_loss: 0.465948 - train_acc: 0.800000\n",
      "valid_loss: 0.583342 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 55\n",
      "train_loss: 0.464967 - train_acc: 0.800000\n",
      "valid_loss: 0.583610 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 56\n",
      "train_loss: 0.464034 - train_acc: 0.800000\n",
      "valid_loss: 0.583940 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 57\n",
      "train_loss: 0.463147 - train_acc: 0.800000\n",
      "valid_loss: 0.584279 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 58\n",
      "train_loss: 0.462305 - train_acc: 0.800000\n",
      "valid_loss: 0.584664 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 59\n",
      "train_loss: 0.461506 - train_acc: 0.800000\n",
      "valid_loss: 0.585044 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 60\n",
      "train_loss: 0.460748 - train_acc: 0.800000\n",
      "valid_loss: 0.585436 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 61\n",
      "train_loss: 0.460030 - train_acc: 0.800000\n",
      "valid_loss: 0.585814 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 62\n",
      "train_loss: 0.459353 - train_acc: 0.800000\n",
      "valid_loss: 0.586196 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 63\n",
      "train_loss: 0.458711 - train_acc: 0.800000\n",
      "valid_loss: 0.586545 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 64\n",
      "train_loss: 0.458104 - train_acc: 0.800000\n",
      "valid_loss: 0.586873 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 65\n",
      "train_loss: 0.457531 - train_acc: 0.800000\n",
      "valid_loss: 0.587187 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 66\n",
      "train_loss: 0.456995 - train_acc: 0.800000\n",
      "valid_loss: 0.587476 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 67\n",
      "train_loss: 0.456488 - train_acc: 0.800000\n",
      "valid_loss: 0.587734 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 68\n",
      "train_loss: 0.456009 - train_acc: 0.800000\n",
      "valid_loss: 0.587971 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 69\n",
      "train_loss: 0.455561 - train_acc: 0.800000\n",
      "valid_loss: 0.588186 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 70\n",
      "train_loss: 0.455140 - train_acc: 0.800000\n",
      "valid_loss: 0.588371 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 71\n",
      "train_loss: 0.454747 - train_acc: 0.800000\n",
      "valid_loss: 0.588545 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 72\n",
      "train_loss: 0.454378 - train_acc: 0.800000\n",
      "valid_loss: 0.588697 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 73\n",
      "train_loss: 0.454035 - train_acc: 0.800000\n",
      "valid_loss: 0.588835 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 74\n",
      "train_loss: 0.453716 - train_acc: 0.800000\n",
      "valid_loss: 0.588944 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 75\n",
      "train_loss: 0.453419 - train_acc: 0.800000\n",
      "valid_loss: 0.589051 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 76\n",
      "train_loss: 0.453144 - train_acc: 0.800000\n",
      "valid_loss: 0.589133 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 77\n",
      "train_loss: 0.452892 - train_acc: 0.800000\n",
      "valid_loss: 0.589210 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 78\n",
      "train_loss: 0.452658 - train_acc: 0.800000\n",
      "valid_loss: 0.589285 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 79\n",
      "train_loss: 0.452448 - train_acc: 0.800000\n",
      "valid_loss: 0.589348 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 80\n",
      "train_loss: 0.452252 - train_acc: 0.800000\n",
      "valid_loss: 0.589391 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 81\n",
      "train_loss: 0.452076 - train_acc: 0.800000\n",
      "valid_loss: 0.589446 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 82\n",
      "train_loss: 0.451918 - train_acc: 0.800000\n",
      "valid_loss: 0.589475 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 83\n",
      "train_loss: 0.451778 - train_acc: 0.800000\n",
      "valid_loss: 0.589505 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 84\n",
      "train_loss: 0.451652 - train_acc: 0.800000\n",
      "valid_loss: 0.589540 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 85\n",
      "train_loss: 0.451539 - train_acc: 0.800000\n",
      "valid_loss: 0.589552 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 86\n",
      "train_loss: 0.451440 - train_acc: 0.800000\n",
      "valid_loss: 0.589574 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 87\n",
      "train_loss: 0.451356 - train_acc: 0.800000\n",
      "valid_loss: 0.589597 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 88\n",
      "train_loss: 0.451282 - train_acc: 0.800000\n",
      "valid_loss: 0.589599 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 89\n",
      "train_loss: 0.451224 - train_acc: 0.800000\n",
      "valid_loss: 0.589615 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 90\n",
      "train_loss: 0.451172 - train_acc: 0.800000\n",
      "valid_loss: 0.589631 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 91\n",
      "train_loss: 0.451129 - train_acc: 0.800000\n",
      "valid_loss: 0.589632 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 92\n",
      "train_loss: 0.451097 - train_acc: 0.800000\n",
      "valid_loss: 0.589631 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 93\n",
      "train_loss: 0.451069 - train_acc: 0.800000\n",
      "valid_loss: 0.589642 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 94\n",
      "train_loss: 0.451052 - train_acc: 0.800000\n",
      "valid_loss: 0.589637 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 95\n",
      "train_loss: 0.451041 - train_acc: 0.800000\n",
      "valid_loss: 0.589642 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 96\n",
      "train_loss: 0.451034 - train_acc: 0.800000\n",
      "valid_loss: 0.589638 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 97\n",
      "train_loss: 0.451030 - train_acc: 0.800000\n",
      "valid_loss: 0.589637 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 98\n",
      "train_loss: 0.451026 - train_acc: 0.800000\n",
      "valid_loss: 0.589638 - valid_acc: 0.696629\n",
      "Fold 1 - Epochs 99\n",
      "train_loss: 0.451025 - train_acc: 0.800000\n",
      "valid_loss: 0.589638 - valid_acc: 0.696629\n",
      "Saving model fold 1\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "k_folds = 2\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "train_results = {}\n",
    "test_results = {}\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(range(num_graphs))):\n",
    "    train_results[fold] = {'loss': [], 'acc': []}\n",
    "    test_results[fold] = {'loss': [], 'acc': []}\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    train_dataloader = GraphDataLoader(\n",
    "    EthIdsdataset,\n",
    "    batch_size=128,\n",
    "    drop_last=False,\n",
    "    sampler=train_subsampler)\n",
    "    test_dataloader = GraphDataLoader(\n",
    "    EthIdsdataset,\n",
    "    batch_size=128,\n",
    "    drop_last=False,\n",
    "    sampler=test_subsampler)\n",
    "    print('Start training fold {} with {}/{} train/test smart contracts'.format(fold, len(train_dataloader), len(test_dataloader)))\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    model = HANVulClassifier(reflected_global_graph, meta_paths, in_size=16, hidden_size=16, out_size=2, num_heads=8, dropout=0.6)\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(),  lr=0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=0.01, total_steps=total_steps)\n",
    "    lrs = []\n",
    "    for epoch in range(epochs):\n",
    "        print('Fold {} - Epochs {}'.format(fold, epoch))\n",
    "        total_loss = 0\n",
    "        train_acc = 0\n",
    "        steps = 0\n",
    "        for idx, (batched_graph, labels) in enumerate(train_dataloader):\n",
    "            labels = labels.to(device)\n",
    "            logits = model(batched_graph)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            train_acc += accuracy(preds, labels)\n",
    "            loss = cross_entropy(logits, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            lrs.append(opt.param_groups[0][\"lr\"])\n",
    "        print('train_loss: {:4f} - train_acc: {:4f}'.format(total_loss/steps, train_acc/steps))\n",
    "        train_results[fold]['loss'].append(total_loss/steps)\n",
    "        train_results[fold]['acc'].append(train_acc/steps)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            test_acc = 0\n",
    "            steps = 0\n",
    "            for idx, (batched_graph, labels) in enumerate(test_dataloader):\n",
    "                labels = labels.to(device)\n",
    "                logits = model(batched_graph)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                test_acc += accuracy(preds, labels)\n",
    "                loss = cross_entropy(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "            print('valid_loss: {:4f} - valid_acc: {:4f}'.format(total_loss/steps, test_acc/steps))\n",
    "            test_results[fold]['loss'].append(total_loss/steps)\n",
    "            test_results[fold]['acc'].append(test_acc/steps)\n",
    "    print('Saving model fold {}'.format(fold))\n",
    "    save_path = f'./models/model_han_fold_{fold}.pth'\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "7fac9373-efdd-49c5-8215-f635bd605d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = './ge-sc/logs/HAN_CrossVal'\n",
    "writer = SummaryWriter(tensorboard_path)\n",
    "tensorboard_acc = {'train': train_results[0]['acc'], 'valid': test_results[0]['acc']}\n",
    "tensorboard_loss = {'train': train_results[0]['loss'], 'valid': test_results[0]['loss']}\n",
    "# for key, results in train_results[0].items():\n",
    "#     tensorboard_acc[] = \n",
    "#     writer.add_scalars('Loss', train_res, epoch)\n",
    "# for idx, lr in enumerate(lrs):\n",
    "#     writer.add_scalar('Learning rate', lr, idx)\n",
    "for idx, lr in enumerate(lrs):\n",
    "    writer.add_scalar('Learning rate', lr, idx)\n",
    "\n",
    "for fold in range(k_folds):\n",
    "    for idx in range(epochs):\n",
    "        writer.add_scalars('Accuracy', {f'train_{fold+1}': train_results[fold]['acc'][idx],\n",
    "                                        f'valid_{fold+1}': test_results[fold]['acc'][idx]}, idx)\n",
    "        writer.add_scalars('Loss', {f'train_{fold+1}': train_results[fold]['loss'][idx],\n",
    "                                    f'valid_{fold+1}': test_results[fold]['loss'][idx]}, idx)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27212540-d5c6-4f5b-9e46-003176fc8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "# etypes is the list of edge types as strings.\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(epochs):\n",
    "    for batched_graph, labels in dataloader:\n",
    "        logits = model(batched_graph)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        opt.zero_grad()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b60dc-4b30-41c8-8536-9cf07c192f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea3229-a71b-463e-8851-aa4c4b2c7af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d135b5-d690-4402-8b79-b0160e169b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a950c77d-faa1-4414-a61b-057488422e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_metapath = list(dgl_hete_graph.metagraph().edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b51fcdb3-393c-4f16-b186-c5841eb04eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_dgl_hete_graph.get_etype_id(('RETURN', 'next', 'END_IF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66df0410-a112-4bc7-9f3f-eb2ff9967a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node BEGIN_LOOP has 49024\n",
      "node BREAK has 45362\n",
      "node CONTINUE has 44867\n",
      "node END_IF has 48975\n",
      "node END_LOOP has 49025\n",
      "node ENTRY_POINT has 49085\n",
      "node EXPRESSION has 49086\n",
      "node FUNCTION_NAME has 49088\n",
      "node IF has 48971\n",
      "node IF_LOOP has 49027\n",
      "node INLINE ASM has 48934\n",
      "node NEW VARIABLE has 49018\n",
      "node OTHER_ENTRYPOINT has 49075\n",
      "node RETURN has 49033\n",
      "node THROW has 48267\n",
      "node _ has 49087\n",
      "16\n",
      "775924\n"
     ]
    }
   ],
   "source": [
    "num_node = 0\n",
    "for node in explicated_dgl_hete_graph.ntypes:\n",
    "    print('node {} has {}'.format(node, explicated_dgl_hete_graph.number_of_nodes(node)))\n",
    "    num_node += explicated_dgl_hete_graph.number_of_nodes(node)\n",
    "print(len(explicated_dgl_hete_graph.ntypes))\n",
    "print(num_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d70693ff-dcbe-4c23-bb14-2c2994e1b061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for node in explicated_dgl_hete_graph.ntypes:\n",
    "    if features is None:\n",
    "        features = metapath_embedding(n)\n",
    "    else:\n",
    "        features.append(metapath_embedding(node))\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "4a4f450b-db49-48c0-a6a7-7d9a880630a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[226, 253],\n",
       "                       [228, 255]]),\n",
       "       values=tensor([1., 1.]),\n",
       "       size=(1559, 2116), nnz=2, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_hete_graph.adj(etype=('BEGIN_LOOP', 'next', 'EXPRESSION'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "478800f3-9dd2-4990-b197-318e280462be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (224, 228)\t1\n",
      "  (251, 255)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 7)\t1\n",
      "  (4, 9)\t1\n",
      "  (4, 9)\t1\n",
      "  (4, 9)\t1\n",
      "  (5, 10)\t1\n",
      "  (5, 10)\t1\n",
      "  (6, 11)\t1\n",
      "  (7, 12)\t1\n",
      "  (9, 14)\t1\n",
      "  (13, 18)\t1\n",
      "  (17, 22)\t1\n",
      "  (18, 21)\t1\n",
      "  (19, 24)\t1\n",
      "  (19, 24)\t1\n",
      "  (21, 26)\t1\n",
      "  (24, 29)\t1\n",
      "  (25, 30)\t1\n",
      "  (26, 31)\t1\n",
      "  (26, 31)\t1\n",
      "  (26, 31)\t1\n",
      "  (28, 33)\t1\n",
      "  :\t:\n",
      "  (647, 652)\t1\n",
      "  (647, 650)\t1\n",
      "  (651, 654)\t1\n",
      "  (664, 669)\t1\n",
      "  (714, 719)\t1\n",
      "  (720, 725)\t1\n",
      "  (720, 725)\t1\n",
      "  (739, 744)\t1\n",
      "  (755, 758)\t1\n",
      "  (781, 786)\t1\n",
      "  (787, 792)\t1\n",
      "  (803, 808)\t1\n",
      "  (816, 821)\t1\n",
      "  (831, 836)\t1\n",
      "  (906, 909)\t1\n",
      "  (908, 911)\t1\n",
      "  (912, 915)\t1\n",
      "  (925, 930)\t1\n",
      "  (1007, 1012)\t1\n",
      "  (1016, 1021)\t1\n",
      "  (1067, 1072)\t1\n",
      "  (1283, 1288)\t1\n",
      "  (1358, 1363)\t1\n",
      "  (1545, 1550)\t1\n",
      "  (1556, 1561)\t1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_231306/874073363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0madj_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl_hete_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy_fmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdgl_hete_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy_fmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "adj = 1\n",
    "for etype in dgl_hete_graph.canonical_etypes:\n",
    "    adj_tmp = dgl_hete_graph.adj(etype=etype, scipy_fmt='csr', transpose=False)\n",
    "    \n",
    "    \n",
    "    adj = adj * dgl_hete_graph.adj(etype=etype, scipy_fmt='csr', transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a3954f4f-eafd-4220-b4ed-36539abf6874",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BEGIN_LOOP', 'BEGIN_LOOP_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('BEGIN_LOOP', 'BEGIN_LOOP_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('BREAK', 'BREAK_next_END_LOOP', 'END_LOOP'),\n",
       " ('CONTINUE', 'CONTINUE_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('END_IF', 'END_IF_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('END_IF', 'END_IF_next_END_IF', 'END_IF'),\n",
       " ('END_IF', 'END_IF_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('END_IF', 'END_IF_next_IF', 'IF'),\n",
       " ('END_IF', 'END_IF_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('END_IF', 'END_IF_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('END_IF', 'END_IF_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('END_IF', 'END_IF_next_RETURN', 'RETURN'),\n",
       " ('END_IF', 'END_IF_next_THROW', 'THROW'),\n",
       " ('END_IF', 'END_IF_next__', '_'),\n",
       " ('END_LOOP', 'END_LOOP_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('END_LOOP', 'END_LOOP_next_END_IF', 'END_IF'),\n",
       " ('END_LOOP', 'END_LOOP_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('END_LOOP', 'END_LOOP_next_IF', 'IF'),\n",
       " ('END_LOOP', 'END_LOOP_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('END_LOOP', 'END_LOOP_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('END_LOOP', 'END_LOOP_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('END_LOOP', 'END_LOOP_next_RETURN', 'RETURN'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_IF', 'IF'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_RETURN', 'RETURN'),\n",
       " ('ENTRY_POINT', 'ENTRY_POINT_next_THROW', 'THROW'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_BREAK', 'BREAK'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_CONTINUE', 'CONTINUE'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_END_IF', 'END_IF'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_IF', 'IF'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_RETURN', 'RETURN'),\n",
       " ('EXPRESSION', 'EXPRESSION_next_THROW', 'THROW'),\n",
       " ('EXPRESSION', 'EXPRESSION_next__', '_'),\n",
       " ('FUNCTION_NAME', 'FUNCTION_NAME_next_ENTRY_POINT', 'ENTRY_POINT'),\n",
       " ('FUNCTION_NAME', 'FUNCTION_NAME_next_OTHER_ENTRYPOINT', 'OTHER_ENTRYPOINT'),\n",
       " ('IF', 'IF_if_false_END_IF', 'END_IF'),\n",
       " ('IF', 'IF_if_false_EXPRESSION', 'EXPRESSION'),\n",
       " ('IF', 'IF_if_false_IF', 'IF'),\n",
       " ('IF', 'IF_if_false_INLINE ASM', 'INLINE ASM'),\n",
       " ('IF', 'IF_if_false_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('IF', 'IF_if_false_RETURN', 'RETURN'),\n",
       " ('IF', 'IF_if_false_THROW', 'THROW'),\n",
       " ('IF', 'IF_if_false__', '_'),\n",
       " ('IF', 'IF_if_true_BREAK', 'BREAK'),\n",
       " ('IF', 'IF_if_true_CONTINUE', 'CONTINUE'),\n",
       " ('IF', 'IF_if_true_END_IF', 'END_IF'),\n",
       " ('IF', 'IF_if_true_EXPRESSION', 'EXPRESSION'),\n",
       " ('IF', 'IF_if_true_IF', 'IF'),\n",
       " ('IF', 'IF_if_true_INLINE ASM', 'INLINE ASM'),\n",
       " ('IF', 'IF_if_true_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('IF', 'IF_if_true_RETURN', 'RETURN'),\n",
       " ('IF', 'IF_if_true_THROW', 'THROW'),\n",
       " ('IF', 'IF_if_true__', '_'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_false_END_LOOP', 'END_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_false_IF', 'IF'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_END_LOOP', 'END_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_EXPRESSION', 'EXPRESSION'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_IF', 'IF'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_IF_LOOP', 'IF_LOOP'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_INLINE ASM', 'INLINE ASM'),\n",
       " ('IF_LOOP', 'IF_LOOP_if_true_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_END_IF', 'END_IF'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_IF', 'IF'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_IF_LOOP', 'IF_LOOP'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('INLINE ASM', 'INLINE ASM_next_RETURN', 'RETURN'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_BEGIN_LOOP', 'BEGIN_LOOP'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_EXPRESSION', 'EXPRESSION'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_IF', 'IF'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_INLINE ASM', 'INLINE ASM'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_NEW VARIABLE', 'NEW VARIABLE'),\n",
       " ('NEW VARIABLE', 'NEW VARIABLE_next_RETURN', 'RETURN'),\n",
       " ('OTHER_ENTRYPOINT',\n",
       "  'OTHER_ENTRYPOINT_next_OTHER_ENTRYPOINT',\n",
       "  'OTHER_ENTRYPOINT'),\n",
       " ('_', '__next_END_IF', 'END_IF'),\n",
       " ('_', '__next_EXPRESSION', 'EXPRESSION'),\n",
       " ('_', '__next_IF', 'IF')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicated_dgl_hete_graph.canonical_etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1f55b392-1673-4384-9631-0ee9445d6713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_metapah = [[emt for emt in explicated_dgl_hete_graph.etypes]]\n",
    "len(edge_metapah[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f98912c2-9aa5-42d3-b8d8-8543421d8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_edge_metapah = [['BEGIN_LOOP_next_EXPRESSION', 'EXPRESSION_next_BEGIN_LOOP'],\n",
    "                       ['IF_LOOP_if_true_BEGIN_LOOP', 'BEGIN_LOOP_next_IF_LOOP'],\n",
    "#                       ['EXPRESSION_next_NEW VARIABLE', 'NEW VARIABLE_next_EXPRESSION'],\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "28040dc2-cb4e-4199-8af7-1c5cf12e4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explicated_dgl_hete_graph = dgl.remove_self_loop(explicated_dgl_hete_graph, etype=('END_IF', 'END_IF_next_END_IF', 'END_IF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "27eed4ad-f6a3-4a2f-9a2f-37ef02f3064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559 2116\n"
     ]
    }
   ],
   "source": [
    "print(explicated_dgl_hete_graph.number_of_nodes('BEGIN_LOOP'), explicated_dgl_hete_graph.number_of_nodes('EXPRESSION'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "afd153eb-b9f9-437e-85eb-4c6219be5809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom HAN\n"
     ]
    }
   ],
   "source": [
    "model = HAN(meta_paths=single_edge_metapah,\n",
    "            in_size=128,\n",
    "            hidden_size=8,\n",
    "            out_size=2,\n",
    "            num_heads=[8],\n",
    "            dropout=0.6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2cff7b6-35f4-45df-a506-7dd66cb72fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicated_dgl_hete_graph.number_of_nodes('BEGIN_LOOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a9f20aaf-1133-4e5a-bb4c-2c1d3edf4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "feature_test = []\n",
    "current = 0\n",
    "for idx, node in enumerate(explicated_dgl_hete_graph.ntypes):\n",
    "    feature_test.append(metapath_embedding.embedding.weight[current:current+explicated_dgl_hete_graph.number_of_nodes(node)])\n",
    "print(len(feature_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da70f885-9b24-4868-89b7-a770d4d841fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "logit = model(explicated_dgl_hete_graph.to(device), metapath_embedding.embedding.weight.data[:1559])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "001249f1-0617-4371-a1b6-9cad0dde05f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1559, 2])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e4aea59a-c42d-4d94-af07-f92021a041b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_dgl_hete_graph.number_of_edges(('_', 'next', 'IF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0b325d5d-b1ff-41d4-95bc-551ecb7514d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28468, 128])\n"
     ]
    }
   ],
   "source": [
    "features = torch.tensor([]).to(device)\n",
    "for node in num_nodes_dict:\n",
    "    features = torch.cat((features, metapath_embedding(node)))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b281d14a-ebb0-4def-b41c-ffc63e18f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(logits, labels):\n",
    "    _, indices = torch.max(logits, dim=1)\n",
    "    prediction = indices.long().cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    accuracy = (prediction == labels).sum() / len(prediction)\n",
    "    micro_f1 = f1_score(labels, prediction, average='micro')\n",
    "    macro_f1 = f1_score(labels, prediction, average='macro')\n",
    "\n",
    "    return accuracy, micro_f1, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "57e15df7-94cf-42bd-985a-f909ba02b5fb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bi_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_231306/1946630734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_dgl_hete_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bi_features' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    logits = model(bi_dgl_hete_graph, bi_features)\n",
    "    loss = loss_fcn(logits, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_acc, train_micro_f1, train_macro_f1 = score(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94e8af-758e-43b3-9beb-48e7d9a2e851",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22fc5aa4-40ee-4f11-b6c9-7ef3d8bc9739",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a38b29e4-d74d-412c-b876-5c0fa12ac44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2fd57649-90e3-4e41-b036-d58757b8ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = './ge-sc/logs/2convs.log'\n",
    "tensorboard_path = './ge-sc/logs/ConvHete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "99f74cf1-b678-454d-afcf-6e18bdc2f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(tensorboard_path)\n",
    "with open(logs_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "for idx, l in enumerate(content):\n",
    "    loss = float(l.split(' - ')[0].split()[-1])\n",
    "    acc = float(l.split(' - ')[1].split()[-1])\n",
    "    writer.add_scalar('Loss/train', loss, idx)\n",
    "    writer.add_scalar('Accuracy/train', acc, idx)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfe3fa-9367-4e0b-a4a7-bb9611b7ee59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "769ee41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = './ge-sc/dgl_models/pytorch/han/dataset/aggregate/labels.json'\n",
    "smartbugs_path = './ge-sc/dgl_models/pytorch/han/dataset/ijcai2020/source_code'\n",
    "output_path = './ge-sc/dgl_models/pytorch/han/dataset/ijcai2020/non_vul_source_code'\n",
    "smartbugs = [f for f in os.listdir(smartbugs_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb7fa3b7-e396-4713-a8fe-19f513b2c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "40090.sol\n",
      "40469.sol\n",
      "32559.sol\n",
      "40118.sol\n",
      "40241.sol\n",
      "40353.sol\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "from shutil import copy\n",
    "with open(label_0, 'r') as f:\n",
    "    content = f.readlines()\n",
    "print(len(content))\n",
    "non_vul_sc = []\n",
    "for sc in content:\n",
    "    line = sc.strip('\\n').strip(',')\n",
    "    line = json.loads(line)\n",
    "    if line['targets'] == '0':\n",
    "        non_vul_sc.append(line['contract_name'])\n",
    "        try:\n",
    "            copy(join(smartbugs_path, line['contract_name']), join(output_path, line['contract_name']))\n",
    "        except:\n",
    "            print(line['contract_name'])\n",
    "print(len(non_vul_sc))\n",
    "# for sc in smartbugs:\n",
    "#     item = {\"target\": \"1\", \"contract_name\": sc}\n",
    "#     content.append(json.dumps(item) + ',\\n')\n",
    "# with open(output, 'w') as f:\n",
    "#     f.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1d60442-8fbe-46d6-879d-8b6ede113535",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3,4)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d93a3f52-b59b-4264-876f-c84b42116f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import AMiner\n",
    "import os.path as osp\n",
    "\n",
    "path = './pytorch_geometric/data/AMiner'\n",
    "dataset = AMiner(path)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fafa944-ea2b-476b-9c3e-a311d6254b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mauthor\u001b[0m={\n",
       "    y=[246678],\n",
       "    y_index=[246678],\n",
       "    num_nodes=1693531\n",
       "  },\n",
       "  \u001b[1mvenue\u001b[0m={\n",
       "    y=[134],\n",
       "    y_index=[134],\n",
       "    num_nodes=3883\n",
       "  },\n",
       "  \u001b[1mpaper\u001b[0m={ num_nodes=3194405 },\n",
       "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 9323605] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 9323605] },\n",
       "  \u001b[1m(paper, published_in, venue)\u001b[0m={ edge_index=[2, 3194405] },\n",
       "  \u001b[1m(venue, publishes, paper)\u001b[0m={ edge_index=[2, 3194405] }\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4db200c-2e8d-4353-bac4-463aefff219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metapath = [\n",
    "        ('author', 'writes', 'paper'),\n",
    "        ('paper', 'published in', 'venue'),\n",
    "        ('venue', 'published', 'paper'),\n",
    "        ('paper', 'written by', 'author'),\n",
    "    ]\n",
    "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
    "                         metapath=metapath, walk_length=50, context_size=7,\n",
    "                         walks_per_node=5, num_negative_samples=5,\n",
    "                         sparse=True).to(device)\n",
    "\n",
    "loader = model.loader(batch_size=256, shuffle=True, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f4d4f9c-1c6f-454d-9af9-414266c9ae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('paper',\n",
       "  'written_by',\n",
       "  'author'): tensor([[      0,       1,       2,  ..., 3194404, 3194404, 3194404],\n",
       "         [      0,       1,       2,  ...,    4393,   21681,  317436]]),\n",
       " ('author',\n",
       "  'writes',\n",
       "  'paper'): tensor([[      0,       0,       0,  ..., 1693528, 1693529, 1693530],\n",
       "         [      0,   45988,  124807,  ..., 3194371, 3194387, 3194389]]),\n",
       " ('paper',\n",
       "  'published_in',\n",
       "  'venue'): tensor([[      0,       1,       2,  ..., 3194402, 3194403, 3194404],\n",
       "         [   2190,    2190,    2190,  ...,    3148,    3148,    3148]]),\n",
       " ('venue',\n",
       "  'publishes',\n",
       "  'paper'): tensor([[      0,       0,       0,  ...,    3882,    3882,    3882],\n",
       "         [2203069, 2203070, 2203071,  ...,  952391,  952392,  952393]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e39d10b1-1d9c-4c38-b00d-25d998b779f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13004/1076449694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i, (pos_rw, neg_rw) in enumerate(loader[10]):\n",
    "        print(pos_rw)\n",
    "        print(neg_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43bf02f0-e64e-4229-84c9-2cfa4d037405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
       "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
       "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
       "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
       "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
       "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
       "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
       "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
       "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
       "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
       "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
       "         208,  462])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_index_dict['venue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b039de0-ed5f-43bc-b169-aab967eb6cfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54781/4258459861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ICSE/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;34mr\"\"\"Gets the data of the attribute :obj:`key`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "data[0]['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b621169f-d694-4db7-b94d-32e5fc58d5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/**\n",
      "\n",
      "['0.5.0', '0.6.0']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_222744/24645924.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "buggy_file = './data/smartbugs_wild/'\n",
    "import re\n",
    "pattern = re.compile(r'\\d.\\d.\\d+')\n",
    "with open(buggy_file, 'r') as f:\n",
    "    line = f.readline()\n",
    "    print(line)\n",
    "    while line:\n",
    "        if 'pragma solidity' in line:\n",
    "            result = pattern.findall(line)\n",
    "            print(result)\n",
    "            parts = line.split()[2].split('.')\n",
    "            version = '.'.join([parts[0][-1], parts[1], parts[-1]])\n",
    "            print(version)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94aea08a-fad1-49ec-9e02-823abf24a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import solc\n",
    "from solc import install_solc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75fb3bb4-3233-4fa9-b11f-486831e04aa1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing '0.4.22'...\n",
      "Version '0.4.22' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.9'...\n",
      "Version '0.5.9' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.4.22'...\n",
      "Version '0.4.22' installed.\n",
      "Installing '0.4.21'...\n",
      "Version '0.4.21' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.7'...\n",
      "Version '0.5.7' installed.\n",
      "Installing '0.5.1'...\n",
      "Version '0.5.1' installed.\n",
      "Installing '0.5.1'...\n",
      "Version '0.5.1' installed.\n",
      "Installing '0.5.10'...\n",
      "Version '0.5.10' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.2'...\n",
      "Version '0.5.2' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.4.22'...\n",
      "Version '0.4.22' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.1'...\n",
      "Version '0.5.1' installed.\n",
      "Installing '0.5.2'...\n",
      "Version '0.5.2' installed.\n",
      "Installing '0.4.22'...\n",
      "Version '0.4.22' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.1'...\n",
      "Version '0.5.1' installed.\n",
      "Installing '0.5.8'...\n",
      "Version '0.5.8' installed.\n",
      "Installing '0.5.8'...\n",
      "Version '0.5.8' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.4.22'...\n",
      "Version '0.4.22' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.4.21'...\n",
      "Version '0.4.21' installed.\n",
      "Installing '0.5.0'...\n",
      "Version '0.5.0' installed.\n",
      "Installing '0.5.1'...\n",
      "Version '0.5.1' installed.\n",
      "Installing '0.5.7'...\n",
      "Version '0.5.7' installed.\n",
      "Installing '0.5.6'...\n",
      "Version '0.5.6' installed.\n",
      "Installing '0.5.10'...\n",
      "Version '0.5.10' installed.\n",
      "Installing '0.5.1'...\n",
      "Version '0.5.1' installed.\n",
      "Installing '0.4.23'...\n",
      "Version '0.4.23' installed.\n",
      "Installing '0.4.22'...\n",
      "Version '0.4.22' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Installing '0.5.11'...\n",
      "Version '0.5.11' installed.\n",
      "Extract 50/50 sources\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "pattern =  re.compile(r'\\d.\\d.\\d+')\n",
    "def get_solc_version(source):\n",
    "    with open(source, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if 'pragma solidity' in line:\n",
    "                if len(pattern.findall(line)) > 0:\n",
    "                    return pattern.findall(line)[0]\n",
    "                else:\n",
    "                    return '0.4.25'\n",
    "            line = f.readline()\n",
    "    return '0.4.25'\n",
    "\n",
    "smart_contract_path = './ge-sc/data/solidifi_buggy_contracts/Re-entrancy'\n",
    "smart_contracts = [join(smart_contract_path, f) for f in os.listdir(smart_contract_path) if f.endswith('.sol')]\n",
    "count = 0\n",
    "for sc in smart_contracts:\n",
    "    sc_version = get_solc_version(sc)\n",
    "    try:\n",
    "        subprocess.run(['solc-select', 'install', sc_version])\n",
    "        count += 1\n",
    "    except:\n",
    "        print(sc_version)\n",
    "print(f'Extract {count}/{len(smart_contracts)} sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9273612-76ec-4155-bf45-8efd6874e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './ge-sc/data/solidifi_buggy_contracts/Overflow-Underflow/vulnerabilities.json'\n",
    "out = './ge-sc/data/solidifi_buggy_contracts/aggregate/vulnerabilities.json'\n",
    "buggy_path = './ge-sc/data/solidifi_buggy_contracts'\n",
    "buggys = [join(buggy_path, f) for f in os.listdir(buggy_path)]\n",
    "buggys.remove(join(buggy_path, 'aggregate'))\n",
    "total = []\n",
    "for bug in buggys:\n",
    "    bugtype = bug.split('/')[-1]\n",
    "    with open(path, 'r') as f:\n",
    "        content = json.load(f)\n",
    "    for i in range(len(content)):\n",
    "        content[i]['name'] = bugtype + '_' + content[i]['name'] \n",
    "    total += content\n",
    "with open(out, 'w') as fout:\n",
    "    json.dump(total, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "260152e2-ab3b-48b7-9d07-285c5f73d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(out, 'w') as fout:\n",
    "    json.dump(content, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfbbe44-70d6-42f5-8b0e-49edf69fc327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08f7aa39-7868-42aa-ab0b-21dcb0bd5316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf6ae5a-8f48-4f3a-bb95-d46f2a09f647",
   "metadata": {},
   "source": [
    "## Read report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a8ff27-e97f-4f15-b52c-b8bf4e111b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_avg_results(report_path):\n",
    "    with open(report, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    buggy_f1 = 0\n",
    "    macro_f1 = 0\n",
    "    for i in range(len(results)):\n",
    "        buggy_f1 += results[i]['1']['f1-score']\n",
    "        macro_f1 += results[i]['macro avg']['f1-score']\n",
    "    return round(buggy_f1 / len(results), 4), round(macro_f1 / len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66598947-11cd-418b-a504-386122fc0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_list = ['access_control', 'arithmetic', 'denial_of_service',\n",
    "            'front_running', 'reentrancy', 'time_manipulation', \n",
    "            'unchecked_low_level_calls']\n",
    "models = ['nodetype', 'metapath2vec', 'gae', 'line', 'node2vec']\n",
    "for bugtype in bug_list:\n",
    "    print(bugtype)\n",
    "    for model in models:\n",
    "        report_path = f'./ge-sc/logs/node_classification/cfg/{model}/{bugtype}'\n",
    "        buggy_f1, macro_f1 = get_avg_results(report_path)\n",
    "        print(buggy_f1)\n",
    "        print(macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdee26ea-8a29-4d65-81c2-2f2d299c24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a915634d-9cfd-4aee-8101-ab3c757f0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ge-sc/logs/node_classification/cfg/nodetype/access_control/test_report.json', 'r') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "buggy_f1 = [f['1']['f1-score'] for f in content]\n",
    "macro_f1 = [f['macro avg']['f1-score'] for f in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac501d46-6edf-42ba-802a-d1100b81f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stats.ttest_1samp(macro_f1, 0.702)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
